{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, random, gc, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from kaggle.competitions import nflrush\n",
    "import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.stats import cumfreq\n",
    "from scipy.optimize import nnls\n",
    "import lightgbm as lgb\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.engine.saving import load_model\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Embedding, Concatenate, Flatten, BatchNormalization, Dropout, Activation, PReLU, Add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import metrics\n",
    "from collections import Counter\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, KDTree, ConvexHull \n",
    "from shapely.ops import polygonize, unary_union\n",
    "from shapely.geometry import LineString, MultiPolygon, MultiPoint, Point, Polygon\n",
    "from shapely.geometry import shape, mapping\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "mname = 'zoo_keras'\n",
    "# path = '/kaggle/input/nfl-big-data-bowl-2020/'\n",
    "path = './'\n",
    "build_data = True\n",
    "search = False\n",
    "nrep = 10\n",
    "patience = 21\n",
    "w_holdout = True\n",
    "perm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=6, suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize coordinates, angles, yardline so offense is always driving to the right\n",
    "# https://www.kaggle.com/kernels/scriptcontent/21906255/\n",
    "def std_cols(df):\n",
    "    \n",
    "    # fix inconsistent team abbreviations\n",
    "    ita = {'ARZ': 'ARI', 'BLT':'BAL', 'CLV':'CLE', 'HST':'HOU'}\n",
    "    update = ['PossessionTeam', 'FieldPosition']\n",
    "    for col in update:\n",
    "        for old, new in ita.items():\n",
    "            df.loc[df[col] == old,col] = new\n",
    "                \n",
    "    df['X'] = df.apply(lambda x: x.X if x.PlayDirection == 'right'\\\n",
    "                           else 120-x.X, axis=1) \n",
    "    \n",
    "    df['Y'] = df.apply(lambda x: x.Y if x.PlayDirection == 'right'\\\n",
    "                           else 53.3-x.Y, axis=1) \n",
    "    \n",
    "#     # adjust 2017 Orientation as it differs by 90 degrees from 2018 and 2019\n",
    "#     df.loc[df.Season == 2017, 'Orientation'] = np.mod(df.Orientation + 90, 360)\n",
    "#     # set angles so 0 degrees is directly downfield for rusher and range -180 to 180\n",
    "#     df['Orientation'] = df.apply(lambda x: 180 - np.mod(x.Orientation + 90 \\\n",
    "#                                      if x.PlayDirection == 'right' \\\n",
    "#                                      else x.Orientation - 90, 360), axis=1)\n",
    "    \n",
    "    df['Dir'] = df.apply(lambda x: 180 - np.mod(x.Dir + 90 \\\n",
    "                                     if x.PlayDirection == 'right' \\\n",
    "                                     else x.Dir - 90, 360), axis=1)\n",
    "    \n",
    "    df['YardLine'] = df.apply(lambda x: x.YardLine + 10 \\\n",
    "                              if (x.FieldPosition == x.PossessionTeam) \\\n",
    "                              else 60 + (50-x.YardLine), axis=1)\n",
    "    \n",
    "    df.loc[:, 'S'] = 10 * df['Dis']\n",
    "    \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./train1.csv' does not exist: b'./train1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./train1.csv' does not exist: b'./train1.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [15,10]\n",
    "\n",
    "train = pd.read_csv(path + 'train1.csv', dtype={'WindSpeed': 'object'})\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train0 = train.copy()\n",
    "train = std_cols(train)\n",
    "# train_df = train.copy()\n",
    "train_df = train\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2a87c5729f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# make a copy so as not to alter the original df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "df = train_df\n",
    "mode = 'train'\n",
    "verbose = True\n",
    "\n",
    "# make a copy so as not to alter the original df\n",
    "df = df.copy()\n",
    "\n",
    "df['OffenseDefense'] = \\\n",
    "df.apply(lambda x: \"Offense\" if ((x.Team == 'home') \\\n",
    "                                 & (x.PossessionTeam == \\\n",
    "                                    x.HomeTeamAbbr)) | \\\n",
    "                                ((x.Team == 'away') & \\\n",
    "                                 (x.PossessionTeam == \\\n",
    "                                  x.VisitorTeamAbbr)) \\\n",
    "                                else \"Defense\", axis=1)\n",
    "\n",
    "df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n",
    "\n",
    "df.loc[df.IsRusher, 'OffenseDefense'] = \"Rusher\"\n",
    "\n",
    "keep = ['GameId','PlayId','X','Y','Dir','S','IsRusher','OffenseDefense']\n",
    "\n",
    "df = df[keep]\n",
    "\n",
    "if verbose:\n",
    "    print(df.shape)\n",
    "\n",
    "# flip defense direction\n",
    "# df.loc[df.OffenseDefense=='Defense','Dir'] = df.loc[df.OffenseDefense=='Defense','Dir'] + 180\n",
    "\n",
    "newdir = df.Dir\n",
    "# newdir = 0.99*df.Dir + 0.01*df.Orientation\n",
    "df['SX'] = df.S * np.cos(newdir/180*np.pi) \n",
    "df['SY'] = df.S * np.sin(newdir/180*np.pi)\n",
    "\n",
    "bdf = df.loc[df.IsRusher,['PlayId','X','Y','SX','SY']]\n",
    "bdf.columns = ['PlayId','Ball_X','Ball_Y','Ball_SX','Ball_SY']\n",
    "\n",
    "# bdf = df.loc[df.IsRusher,['PlayId','X','Y','S','Dir']]\n",
    "# bdf.columns = ['PlayId','Ball_X','Ball_Y','Ball_S','Ball_Dir']\n",
    "\n",
    "df = df.merge(bdf, how='left', on='PlayId')\n",
    "\n",
    "df['XR'] = df.X - df.Ball_X\n",
    "df['YR'] = df.Y - df.Ball_Y\n",
    "\n",
    "df['SXR'] = df.SX - df.Ball_SX\n",
    "df['SYR'] = df.SY - df.Ball_SY \n",
    "\n",
    "# df['SXR'] = (df.S - df.Ball_S) * np.cos(df.Dir/180*np.pi) \n",
    "# df['SYR'] = (df.S - df.Ball_S) * np.sin(df.Dir/180*np.pi) \n",
    "\n",
    "\n",
    "print(df.head(), df.shape)\n",
    "\n",
    "# return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c7a6a9d65e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# b = ['Ball_X','Ball_Y','Ball_SX','Ball_SY']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# o = df.loc[df.OffenseDefense=='Offense',k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOffenseDefense\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Offense'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOffenseDefense\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Defense'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PlayId'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'XRO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'YRO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SXO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SYO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SXRO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SYRO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "k = ['PlayId','XR','YR','SX','SY','SXR','SYR']\n",
    "# b = ['Ball_X','Ball_Y','Ball_SX','Ball_SY']\n",
    "# o = df.loc[df.OffenseDefense=='Offense',k]\n",
    "o = df.loc[df.OffenseDefense=='Offense',k]\n",
    "d = df.loc[df.OffenseDefense=='Defense',k]\n",
    "o.columns = ['PlayId','XRO','YRO','SXO','SYO','SXRO','SYRO']\n",
    "d.columns = ['PlayId','XRD','YRD','SXD','SYD','SXRD','SYRD']\n",
    "print(o.shape, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cb0c3688bc7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PlayId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'o' is not defined"
     ]
    }
   ],
   "source": [
    "od = o.merge(d, how='outer', on='PlayId')\n",
    "print(od.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2e123660d004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m23171\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'od' is not defined"
     ]
    }
   ],
   "source": [
    "od.shape[0]/23171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e4a3ec483323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'od' is not defined"
     ]
    }
   ],
   "source": [
    "od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-423bd8b24353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'XOD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXRO\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXRD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'YOD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYRO\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYRD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SXOD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSXO\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSXD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SYOD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYO\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'od' is not defined"
     ]
    }
   ],
   "source": [
    "od['XOD'] = od.XRO - od.XRD\n",
    "od['YOD'] = od.YRO - od.YRD\n",
    "od['SXOD'] = od.SXO - od.SXD\n",
    "od['SYOD'] = od.SYO - od.SYD\n",
    "print(od.head, od.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cdd6f098f5d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PlayId'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'XRO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'YRO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SXO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SYO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SXRO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SYRO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'od' is not defined"
     ]
    }
   ],
   "source": [
    "od.drop(['PlayId','XRO','YRO','SXO','SYO','SXRO','SYRO'], axis=1, inplace=True)\n",
    "print(od.shape, od.shape[0]/110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1963bec7416d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'od' is not defined"
     ]
    }
   ],
   "source": [
    "od.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e4a3ec483323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'od' is not defined"
     ]
    }
   ],
   "source": [
    "od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = od.columns\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# od = scaler.fit_transform(od)\n",
    "# od = np.nan_to_num(od)\n",
    "# od = pd.DataFrame(od, columns=cols)\n",
    "# od.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-070d0364f474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reshape to 4d: play, off, def, feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'od' is not defined"
     ]
    }
   ],
   "source": [
    "# reshape to 4d: play, off, def, feature\n",
    "x4 = od.values.reshape(-1,10,11,od.shape[1])\n",
    "print(x4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x4 = x4.transpose(0, 2, 1, 3)\n",
    "# print(x4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7d4b96066b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x4' is not defined"
     ]
    }
   ],
   "source": [
    "x4[0,0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if build_data:\n",
    "#     X0 = cruncher0(train_df, mode='train', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d85b4b6dc8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x4' is not defined"
     ]
    }
   ],
   "source": [
    "np.isnan(x4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c42f441ca345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x4' is not defined"
     ]
    }
   ],
   "source": [
    "x4 = np.nan_to_num(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d85b4b6dc8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x4' is not defined"
     ]
    }
   ],
   "source": [
    "np.isnan(x4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d192abf749e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx4_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x4' is not defined"
     ]
    }
   ],
   "source": [
    "x4_train = x4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5d8ed175846b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my01_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Yards\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# target\n",
    "n = len(train_df) // 22\n",
    "print(n)\n",
    "\n",
    "y01_train = train_df[\"Yards\"][::22].values.copy()\n",
    "\n",
    "y0_train = np.zeros(shape=(n, 199))\n",
    "for i,yard in enumerate(train_df['Yards'][::22]):\n",
    "    y0_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n",
    "\n",
    "\n",
    "# limit target range\n",
    "y = y01_train.copy()\n",
    "MIN = -10\n",
    "MAX = 35\n",
    "# MIN = -30\n",
    "# MAX = 50\n",
    "y[y < MIN] = MIN\n",
    "y[y > MAX] = MAX\n",
    "y -= MIN\n",
    "\n",
    "num_class = MAX - MIN + 1\n",
    "\n",
    "y_train = np.zeros(shape=(n, num_class))\n",
    "for i, yard in enumerate(y):\n",
    "    y_train[i, yard:] = np.ones(shape=(1, num_class-yard))\n",
    "\n",
    "y1_train = y\n",
    "\n",
    "# y_train = np.zeros(len(y_train_),dtype=np.float)\n",
    "# for i in range(len(y_train)):\n",
    "#     y_train[i] = (y_train_[i])\n",
    "\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# scaler.fit([[y] for y in y_train])\n",
    "# y_train = np.array([y[0] for y in scaler.transform([[y] for y in y_train])])\n",
    "\n",
    "print(y0_train.shape, y01_train.shape)\n",
    "print(y_train.shape, y1_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true is a vector of scalars and y_pred cdfs\n",
    "def crps0(y_true, y_pred):\n",
    "    ans = 0\n",
    "    for i, y in enumerate(y_true):\n",
    "        h = np.zeros(199)\n",
    "        yf = int(np.floor(y))\n",
    "        h[(yf+99):] = 1.0\n",
    "                \n",
    "        ans += mean_squared_error(h, y_pred[i])\n",
    "        \n",
    "    return ans / (len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce monotonicity\n",
    "def mono(p):\n",
    "    for pred in p:\n",
    "        prev = 0\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] < prev:\n",
    "                pred[i] = prev\n",
    "            prev = pred[i]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "#     'device': 'gpu',\n",
    "    'objective':'regression_l1',\n",
    "#     'is_unbalance': True,\n",
    "    'boosting_type':'gbdt',\n",
    "    'metric': 'l1',\n",
    "    'n_jobs': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 2**6,\n",
    "    'max_depth': 4,\n",
    "    'tree_learner':'serial',\n",
    "    'colsample_bytree': 0.7,\n",
    "#     'subsample_freq': 1,\n",
    "    'subsample': 0.7,\n",
    "    'max_bin': 255,\n",
    "    'verbose': -1,\n",
    "    'seed': 123,\n",
    "} \n",
    "\n",
    "# parallelize lgb predictor\n",
    "# def gb_cox(tr_yc, v):\n",
    "#     cf = cumfreq(tr_yc + v, numbins=199, defaultreallimits=(-99,100))\n",
    "#     return cf.cumcount / len(tr_yc) \n",
    "\n",
    "def gb_cox(tr_yc, v):\n",
    "    cf = cumfreq(tr_yc + v, numbins=num_class, defaultreallimits=(0,num_class))\n",
    "    return cf.cumcount / len(tr_yc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust predictions by modified yardline\n",
    "def adjusty(p, df, y_true=None, reduced=True):\n",
    "    n = len(p)\n",
    "#     p = np.cumsum(p, axis=1)\n",
    "#     p = np.clip(p, 0, 1)\n",
    "    if reduced:\n",
    "        pred = np.zeros((n, 199))        \n",
    "        pred[:, (99+MIN):(100+MAX)] = p\n",
    "        pred[:, 100+MAX:] = 1\n",
    "    else:\n",
    "        pred = p\n",
    "    cdf = pred.copy()\n",
    "    for i in range(0,n):\n",
    "        r = i*22\n",
    "        y = df[\"YardLine\"].iloc[r] - 10\n",
    "        \n",
    "        if y < 99: cdf[i,:(100-y-1)] = 0\n",
    "        if y > 1: cdf[i,-(y-1):] = 1\n",
    "                \n",
    "        # check for improvement, should never be worse\n",
    "        if y_true is not None:\n",
    "            mse_orig = mean_squared_error(y_true[i], pred[i])\n",
    "            mse_new = mean_squared_error(y_true[i], cdf[i])\n",
    "            if (mse_new > mse_orig):\n",
    "                print('adjusty inconsistency', i, df[\"FieldPosition\"].iloc[r],\n",
    "                      df[\"PossessionTeam\"].iloc[r],\n",
    "                      df[\"YardLine\"].iloc[r], y, df[\"Yards\"].iloc[r], mse_orig, mse_new)\n",
    "                print(y_true[i])\n",
    "                print(pred[i])\n",
    "                print(cdf[i])\n",
    "                break\n",
    "            \n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust predictions by modified yardline\n",
    "def adjusty2(p, yardline, y_true=None, reduced=True):\n",
    "    n = len(yardline)\n",
    "    if reduced:\n",
    "#         p = np.cumsum(p, axis=1)\n",
    "#         p = np.clip(p, 0, 1)\n",
    "        pred = np.zeros((n, 199))        \n",
    "        pred[:, (99+MIN):(100+MAX)] = p\n",
    "        pred[:, 100+MAX:] = 1\n",
    "    else:\n",
    "        # pred = np.clip(p, 0, 1)\n",
    "        pred = p\n",
    "    cdf = pred.copy()\n",
    "    for i in range(0,n):\n",
    "        y = yardline[i]\n",
    "        \n",
    "        if y < 99: cdf[i,:(100-y-1)] = 0\n",
    "        if y > 1: cdf[i,-(y-1):] = 1\n",
    "                \n",
    "        # check for improvement, should never be worse\n",
    "        if y_true is not None:\n",
    "            mse_orig = mean_squared_error(y_true[i], pred[i])\n",
    "            mse_new = mean_squared_error(y_true[i], cdf[i])\n",
    "            if (mse_new > mse_orig):\n",
    "                print('adjusty2 inconsistency', i, y, mse_orig, mse_new)\n",
    "                print(y_true[i])\n",
    "                print(pred[i])\n",
    "                print(cdf[i])\n",
    "                break\n",
    "            \n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importance(X, y, model, func, better='smaller', nrep=5): \n",
    "    perm = {}\n",
    "    pred = model.predict(X)\n",
    "    baseline = func(y, pred)\n",
    "    print('\\nPermutation Importance Baseline Score', baseline)\n",
    "    for i, c in enumerate(X.columns):\n",
    "        values = X[c].values.copy()\n",
    "        dtype = X[c].dtype.name\n",
    "        score = 0.0\n",
    "        for r in range(nrep):\n",
    "            X[c] = np.random.permutation(values)\n",
    "            X[c] = X[c].astype(dtype) \n",
    "            pred = model.predict(X)\n",
    "            score = score + func(y, pred)\n",
    "        if better=='smaller':\n",
    "            perm[c] = score/nrep - baseline\n",
    "        else:\n",
    "            perm[c] = baseline - score/nrep\n",
    "        X[c] = values.copy()\n",
    "        X[c] = X[c].astype(dtype) \n",
    "        print(f'{i} {perm[c]:11.8f} {c}')\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(perm, orient='index').reset_index()\n",
    "    df.columns = ['Feature','Perm']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature list and X_list assumed to be nested lists of same sizes, X_list contains numpy arrays\n",
    "def permutation_importance_list(feature_list, X_list, y, yardline, model, func, better='smaller', nrep=5): \n",
    "    perm = {}\n",
    "    p = model.predict(X_list)\n",
    "    p = mono(p)\n",
    "    pred = adjusty2(p, yardline, y_true=y)\n",
    "    baseline = func(y, pred)\n",
    "    print('\\npermutation importance baseline score', baseline)\n",
    "    for feat, X in zip(feature_list, X_list):\n",
    "        if len(feat) == 0: continue\n",
    "        for c, f in enumerate(feat):\n",
    "            values = X[...,c].copy()\n",
    "            score = 0.0\n",
    "            for r in range(nrep):\n",
    "                X[...,c] = np.random.permutation(values)\n",
    "                p = model.predict(X_list)\n",
    "                p = mono(p)\n",
    "                pred = adjusty2(p, yardline, y_true=y)\n",
    "                score = score + func(y, pred)\n",
    "            if better=='smaller':\n",
    "                perm[f] = score/nrep - baseline\n",
    "            else:\n",
    "                perm[f] = baseline - score/nrep\n",
    "            X[...,c] = values.copy()\n",
    "            print(f'{c} {perm[f]:.7f} {f}')\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(perm, orient='index').reset_index()\n",
    "    df.columns = ['Feature','Perm']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "import keras.backend as K\n",
    "def crps(y_true, y_pred):\n",
    "    loss = K.mean((K.cumsum(y_pred, axis = 1) - y_true)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/119400#latest-683614\n",
    "keras.backend.clear_session()\n",
    "\n",
    "def build_model(inp1, inp2, inp3, units=128, print_summary=False):\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    # inputs\n",
    "    inputs = keras.layers.Input(shape=(inp1,inp2,inp3))\n",
    "    \n",
    "    # 4D\n",
    "    x = keras.layers.Conv2D(128,(1,1),activation='relu')(inputs)\n",
    "    x = keras.layers.Conv2D(160,(1,1),activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(128,(1,1),activation='relu')(x)\n",
    "    a = keras.layers.AveragePooling2D(pool_size=(inp1,1))(x)\n",
    "    a = keras.layers.Lambda(lambda x1 : x1*0.7)(a)\n",
    "    m = keras.layers.MaxPooling2D(pool_size=(inp1,1))(x)\n",
    "    m = keras.layers.Lambda(lambda x1 : x1*0.3)(m)\n",
    "    x = keras.layers.Add()([a,m])\n",
    "    x = keras.layers.Reshape((inp2,units))(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # 3D\n",
    "    x = keras.layers.Conv1D(160,(1),activation='relu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv1D(96,(1),activation='relu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv1D(96,(1),activation='relu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    a = keras.layers.AveragePooling1D(pool_size=inp2)(x)\n",
    "    m = keras.layers.MaxPooling1D(pool_size=inp2)(x)\n",
    "    x = keras.layers.Average()([a,m])\n",
    "    x = keras.layers.Flatten()(x)\n",
    "\n",
    "    # 2D\n",
    "    x = keras.layers.Dense(96, activation='relu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "#     x = keras.layers.Dropout(0.05)(x)  \n",
    "    x = keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = keras.layers.Dense(num_class, activation='sigmoid')(x)\n",
    "#     x = keras.layers.Dense(num_class, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs = [inputs], outputs = [x])\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=2e-3, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "    \n",
    "#     model.compile(optimizer='adam', loss='mse')\n",
    "#     model.compile(optimizer='sgd', loss='mse')\n",
    "#     model.compile(optimizer='adam', loss=crps)\n",
    "    \n",
    "    if print_summary: print(model.summary())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d36f0551e963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-00161f4d3b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = df[::22].reset_index(drop=True)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if w_holdout:\n",
    "\n",
    "#     train_df['week'] = train_df.groupby('PossessionTeam')['GameId'].rank(method='dense')\n",
    "#     print(train_df['week'].describe())\n",
    "#     dfw = train_df[['GameId','week']][::22].copy().reset_index(drop=True)\n",
    "    y_pred = np.zeros((df.shape[0], 199)) \n",
    "\n",
    "#     if perm: nrepw = 1\n",
    "#     else: nrepw = 10\n",
    "    nrepw = 10\n",
    "    nepoch = 100\n",
    "    batch_size = 64\n",
    "    units = [199] * nrepw\n",
    "    max_depths = [5] * nrepw\n",
    "\n",
    "    ncores = multiprocessing.cpu_count()\n",
    "\n",
    "    if perm:\n",
    "        os.makedirs('imp',exist_ok=True)\n",
    "\n",
    "    # collect modeling results in these lists\n",
    "    models_nn = []\n",
    "    models_lgb = []\n",
    "    models_lgb_bi = []\n",
    "    models_tr_yc = []\n",
    "    models_w = []\n",
    "    models_h = []\n",
    "\n",
    "    ecdfs = []\n",
    "    escores = []\n",
    "    bscores = []\n",
    "    bscorew = []\n",
    "    bscorea = []\n",
    "    vscores = []\n",
    "\n",
    "    n = len(y1_train)\n",
    "    print('nn train shape', x4_train.shape)\n",
    "    # print('lgb train shape', X_train1.shape)\n",
    "    # nn_features = list(X_train0.columns)\n",
    "    # lgb_features = list(X_train1.columns)\n",
    "    os.makedirs('imp', exist_ok=True)\n",
    "    first = True\n",
    "\n",
    "    for nfold in [1]:\n",
    "\n",
    "        # kfold = KFold(n_splits=nfold, shuffle=False)\n",
    "\n",
    "        # kfold = GroupKFold(n_splits=K)\n",
    "        # groups = train_df['GameId'][::22]\n",
    "\n",
    "        # groups = 10 * train_df['Season'][::22] + train_df['Week'][::22]\n",
    "\n",
    "        # kfold = StratifiedKFold(n_splits = K, \n",
    "        #                             random_state = 231, \n",
    "        #                             shuffle = True)    \n",
    "\n",
    "\n",
    "        # full_val_preds = np.zeros((n))\n",
    "        full_val_preds = np.zeros((n,199))\n",
    "\n",
    "        # test_preds = np.zeros((np.shape(X_test)[0],K))\n",
    "\n",
    "        # for f, (f_ind, outf_ind) in enumerate(kfold.split(X_train, y_train)):\n",
    "        # for f, (f_ind, outf_ind) in enumerate(kfold.split(X_train, y_train, groups=groups)):\n",
    "        for f in range(nfold):\n",
    "#             f_ind = df[~df.week.between(30, 32)].index\n",
    "#             outf_ind = df[df.week.between(30, 32)].index\n",
    "            f_ind = df1[df1.GameId < 2019110000].index\n",
    "            outf_ind = df1[df1.GameId >= 2019110000].index\n",
    "            print(len(f_ind), len(outf_ind))\n",
    "\n",
    "            x4_train_f, x4_val_f = x4_train[f_ind].copy(), x4_train[outf_ind].copy()\n",
    "            y_train_f, y_val_f = y_train[f_ind], y_train[outf_ind]\n",
    "            y1_train_f, y1_val_f = y1_train[f_ind], y1_train[outf_ind]\n",
    "            y0_train_f, y0_val_f = y0_train[f_ind], y0_train[outf_ind]\n",
    "            y01_train_f, y01_val_f = y01_train[f_ind], y01_train[outf_ind]\n",
    "    #         sw_f = sw[f_ind] \n",
    "\n",
    "            # shuffle data\n",
    "            idx = np.arange(len(y_train_f))\n",
    "            np.random.shuffle(idx)\n",
    "        #     X_train_f = X_train_f[idx]\n",
    "            y_train_f = y_train_f[idx]\n",
    "            y1_train_f = y1_train_f[idx]\n",
    "            y0_train_f = y0_train_f[idx]\n",
    "            y01_train_f = y01_train_f[idx]\n",
    "            x4_train_f = x4_train_f[idx]\n",
    "        #     y_train_f = y_train_f.iloc[idx]\n",
    "\n",
    "            # track oof prediction for cv scores\n",
    "            val_preds = 0\n",
    "            vi = np.array([np.array([v*22 + i for i in range(22)]) for v in outf_ind]).flatten()\n",
    "            di = train.iloc[vi].copy()\n",
    "            di = di.reset_index(drop=True)\n",
    "\n",
    "            # ecdf, to be ensembled with nn prediction, kind of a cox neural net model\n",
    "            nt = len(y1_train_f)\n",
    "            nv = len(y1_val_f)\n",
    "            cf = cumfreq(y1_train_f, numbins=199, defaultreallimits=(-99,100))\n",
    "            ecdf = cf.cumcount / nt\n",
    "            ecdfs.append(ecdf)\n",
    "            ecdfr = ecdf.repeat(nv).reshape(199,nv).transpose()\n",
    "            escore = mean_squared_error(y0_val_f, ecdfr)\n",
    "\n",
    "            print('')\n",
    "            print('*'*10)\n",
    "            print(f'Fold {f+1}/{nfold}')\n",
    "            print('*'*10)\n",
    "\n",
    "            print('')\n",
    "            print(f'escore {escore:.6f}')\n",
    "            escores.append(escore)\n",
    "\n",
    "            for j in range(nrepw):\n",
    "\n",
    "                print('')\n",
    "                print(f'Rep {j+1}/{nrepw}')\n",
    "\n",
    "                model= build_model(x4_train.shape[1], x4_train.shape[2], x4_train.shape[3],\n",
    "                    print_summary=first)\n",
    "                if first: first = False\n",
    "\n",
    "                es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=2, \n",
    "                   patience=patience)\n",
    "                es.set_model(model)\n",
    "                \n",
    "                lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                                       patience=10, verbose=2, mode='min',\n",
    "                                                       min_delta=0.00001)\n",
    "                \n",
    "#                 oc = OneCycleLR(0.0005)\n",
    "\n",
    "                h = model.fit(x4_train_f, y_train_f, epochs=nepoch,\n",
    "                          # sample_weight=sw_f,\n",
    "                          # default batch_size is 32\n",
    "                          batch_size=batch_size,\n",
    "                          callbacks=[es, lr],\n",
    "                          # large batch sizes tend to perform poorly\n",
    "        #                   batch_size=2**(j+10),\n",
    "                          validation_data=(x4_val_f, y_val_f),\n",
    "                          verbose=2)\n",
    "\n",
    "                models_nn.append(model)\n",
    "#                 models_w.append(0.5 / len(fold_list) / nfold / nrep)\n",
    "                models_h.append(h)\n",
    "\n",
    "                vp = model.predict(x4_val_f)\n",
    "                vp = mono(vp)\n",
    "                vp = adjusty(vp, di, y0_val_f)\n",
    "                vs = mean_squared_error(y0_val_f,vp)\n",
    "                print(f'nn crps {vs:.6f}')\n",
    "\n",
    "#                 # lgb\n",
    "#                 # print('')\n",
    "#                 tr_data = lgb.Dataset(X_train_f1, label=y1_train_f)\n",
    "#                 vl_data = lgb.Dataset(X_val_f1, label=y1_val_f) \n",
    "#                 # vary max_depth with rep\n",
    "#                 lgb_params['max_depth'] = max_depths[j]\n",
    "#                 lgb_params['seed'] = 123 + j\n",
    "#                 clf = lgb.train(lgb_params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "#                                 num_boost_round=20000, early_stopping_rounds=100,\n",
    "#                                 verbose_eval=0)\n",
    "#                 models_lgb.append(clf)\n",
    "#                 models_lgb_bi.append(clf.best_iteration)\n",
    "\n",
    "#                 vpl = clf.predict(X_val_f1, num_iteration=clf.best_iteration)\n",
    "#                 # lgb cox model, shift ecdf so its median is at lgb point prediction\n",
    "#                 tr_yc = y1_train_f - np.median(y1_train_f)\n",
    "#                 models_tr_yc.append(tr_yc)\n",
    "#                 cl = Parallel(n_jobs=ncores)(delayed(gb_cox)(tr_yc,v) for v in vpl)\n",
    "#                 c = np.concatenate(cl).reshape(-1,num_class)\n",
    "#                 c = mono(c)\n",
    "#                 c = adjusty(c, di, y0_val_f)\n",
    "#                 print(f'lgb crps {mean_squared_error(y0_val_f,c):.6f}')\n",
    "\n",
    "#                 # nonnegative least squares to estimate ensemble weights\n",
    "#                 b = y0_val_f.flatten()\n",
    "#                 A = np.zeros((len(b),3))\n",
    "#                 A[:,0] = vp.flatten()\n",
    "#                 A[:,1] = c.flatten()\n",
    "#                 A[:,2] = ecdfr.flatten()\n",
    "#                 bestw = nnls(A,b)[0]\n",
    "#                 besta = np.matmul(A,bestw).reshape(-1,199)\n",
    "#                 besta = mono(besta)\n",
    "#                 besta = adjusty(besta, di, y0_val_f, reduced=False)\n",
    "#                 bscore = bests = mean_squared_error(y0_val_f, besta)\n",
    "\n",
    "#                 # print('')        \n",
    "#                 print(f'bscore {bests:.6f} {bestw}')\n",
    "#                 bscores.append(bests)\n",
    "#                 bscorew.append(bestw)\n",
    "#                 bscorea.append(besta)\n",
    "\n",
    "#                 val_preds += besta / nrepw\n",
    "\n",
    "                bscores.append(vs)\n",
    "                val_preds += vp / nrepw\n",
    "\n",
    "                # test_preds[:,f] += model.predict(proc_X_test_f)[:,0] / nrep\n",
    "\n",
    "\n",
    "                if perm:\n",
    "                    ff = str(nfold) + '_' + str(f+1)\n",
    "                    \n",
    "#                     feature_imp = pd.DataFrame(zip(lgb_features, clf.feature_importance(),\n",
    "#                                                    clf.feature_importance(importance_type='gain')),\n",
    "#                                                    columns=['Feature','Splits'+ff,'Gain'+ff])\n",
    "                    \n",
    "#                     perm_imp = permutation_importance(X_val_f1,\n",
    "#                                                       y1_val_f, clf,\n",
    "#                                                       mean_absolute_error)\n",
    "#                     perm_imp.columns = ['Feature','Perm'+ff]\n",
    "#                     feature_imp = feature_imp.merge(perm_imp, how='left', on='Feature')\n",
    "\n",
    "                    yardline = train_df['YardLine'][::22].values - 10\n",
    "                    perm_imp = permutation_importance_list([list(od.columns)],\n",
    "                                                           [x4_val_f],\n",
    "                                                           y0_val_f, yardline[outf_ind],\n",
    "                                                           model, mean_squared_error)\n",
    "\n",
    "#                     perm_imp = permutation_importance(X_val_f0,\n",
    "#                                                       y_val_f, model,\n",
    "#                                                       mean_squared_error)\n",
    "\n",
    "                    perm_imp.columns = ['Feature','PermNN'+ff]\n",
    "                    perm_imp = perm_imp.sort_values(by='PermNN'+ff, ascending=False).reset_index(drop=True)\n",
    "                    print()\n",
    "                    print(perm_imp.head(n=50))\n",
    "#                     print()\n",
    "#                     print(perm_imp.tail(n=50))\n",
    "    \n",
    "                    # feature_imp = feature_imp.merge(perm_imp, how='left', on='Feature')\n",
    "\n",
    "#                     feature_imp.sort_values(by='Splits'+ff, inplace=True, ascending=False)\n",
    "#                     print('')\n",
    "#                     print(feature_imp.head(n=10))\n",
    "\n",
    "#                     feature_imp.sort_values(by='Gain'+ff, inplace=True, ascending=False)\n",
    "#                     print('')\n",
    "#                     print(feature_imp.head(n=10))\n",
    "\n",
    "#                     feature_imp.sort_values(by='Perm'+ff, inplace=True, ascending=False)\n",
    "#                     print('')\n",
    "#                     print(feature_imp.head(n=15))\n",
    "\n",
    "#                     feature_imp.sort_values(by='PermNN'+ff, inplace=True, ascending=False)\n",
    "#                     print('')\n",
    "#                     print(feature_imp.head(n=15))\n",
    "\n",
    "#                     print(feature_imp.shape)\n",
    "\n",
    "#                     fname = 'imp/' + mname + '_imp' + ff + '.csv'\n",
    "#                     perm_imp.to_csv(fname, index=False)\n",
    "#                     print(fname, feature_imp.shape)\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "            val_preds = mono(val_preds)\n",
    "            val_preds = adjusty(val_preds, di, y0_val_f, reduced=False)\n",
    "            full_val_preds[outf_ind] += val_preds\n",
    "            vscore = mean_squared_error(y0_val_f, val_preds)\n",
    "            print(f'\\nvscore {vscore:.6f}')\n",
    "            vscores.append(vscore)\n",
    "\n",
    "        #     if f == 0: break\n",
    "\n",
    "        nfh = int(np.ceil(nfold / 2))\n",
    "        nfq = int(np.ceil(nfold / 4))\n",
    "\n",
    "        print('')\n",
    "        print(f'\\nAll bscores {np.array(bscores)}')\n",
    "        print('Mean bscores: %.6f' % np.mean(bscores))\n",
    "        print('Mean vscores: %.6f' % np.mean(vscores))\n",
    "    #         print('Mean vscores last half: %.6f' % np.mean(vscores[-nfh:]))\n",
    "    #         print('Mean vscores last quar: %.6f' % np.mean(vscores[-nfq:]))\n",
    "    #     print('Mean ecdf weights last half: %.6f' % np.mean(bscorew[-nfh*nrep:]))\n",
    "    #     print('Mean ecdf weights last quar: %.6f' % np.mean(bscorew[-nfq*nrep:]))\n",
    "#         print(f'\\nAll bscores {np.array(bscores)}')\n",
    "        # print(f'\\nAll vscores {np.array(vscores)}')\n",
    "#         print(f'\\nAll lgb iters {np.array(models_lgb_bi)}')\n",
    "#         print(f'\\nAll ecdf weights {bscorew}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
