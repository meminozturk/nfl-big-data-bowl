{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from kaggle.competitions import nflrush\n",
    "\n",
    "import io\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import multiprocessing\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import keras\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from keras import backend as F\n",
    "from keras import initializers\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.engine.saving import load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Input, Lambda, BatchNormalization, Dropout, Add, Concatenate\n",
    "from keras.models import Model \n",
    "from keras.optimizers import SGD, Adam,adam\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import lightgbm as lgb\n",
    "from scipy.spatial import Voronoi\n",
    "from shapely.geometry import Polygon\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    F.set_session(sess)\n",
    "    \n",
    "# fix_seeds(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "__all__ = ['RAdam']\n",
    "\n",
    "class RAdam(keras.optimizers.Optimizer):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    # Arguments\n",
    "        learning_rate: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay for each param.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n",
    "        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n",
    "        min_lr: float >= 0. Minimum learning rate after warmup.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n",
    "                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n",
    "        learning_rate = kwargs.pop('lr', learning_rate)\n",
    "        super(RAdam, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.total_steps = K.variable(total_steps, name='total_steps')\n",
    "            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n",
    "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.initial_weight_decay = weight_decay\n",
    "        self.initial_total_steps = total_steps\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        if self.initial_total_steps > 0:\n",
    "            warmup_steps = self.total_steps * self.warmup_proportion\n",
    "            decay_steps = K.maximum(self.total_steps - warmup_steps, 1)\n",
    "            decay_rate = (self.min_lr - lr) / decay_steps\n",
    "            lr = K.switch(\n",
    "                t <= warmup_steps,\n",
    "                lr * (t / warmup_steps),\n",
    "                lr + decay_rate * K.minimum(t - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        else:\n",
    "            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        beta_1_t = K.pow(self.beta_1, t)\n",
    "        beta_2_t = K.pow(self.beta_2, t)\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            m_corr_t = m_t / (1.0 - beta_1_t)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t))\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t))\n",
    "\n",
    "            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                         (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                         sma_inf / sma_t)\n",
    "\n",
    "            p_t = K.switch(sma_t >= 5, r_t * m_corr_t / (v_corr_t + self.epsilon), m_corr_t)\n",
    "\n",
    "            if self.initial_weight_decay > 0:\n",
    "                p_t += self.weight_decay * p\n",
    "\n",
    "            p_t = p - lr * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self.learning_rate\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'learning_rate': float(K.get_value(self.learning_rate)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'decay': float(K.get_value(self.decay)),\n",
    "            'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': float(K.get_value(self.total_steps)),\n",
    "            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "        }\n",
    "        base_config = super(RAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(Callback):\n",
    "    def __init__(self, model, callbacks, data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.callbacks = callbacks\n",
    "        self.data = data\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end(logs)\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        X_train, y_train = self.data[0][0], self.data[0][1]\n",
    "        y_pred = self.model.predict(X_train)\n",
    "        y_true = np.clip(np.cumsum(y_train, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        tr_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_train.shape[0])\n",
    "        logs['tr_CRPS'] = tr_s\n",
    "\n",
    "        X_valid, y_valid = self.data[1][0], self.data[1][1]\n",
    "\n",
    "        y_pred = self.model.predict(X_valid)\n",
    "        y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "        logs['val_CRPS'] = val_s\n",
    "        print('tr CRPS', tr_s, 'val CRPS', val_s)\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(batch, logs)\n",
    "\n",
    "class Gambler():\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "    def construct_model(self):\n",
    "        # opm = Adam(learning_rate=0.0001)\n",
    "        opm = RAdam(warmup_proportion=0.1, min_lr=1e-4)\n",
    "        my_init = initializers.glorot_uniform(seed=2019)\n",
    "        model = Sequential([\n",
    "            Dense(512, input_shape=(self.input_size,),kernel_initializer=my_init),\n",
    "            keras.layers.LeakyReLU(0.25),\n",
    "            keras.layers.Dropout(0.50,seed=2019),\n",
    "            Dense(128, input_shape=(self.input_size,),kernel_initializer=my_init),\n",
    "            keras.layers.LeakyReLU(0.25),\n",
    "            keras.layers.Dropout(0.50,seed=2019),\n",
    "            Dense(64,kernel_initializer=my_init),\n",
    "            keras.layers.LeakyReLU(0.25),\n",
    "            keras.layers.Dropout(0.50,seed=2019),\n",
    "            Dense(199,kernel_initializer=my_init),\n",
    "            Activation('softmax'),\n",
    "        ],)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',optimizer=opm,metrics=[])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, X_valid, y_train, y_valid, fold):\n",
    "        self.models[fold] = self.construct_model()\n",
    "\n",
    "        self.scalers[fold] = StandardScaler()\n",
    "        X_train = self.scalers[fold].fit_transform(X_train)\n",
    "        X_valid = self.scalers[fold].transform(X_valid)\n",
    "\n",
    "        es = EarlyStopping(monitor='val_CRPS',mode='min',restore_best_weights=True,verbose=1,patience=11)\n",
    "        es.set_model(self.models[fold])\n",
    "        metric = Metric(self.models[fold], [es], [(X_train, y_train), (X_valid, y_valid)])\n",
    "        self.models[fold].fit(X_train, y_train,verbose=0,callbacks=[metric],epochs=1000, batch_size=128)\n",
    "\n",
    "    def predict(self, X, fold):\n",
    "        X = self.scalers[fold].transform(X)\n",
    "        preds = self.models[fold].predict(X)\n",
    "        return preds\n",
    "    \n",
    "    def predict_final(self, X):\n",
    "        final = None\n",
    "        for fold in self.models.keys():\n",
    "            preds = self.predict(X, fold)\n",
    "            if final is None:\n",
    "                final = preds / (len(self.models.keys()))\n",
    "            else:\n",
    "                final += preds / (len(self.models.keys()))\n",
    "        return final\n",
    "\n",
    "def train_loop(gambler, df, num_folds,useful_raw_features,cv=\"cv\"):    \n",
    "    if cv == \"cv\":\n",
    "        spliter = KFold(n_splits=num_folds, random_state=2019, shuffle = True)\n",
    "        oof_predictions = np.zeros((df.shape[0], 199))\n",
    "        oof_targets = np.zeros((df.shape[0], 199))\n",
    "        oof_ids = np.zeros(df.shape[0])\n",
    "        fold = 0\n",
    "        for train_index, valid_index in spliter.split(df):\n",
    "            print('### Fold', fold+1, '###')\n",
    "            dataset_train = df.loc[train_index].copy()\n",
    "            dataset_valid = df.loc[valid_index].copy()\n",
    "\n",
    "            # dataset_train = pd.concat([dataset_train,fake_df[fake_df.PlayId.isin(dataset_train.PlayId)]],axis=0)\n",
    "            X_train = dataset_train[useful_raw_features].copy().fillna(-10)\n",
    "            X_valid = dataset_valid[useful_raw_features].copy().fillna(-10)\n",
    "\n",
    "            # get targets\n",
    "            targets = dataset_train['Yards']\n",
    "            y_train = np.zeros((targets.shape[0], 199))\n",
    "            for idx, target in enumerate(list(targets)):\n",
    "                y_train[idx][99 + target] = 1\n",
    "\n",
    "            targets = dataset_valid['Yards']\n",
    "            y_valid = np.zeros((targets.shape[0], 199))\n",
    "            for idx, target in enumerate(list(targets)):\n",
    "                y_valid[idx][99 + target] = 1\n",
    "\n",
    "            gambler.train(X_train, X_valid, y_train, y_valid, fold)\n",
    "\n",
    "            oof_pred = gambler.predict(X_valid, fold)\n",
    "            oof_pred = np.clip(np.cumsum(oof_pred, axis=1), 0, 1)\n",
    "            oof_predictions[valid_index] = oof_pred\n",
    "            \n",
    "            y_valid = np.clip(np.cumsum(y_valid, axis=1), 0, 1)            \n",
    "            oof_targets[valid_index] = y_valid\n",
    "            oof_ids[valid_index] = dataset_valid['PlayId'].values\n",
    "\n",
    "            oof_score = ((oof_pred - y_valid) ** 2).sum(axis=1).sum(axis=0) / (199 * y_valid.shape[0])\n",
    "            print(f'Fold {fold+1} score', oof_score)\n",
    "            fold += 1  \n",
    "            \n",
    "        oof_score = ((oof_predictions - oof_targets) ** 2).sum(axis=1).sum(axis=0) / (199 * oof_targets.shape[0])\n",
    "        print(f'OOF Score', oof_score)\n",
    "        \n",
    "    elif cv == \"split\":\n",
    "        dataset_train, dataset_valid = train_test_split(df, test_size=0.1, random_state=2019)\n",
    "        X_train = dataset_train[useful_raw_features].copy().fillna(-10)\n",
    "        X_valid = dataset_valid[useful_raw_features].copy().fillna(-10)\n",
    "\n",
    "        # get targets\n",
    "        targets = dataset_train['Yards']\n",
    "        y_train = np.zeros((targets.shape[0], 199))\n",
    "        for idx, target in enumerate(list(targets)):\n",
    "            y_train[idx][99 + target] = 1\n",
    "\n",
    "        targets = dataset_valid['Yards']\n",
    "        y_valid = np.zeros((targets.shape[0], 199))\n",
    "        for idx, target in enumerate(list(targets)):\n",
    "            y_valid[idx][99 + target] = 1\n",
    "\n",
    "        gambler.train(X_train, X_valid, y_train, y_valid, 0)\n",
    "        oof_pred = gambler.predict(X_valid, 0)        \n",
    "        oof_pred = np.clip(np.cumsum(oof_pred, axis=1), 0, 1)\n",
    "        oof_predictions = oof_pred.copy()\n",
    "        \n",
    "        oof_ids = dataset_valid['PlayId'].values    \n",
    "        y_valid = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "        oof_targets = y_valid\n",
    "        \n",
    "        oof_score = ((oof_pred - y_valid) ** 2).sum(axis=1).sum(axis=0) / (199 * y_valid.shape[0])\n",
    "        print(f'OOF Score', oof_score)\n",
    "        \n",
    "    else:\n",
    "        games = df[['GameId', 'PossessionTeam']].drop_duplicates()\n",
    "\n",
    "        # Sort so the latest games are first and label the games with cumulative counter\n",
    "        games = games.sort_values(['PossessionTeam', 'GameId'], ascending=[True, False])\n",
    "        games['row_number'] = games.groupby(['PossessionTeam']).cumcount() + 1\n",
    "\n",
    "        # Use last 5 games for each team as validation. There will be overlap since two teams will have the same\n",
    "        game_set = set([1, 2, 3, 4, 5])\n",
    "\n",
    "        # Set of unique game ids\n",
    "        game_ids = set(games[games['row_number'].isin(game_set)]['GameId'].unique().tolist())\n",
    "\n",
    "        dataset_train = df[~df['GameId'].isin(game_ids)]\n",
    "        dataset_valid = df[df['GameId'].isin(game_ids)]\n",
    "\n",
    "        X_train = dataset_train[useful_raw_features].copy().fillna(-10)\n",
    "        X_valid = dataset_valid[useful_raw_features].copy().fillna(-10)\n",
    "\n",
    "        # get targets\n",
    "        targets = dataset_train['Yards']\n",
    "        y_train = np.zeros((targets.shape[0], 199))\n",
    "        for idx, target in enumerate(list(targets)):\n",
    "            y_train[idx][99 + target] = 1\n",
    "\n",
    "        targets = dataset_valid['Yards']\n",
    "        y_valid = np.zeros((targets.shape[0], 199))\n",
    "        for idx, target in enumerate(list(targets)):\n",
    "            y_valid[idx][99 + target] = 1\n",
    "\n",
    "        gambler.train(X_train, X_valid, y_train, y_valid, 0)\n",
    "        oof_pred = gambler.predict(X_valid, 0)        \n",
    "        oof_pred = np.clip(np.cumsum(oof_pred, axis=1), 0, 1)\n",
    "        oof_predictions = oof_pred.copy()\n",
    "\n",
    "        oof_ids = dataset_valid['PlayId'].values    \n",
    "        y_valid = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "        oof_targets = y_valid\n",
    "\n",
    "        oof_score = ((oof_pred - y_valid) ** 2).sum(axis=1).sum(axis=0) / (199 * y_valid.shape[0])\n",
    "        print(f'OOF Score', oof_score)\n",
    "\n",
    "    return oof_ids, oof_predictions, oof_targets\n",
    "\n",
    "def encode_ohe(df, features):\n",
    "    df[features] = df[features].fillna('missing')\n",
    "    df = pd.get_dummies(df,columns = features, drop_first = True)\n",
    "    return df\n",
    "\n",
    "def generate_categorical_encoders(train, features):\n",
    "    encoders = {}\n",
    "    for feature in features:\n",
    "        train[feature] = train[feature].fillna('missing')\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(train[feature].values)\n",
    "        le_dict = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "        encoders[feature] = le_dict\n",
    "    return encoders\n",
    "\n",
    "def encode_categorical_features(df, features, encoders):\n",
    "    for f in features:\n",
    "        df[f] = df[f].fillna('missing')\n",
    "        df[f] = df[f].map(encoders[f])\n",
    "\n",
    "def aggreate_by_play(df, configs):\n",
    "    df = df.sort_values('PlayId')\n",
    "    agg_df = pd.DataFrame({'PlayId': list(df['PlayId'].unique())}).sort_values('PlayId')\n",
    "    # TODO aggerate with a sliding window\n",
    "    for config in configs:\n",
    "        feature = config[0]\n",
    "        if feature == 'PlayId' or feature not in df.columns:\n",
    "            continue\n",
    "        gy = df.groupby('PlayId')\n",
    "        gy_team = df.groupby(['PlayId','IsOnOffense'])\n",
    "        if 'team' in config[2]:\n",
    "            for agg_func in config[2]:                \n",
    "                if agg_func == 'team':\n",
    "                    continue\n",
    "                elif agg_func == 'first':\n",
    "                    agg_df[feature+\"_def\"] = gy_team[feature].agg(agg_func)[::2].values\n",
    "                    agg_df[feature+\"_off\"] = gy_team[feature].agg(agg_func)[1::2].values\n",
    "                else:\n",
    "                    agg_df[f'{feature}_{agg_func}_def'] = gy_team[feature].agg(agg_func)[::2].values\n",
    "                    agg_df[f'{feature}_{agg_func}_off'] = gy_team[feature].agg(agg_func)[1::2].values\n",
    "        else:\n",
    "            for agg_func in config[2]:\n",
    "                if agg_func == 'first':\n",
    "                    agg_df[feature] = gy[feature].agg(agg_func).values\n",
    "                else:\n",
    "                    agg_df[f'{feature}_{agg_func}'] = gy[feature].agg(agg_func).values\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoldenTimer:\n",
    "    def __init__(self, show=True):\n",
    "        self.start_time = time.time()\n",
    "        self.show = show\n",
    "\n",
    "    def time(self, print_str):\n",
    "        duration = time.time() - self.start_time\n",
    "        if self.show:\n",
    "            print(print_str, duration)\n",
    "        self.start_time = time.time()\n",
    "\n",
    "\n",
    "class FeatureFactory:\n",
    "    def __init__(self, cat_dict):\n",
    "        self.cat_dict = cat_dict\n",
    "    \n",
    "    def make_feats(self, df_, show=False):\n",
    "        timer = GoldenTimer(show)\n",
    "        df = self.adjust_sa(df_)\n",
    "        emil_df = self.get_emil_feats(df.copy())\n",
    "        timer.time(\"done emil feats\")\n",
    "        df = self.get_future_pos(df)\n",
    "        df = self.get_dist(df)\n",
    "        timer.time(\"done dist\")\n",
    "        rush_df = df[df[\"NflIdRusher\"] == df[\"NflId\"]].copy()\n",
    "        rush_df = self.get_closest_feat(df, rush_df)\n",
    "        rush_df = self.get_centroid_feat(df, rush_df)\n",
    "        rush_df = self.get_free_width(df, rush_df)\n",
    "        rush_df = self.get_proper_field_position(rush_df)\n",
    "        rush_df = self.get_season(rush_df)\n",
    "        rush_df = self.get_proper_yard(rush_df)\n",
    "        rush_df = self.get_direction(rush_df)\n",
    "        rush_df = self.do_cat(rush_df)\n",
    "        timer.time(\"done rush feats \")\n",
    "        rush_df = pd.merge(rush_df, emil_df, on=\"PlayId\", how=\"inner\")\n",
    "        return rush_df\n",
    "    \n",
    "    def get_emil_feats(self, df):\n",
    "        df = self.prep_df(df)\n",
    "        df = self.adjust_sa(df)        \n",
    "        df = self.make_emil_feats(df)\n",
    "        return df\n",
    "    \n",
    "    def adjust_sa(self, df):\n",
    "        mean_old, mean_new, std_old, std_new = 2.435519556913685, 2.7570316419451517, 1.2929623410155855, 1.4551321358655551\n",
    "        df[\"S\"] = np.where(df[\"Season\"] >= 2018, (df[\"S\"]-mean_new) / std_new * std_old + mean_old, df[\"S\"])\n",
    "        mean_old, mean_new, std_old, std_new = 1.5895792207792045, 1.7819953460610594, 0.8795106467756848, 1.060305722313926\n",
    "        df[\"A\"] = np.where(df[\"Season\"] >= 2018, (df[\"A\"]-mean_new) / std_new * std_old + mean_old, df[\"A\"])\n",
    "        return df\n",
    "\n",
    "    def get_future_pos(self, df):\n",
    "        df[\"dxdy_dir\"] = (540 - (df[\"Dir\"] + 90)) % 360\n",
    "        df[\"dy\"] = np.sin(np.deg2rad(df[\"dxdy_dir\"]))\n",
    "        df[\"dx\"] = np.cos(np.deg2rad(df[\"dxdy_dir\"]))\n",
    "        df[\"nextX\"] = df[\"X\"] + (df[\"dx\"] * (df[\"S\"]))\n",
    "        df[\"nextY\"] = df[\"Y\"] + (df[\"dy\"] * (df[\"S\"]))\n",
    "        df[\"nextX2\"] = df[\"X\"] + (df[\"dx\"] * (df[\"S\"]*2))\n",
    "        df[\"nextY2\"] = df[\"Y\"] + (df[\"dy\"] * (df[\"S\"]*2))\n",
    "        return df\n",
    "\n",
    "    def get_dist(self, df):\n",
    "        merge_rush = df[df[\"NflIdRusher\"] == df[\"NflId\"]].copy()\n",
    "        merge_col = [\n",
    "            \"PlayId\", \"Team\", \"X\", \"Y\", \"nextX\", \"nextY\", \"nextX2\", \"nextY2\"\n",
    "        ]\n",
    "        merge_rush = merge_rush[merge_col]\n",
    "        merge_rush.columns = [\n",
    "            \"PlayId\", \"rush_team\", \"rush_X\", \"rush_Y\",\n",
    "            \"rush_nextX\", \"rush_nextY\", \"rush_nextX2\", \"rush_nextY2\"\n",
    "        ]\n",
    "        ret_df = pd.merge(df, merge_rush, on=\"PlayId\", how=\"left\")\n",
    "        \n",
    "        ret_df[\"dist\"] = (ret_df[\"X\"] - ret_df[\"rush_X\"]) ** 2 + (ret_df[\"Y\"] - ret_df[\"rush_Y\"]) ** 2\n",
    "        ret_df[\"dist\"] = ret_df[\"dist\"] ** 0.5\n",
    "        ret_df[\"dist2\"] = (ret_df[\"X\"] - ret_df[\"rush_nextX\"]) ** 2 + (ret_df[\"Y\"] - ret_df[\"rush_nextY\"]) ** 2\n",
    "        ret_df[\"dist2\"] = ret_df[\"dist2\"] ** 0.5\n",
    "        ret_df[\"dist3\"] = (ret_df[\"nextX\"] - ret_df[\"rush_nextX\"]) ** 2 + (ret_df[\"nextY\"] - ret_df[\"rush_nextY\"]) ** 2\n",
    "        ret_df[\"dist3\"] = ret_df[\"dist3\"] ** 0.5        \n",
    "        ret_df[\"dist4\"] = (ret_df[\"nextX2\"] - ret_df[\"rush_nextX2\"]) ** 2 + (ret_df[\"nextY2\"] - ret_df[\"rush_nextY2\"]) ** 2\n",
    "        ret_df[\"dist4\"] = ret_df[\"dist4\"] ** 0.5\n",
    "        ret_df[\"tt_dist\"] = (ret_df[\"dist\"] / ret_df[\"S\"]).clip(upper=20)\n",
    "        ret_df[\"tt_dist2\"] = (ret_df[\"dist2\"] / ret_df[\"S\"]).clip(upper=20)\n",
    "        ret_df[\"tt_dist3\"] = (ret_df[\"dist3\"] / ret_df[\"S\"]).clip(upper=20)\n",
    "        ret_df[\"tt_dist4\"] = (ret_df[\"dist4\"] / ret_df[\"S\"]).clip(upper=20)\n",
    "        ret_df[\"dist3l1\"] = ((ret_df[\"nextX\"]-ret_df[\"rush_nextX\"])**2 + (ret_df[\"nextY\"]+1-ret_df[\"rush_nextY\"])**2)**0.5\n",
    "        ret_df[\"dist3r1\"] = ((ret_df[\"nextX\"]-ret_df[\"rush_nextX\"])**2 + (ret_df[\"nextY\"]-1-ret_df[\"rush_nextY\"])**2)**0.5\n",
    "        ret_df[\"dist3l3\"] = ((ret_df[\"nextX\"]-ret_df[\"rush_nextX\"])**2 + (ret_df[\"nextY\"]+3-ret_df[\"rush_nextY\"])**2)**0.5\n",
    "        ret_df[\"dist3r3\"] = ((ret_df[\"nextX\"]-ret_df[\"rush_nextX\"])**2 + (ret_df[\"nextY\"]-3-ret_df[\"rush_nextY\"])**2)**0.5\n",
    "\n",
    "        defense_team_df = ret_df[ret_df[\"Team\"] != ret_df[\"rush_team\"]]\n",
    "        dist_keys = [\"dist\", \"dist2\", \"dist3\", \"dist4\"]\n",
    "        tt_keys = [\"tt_dist\", \"tt_dist2\", \"tt_dist3\", \"tt_dist4\"]\n",
    "        temp_df = self._get_dist_feat(defense_team_df, dist_keys, tt_keys)\n",
    "        ret_df, temp_df1 = self._get_mark_dist(ret_df)\n",
    "        temp_df2 = self._get_side_step_dist(defense_team_df)\n",
    "        temp_df = pd.merge(temp_df, temp_df1, on=\"PlayId\", how=\"left\")\n",
    "        temp_df = pd.merge(temp_df, temp_df2, on=\"PlayId\", how=\"left\")\n",
    "        ret_df = pd.merge(ret_df, temp_df, on=\"PlayId\", how=\"left\")\n",
    "        return ret_df\n",
    "    \n",
    "    def _get_dist_feat(self, defense_team_df, dist_keys, tt_keys):\n",
    "        aggs = dict()\n",
    "        for k in dist_keys:\n",
    "            aggs[k] = [\"min\", \"mean\", \"std\"]\n",
    "        for k in tt_keys:\n",
    "            aggs[k] = [\"min\", \"mean\"]\n",
    "        temp_df = defense_team_df.groupby(\"PlayId\").agg(aggs).reset_index()\n",
    "        \n",
    "        cols = [\"PlayId\"]\n",
    "        for k in dist_keys:\n",
    "            cols += [f\"min_df_{k}\", f\"mean_df_{k}\", f\"std_df_{k}\"]\n",
    "        for k in tt_keys:\n",
    "            cols += [f\"min_{k}\", f\"mean_{k}\"]\n",
    "        temp_df.columns = cols\n",
    "        return temp_df\n",
    "    \n",
    "    def _get_mark_dist(self, df):\n",
    "        df[\"index\"] = df.index\n",
    "        df[\"player_idx\"] = df.groupby([\"PlayId\", \"Team\"])[\"index\"].agg([\"rank\"])\n",
    "        temp_df = None\n",
    "        for i in range(1, 12):\n",
    "            mask = (df[\"Team\"] == df[\"rush_team\"]) & (df[\"player_idx\"] == i)\n",
    "            temp = df[mask]\n",
    "            temp = temp[[\"PlayId\", \"X\", \"Y\"]]\n",
    "            temp.columns = [\"PlayId\", f\"of{i}_X\", f\"of{i}_Y\"]\n",
    "            if temp_df is None:\n",
    "                temp_df = temp\n",
    "            else:\n",
    "                temp_df = pd.merge(temp_df, temp, on=\"PlayId\", how=\"left\")\n",
    "        df = pd.merge(df, temp_df, on=[\"PlayId\"], how=\"left\")\n",
    "        for i in range(1, 12):\n",
    "            df[f\"of{i}_dist\"] = ((df[\"X\"] - df[f\"of{i}_X\"])**2 + (df[\"Y\"] - df[f\"of{i}_Y\"])**2) ** 0.5\n",
    "        agg_col = [f\"of{i}_dist\" for i in range(1, 12)]\n",
    "        df[\"closest_of_dist\"] = np.min(df[agg_col], axis=1)\n",
    "        df[\"closest_of_index\"] = np.argmin(df[agg_col].values, axis=1) + 1\n",
    "        df[\"closest_of_X\"] = 0\n",
    "        df[\"closest_of_Y\"] = 0\n",
    "        for i in range(1, 12):\n",
    "            df[\"closest_of_X\"] = np.where(df[\"closest_of_index\"] == i, df[f\"of{i}_X\"], df[\"closest_of_X\"])\n",
    "            df[\"closest_of_Y\"] = np.where(df[\"closest_of_index\"] == i, df[f\"of{i}_Y\"], df[\"closest_of_Y\"])\n",
    "        df[\"mark_dist\"] = ((df[\"closest_of_X\"]-df[\"rush_X\"])**2 + (df[\"closest_of_Y\"]-df[\"rush_Y\"])**2)**0.5\n",
    "        df[\"is_blocked\"] = np.where(df[\"mark_dist\"] < df[\"dist\"], 1, 0)\n",
    "        \n",
    "        mask = (df[\"Team\"] != df[\"rush_team\"]) & (df[\"is_blocked\"] == 0)\n",
    "        unblocked_defense_team_df = df[mask]\n",
    "        aggs = {\n",
    "            \"dist3\": [\"min\"],\n",
    "            \"dist4\": [\"min\"],\n",
    "        }\n",
    "        temp_df = unblocked_defense_team_df.groupby(\"PlayId\").agg(aggs).reset_index()\n",
    "        cols = [\"PlayId\", \"min_unblocked_dist3\", \"min_unblocked_dist4\",]\n",
    "        temp_df.columns = cols\n",
    "\n",
    "        mask = (df[\"Team\"] != df[\"rush_team\"]) & (df[\"is_blocked\"] == 1)\n",
    "        blocked_defense_team_df = df[mask]\n",
    "        aggs = {\n",
    "            \"dist3\": [\"min\"],\n",
    "        }\n",
    "        temp_df2 = blocked_defense_team_df.groupby(\"PlayId\").agg(aggs).reset_index()\n",
    "        cols = [\"PlayId\", \"min_blocked_dist3\"]\n",
    "        temp_df2.columns = cols\n",
    "        temp_df = pd.merge(temp_df, temp_df2, on=\"PlayId\", how=\"left\")\n",
    "        return df, temp_df\n",
    "    \n",
    "    def _get_side_step_dist(self, defense_team_df):\n",
    "        aggs = {\n",
    "            \"dist3\": [\"mean\"],\n",
    "            \"dist3l1\": [\"mean\"], \"dist3r1\": [\"mean\"],\n",
    "            \"dist3l3\": [\"mean\"], \"dist3r3\": [\"mean\"],\n",
    "        }\n",
    "        temp_df = defense_team_df.groupby(\"PlayId\").agg(aggs).reset_index()\n",
    "        temp_df.columns = [\n",
    "            \"PlayId\", \"mean_df_dist3\", \"mean_df_dist3l1\",\"mean_df_dist3r1\",\n",
    "            \"mean_df_dist3l3\",\"mean_df_dist3r3\"\n",
    "        ]\n",
    "        temp_df[\"mean_diff_dist3l\"] = np.abs(temp_df[\"mean_df_dist3\"] - temp_df[\"mean_df_dist3l1\"])\n",
    "        temp_df[\"mean_diff_dist3r\"] = np.abs(temp_df[\"mean_df_dist3\"] - temp_df[\"mean_df_dist3r1\"])\n",
    "        temp_df[\"mean_dist3_diffmax1\"] = np.max(temp_df[[\"mean_diff_dist3l\", \"mean_diff_dist3r\"]], axis=1)\n",
    "        temp_df[\"mean_dist3_diffmin1\"] = np.min(temp_df[[\"mean_diff_dist3l\", \"mean_diff_dist3r\"]], axis=1)\n",
    "        temp_df[\"mean_diff_dist3l\"] = np.abs(temp_df[\"mean_df_dist3\"] - temp_df[\"mean_df_dist3l3\"])\n",
    "        temp_df[\"mean_diff_dist3r\"] = np.abs(temp_df[\"mean_df_dist3\"] - temp_df[\"mean_df_dist3r3\"])\n",
    "        temp_df[\"mean_dist3_diffmax3\"] = np.max(temp_df[[\"mean_diff_dist3l\", \"mean_diff_dist3r\"]], axis=1)\n",
    "        temp_df[\"mean_dist3_diffmin3\"] = np.min(temp_df[[\"mean_diff_dist3l\", \"mean_diff_dist3r\"]], axis=1)\n",
    "        merge_col = [\"PlayId\", \"mean_dist3_diffmax1\", \"mean_dist3_diffmin1\", \"mean_dist3_diffmax3\", \"mean_dist3_diffmin3\"]\n",
    "        temp_df = temp_df[merge_col]\n",
    "        return temp_df\n",
    "    \n",
    "    def get_closest_feat(self, df, rush_df):\n",
    "        closest_df = df[df[\"min_df_dist\"] == df[\"dist\"]]\n",
    "        use_col = [\"PlayId\", \"S\", \"A\", \"closest_of_dist\", \"dist3\"]\n",
    "        closest_df = closest_df[use_col]\n",
    "        closest_df.columns = [\"PlayId\", \"closest_S\", \"closest_A\", \"closest_mark_dist\", \"closest_next_dist\"]\n",
    "        ret_df = pd.merge(rush_df, closest_df, on=\"PlayId\", how=\"left\")\n",
    "        \n",
    "        closest_df = df[df[\"min_df_dist3\"] == df[\"dist3\"]]\n",
    "        use_col = [\"PlayId\", \"S\", \"A\", \"dist\"]\n",
    "        closest_df = closest_df[use_col]\n",
    "        closest_df.columns = [\"PlayId\", \"closest3_S\", \"closest3_A\", \"closest3_prev_dist\"]\n",
    "        ret_df = pd.merge(ret_df, closest_df, on=\"PlayId\", how=\"left\")\n",
    "        return ret_df\n",
    "    \n",
    "    def get_centroid_feat(self, df, rush_df):\n",
    "        defense_team_df = df[df[\"Team\"] != df[\"rush_team\"]].copy()\n",
    "        aggs = {\n",
    "            \"X\": \"mean\", \"Y\": \"mean\",\n",
    "            \"nextX\": \"mean\", \"nextY\": \"mean\"\n",
    "        }\n",
    "        temp_df = defense_team_df.groupby(\"PlayId\").agg(aggs).reset_index()\n",
    "        temp_df.columns = [\"PlayId\", \"df_centroid_x\", \"df_centroid_y\", \"df_centroid_x1\", \"df_centroid_y1\"]\n",
    "        rush_df = pd.merge(rush_df, temp_df, on=\"PlayId\", how=\"left\")                                                \n",
    "        rush_df[\"dist_to_centroid\"] = ((rush_df[\"X\"] - rush_df[\"df_centroid_x\"])**2 + (rush_df[\"Y\"] - rush_df[\"df_centroid_y\"])**2)**0.5\n",
    "        rush_df[\"dist1_to_centroid\"] = ((rush_df[\"nextX\"] - rush_df[\"df_centroid_x\"])**2 + (rush_df[\"nextY\"] - rush_df[\"df_centroid_y\"])**2)**0.5\n",
    "        rush_df[\"dist2_to_centroid\"] = ((rush_df[\"nextX\"] - rush_df[\"df_centroid_x1\"])**2 + (rush_df[\"nextY\"] - rush_df[\"df_centroid_y1\"])**2)**0.5  \n",
    "        return rush_df\n",
    "    \n",
    "    def get_free_width(self, df, rush_df):\n",
    "        temp = df.copy()\n",
    "        temp_rush1 = self._get_free_width(temp)\n",
    "        temp_rush1.columns = [\"PlayId\", \"max_df_cnt1\", \"min_df_cnt1\", \"free_width1\"]\n",
    "        temp[\"Y\"] = np.where(temp[\"NflIdRusher\"] == temp[\"NflId\"], temp[\"nextY\"], temp[\"Y\"])\n",
    "        temp_rush2 = self._get_free_width(temp)\n",
    "        temp_rush2.columns = [\"PlayId\", \"max_df_cnt2\", \"min_df_cnt2\", \"free_width2\"]\n",
    "        temp[\"Y\"] = temp[\"nextY\"]\n",
    "        temp[\"X\"] = temp[\"nextX\"]\n",
    "        temp_rush3 = self._get_free_width(temp)\n",
    "        temp_rush3.columns = [\"PlayId\", \"max_df_cnt3\", \"min_df_cnt3\", \"free_width3\"]\n",
    "        temp[\"Y\"] = temp[\"nextY2\"]\n",
    "        temp[\"X\"] = temp[\"nextX2\"]\n",
    "        temp_rush4 = self._get_free_width(temp)\n",
    "        temp_rush4.columns = [\"PlayId\", \"max_df_cnt4\", \"min_df_cnt4\", \"free_width4\"]\n",
    "\n",
    "        temp_rush = pd.merge(temp_rush1, temp_rush2, on=\"PlayId\", how=\"left\")\n",
    "        temp_rush = pd.merge(temp_rush, temp_rush3, on=\"PlayId\", how=\"left\")\n",
    "        temp_rush = pd.merge(temp_rush, temp_rush4, on=\"PlayId\", how=\"left\")\n",
    "        rush_df = pd.merge(rush_df, temp_rush, on=\"PlayId\", how=\"left\")\n",
    "        return rush_df\n",
    "        \n",
    "    def _get_free_width(self, temp):\n",
    "        temp[\"std_X\"] = np.where(temp[\"PlayDirection\"] == \"left\", temp[\"X\"]-10, 110-temp[\"X\"])\n",
    "        temp[\"std_rush_X\"] = np.where(temp[\"PlayDirection\"] == \"left\", temp[\"rush_X\"]-10, 110-temp[\"rush_X\"])\n",
    "        temp[\"x_in_box\"] = np.where((temp[\"std_X\"] <= temp[\"std_rush_X\"]+5) & (temp[\"std_rush_X\"] <= temp[\"std_X\"]+10), 1, 0)\n",
    "        temp = temp.sort_values(by=[\"PlayId\", \"Y\"])\n",
    "        temp[\"in_box_sum\"] = temp.groupby([\"PlayId\"])[\"x_in_box\"].cumsum()\n",
    "        temp[\"in_box_r\"] = temp.groupby([\"PlayId\", \"Team\"])[\"in_box_sum\"].shift(1)\n",
    "        temp[\"in_box_l\"] = temp.groupby([\"PlayId\", \"Team\"])[\"in_box_sum\"].shift(-1)\n",
    "        temp[\"df_cnt_r\"] = temp[\"in_box_sum\"] - temp[\"in_box_r\"]\n",
    "        temp[\"df_cnt_l\"] = temp[\"in_box_l\"] - temp[\"in_box_sum\"]\n",
    "        temp[\"max_df_cnt0\"] = np.max(temp[[\"df_cnt_r\", \"df_cnt_l\"]], axis=1)\n",
    "        temp[\"min_df_cnt0\"] = np.min(temp[[\"df_cnt_r\", \"df_cnt_l\"]], axis=1)\n",
    "        temp[\"next_y_in_field\"] = temp.groupby(\"PlayId\")[\"Y\"].shift(-1).fillna(temp[\"Y\"])\n",
    "        temp[\"prev_y_in_field\"] = temp.groupby(\"PlayId\")[\"Y\"].shift(1).fillna(temp[\"Y\"])\n",
    "        temp[\"free_width\"] = np.where(temp[\"max_df_cnt0\"] == 1, temp[\"next_y_in_field\"]-temp[\"prev_y_in_field\"], 0)\n",
    "        temp_rush = temp[temp[\"NflIdRusher\"] == temp[\"NflId\"]]\n",
    "        return temp_rush[[\"PlayId\", \"max_df_cnt0\", \"min_df_cnt0\", \"free_width\"]]\n",
    "    \n",
    "    def get_proper_field_position(self, df):\n",
    "        map_abbr = {\n",
    "            'ARZ': 'ARI', 'BLT': 'BAL', 'CLV': 'CLE', 'HST': 'HOU', 'NE': 'NE', 'BUF': 'BUF',\n",
    "            'CHI': 'CHI', 'CIN': 'CIN', 'CLE': 'CLE', 'DET': 'DET', 'HOU': 'HOU', 'TEN': 'TEN',\n",
    "            'WAS': 'WAS', 'LA': 'LA', 'GB': 'GB', 'SF': 'SF', 'DAL': 'DAL', 'MIN': 'MIN',\n",
    "            'DEN': 'DEN', 'BAL': 'BAL', 'CAR': 'CAR', 'IND': 'IND', 'JAX': 'JAX', 'KC': 'KC',\n",
    "            'NO': 'NO', 'PIT': 'PIT', 'TB': 'TB', 'LAC': 'LAC', 'OAK': 'OAK', 'SEA': 'SEA',\n",
    "            'ATL': 'ATL', 'NYG': 'NYG', 'NYJ': 'NYJ', 'PHI': 'PHI', 'ARI': 'ARI', 'MIA': 'MIA'\n",
    "        }\n",
    "        df['FieldPosition'] = df['FieldPosition'].map(map_abbr)\n",
    "        df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n",
    "        return df\n",
    "    \n",
    "    def get_season(self, df):\n",
    "        df[\"ym\"] = df[\"PlayId\"] // (10**8)\n",
    "        df[\"is_old\"] = df[\"ym\"] < 201800\n",
    "        return df\n",
    "    \n",
    "    def get_proper_yard(self, df):\n",
    "        df[\"ball_is_in_own_half\"] = np.where(df[\"FieldPosition\"] == df[\"PossessionTeam\"], 1, -1)\n",
    "        df[\"playing_to_left\"] = np.where(df[\"PlayDirection\"] == \"left\", 1, -1)\n",
    "        df[\"ball_is_on_right\"] = df[\"playing_to_left\"] * df[\"ball_is_in_own_half\"]\n",
    "        df[\"remaining_yards\"] =  np.where(df[\"ball_is_in_own_half\"]==1, 100-df[\"YardLine\"], df[\"YardLine\"])\n",
    "\n",
    "        df[\"yard_to_X\"] = np.where(df[\"ball_is_on_right\"] == 1, 100-df[\"YardLine\"], df[\"YardLine\"])\n",
    "        df[\"yard_to_X\"] += 10\n",
    "        df[\"rush_yardline_dist\"] = df[\"yard_to_X\"] - df[\"X\"]\n",
    "        df[\"rush_yardline_dist\"] = np.where(df[\"PlayDirection\"] == \"right\", df[\"rush_yardline_dist\"], -df[\"rush_yardline_dist\"])\n",
    "        mid = 26.666\n",
    "        df[\"std_Y\"] = np.abs(mid - df[\"Y\"])\n",
    "        return df\n",
    "    \n",
    "    def get_direction(self, df):\n",
    "        df[\"rounded_dir\"] = df[\"Dir\"]\n",
    "        df[\"rounded_dir\"] = np.where(df[\"PlayDirection\"] == \"left\", (df[\"rounded_dir\"] + 180) % 360, df[\"rounded_dir\"])\n",
    "        df[\"rounded_dir\"] = np.where(df[\"rounded_dir\"]>=180, np.abs(270-df[\"rounded_dir\"])+180, np.abs(90-df[\"rounded_dir\"]))\n",
    "        df[\"rounded_orient\"] = df[\"Orientation\"]\n",
    "        df[\"rounded_orient\"] = np.where(df[\"PlayDirection\"] == \"left\", (df[\"rounded_orient\"] + 180) % 360, df[\"rounded_orient\"])\n",
    "        df[\"rounded_orient\"] = np.where(df[\"rounded_orient\"] >= 180, np.abs(270 - df[\"rounded_orient\"])+180, np.abs(90 - df[\"rounded_orient\"]))\n",
    "        return df\n",
    "\n",
    "    def do_cat(self, df):\n",
    "        for c in self.cat_dict.keys():\n",
    "            df[c] = df[c].map(self.cat_dict[c])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def prep_df(self, df):\n",
    "        df[\"VisitorTeamAbbr\"] = np.where(df[\"VisitorTeamAbbr\"] == \"ARI\", \"ARZ\", df[\"VisitorTeamAbbr\"])\n",
    "        df[\"HomeTeamAbbr\"] = np.where(df[\"HomeTeamAbbr\"] == \"ARI\", \"ARZ\", df[\"HomeTeamAbbr\"])\n",
    "        df[\"VisitorTeamAbbr\"] = np.where(df[\"VisitorTeamAbbr\"] == \"BAL\", \"BLT\", df[\"VisitorTeamAbbr\"])\n",
    "        df[\"HomeTeamAbbr\"] = np.where(df[\"HomeTeamAbbr\"] == \"BAL\", \"BLT\", df[\"HomeTeamAbbr\"])\n",
    "        df[\"VisitorTeamAbbr\"] = np.where(df[\"VisitorTeamAbbr\"] == \"CLE\", \"CLV\", df[\"VisitorTeamAbbr\"])\n",
    "        df[\"HomeTeamAbbr\"] = np.where(df[\"HomeTeamAbbr\"] == \"CLE\", \"CLV\", df[\"HomeTeamAbbr\"])\n",
    "        df[\"VisitorTeamAbbr\"] = np.where(df[\"VisitorTeamAbbr\"] == \"HOU\", \"HST\", df[\"VisitorTeamAbbr\"])\n",
    "        df[\"HomeTeamAbbr\"] = np.where(df[\"HomeTeamAbbr\"] == \"HOU\", \"HST\", df[\"HomeTeamAbbr\"])\n",
    "\n",
    "        df[\"PossessionTeam\"] = np.where(df[\"PossessionTeam\"] == \"ARI\", \"ARZ\", df[\"PossessionTeam\"])\n",
    "        df[\"FieldPosition\"] = np.where(df[\"FieldPosition\"] == \"ARI\", \"ARZ\", df[\"FieldPosition\"])\n",
    "        df[\"PossessionTeam\"] = np.where(df[\"PossessionTeam\"] == \"BAL\", \"BLT\", df[\"PossessionTeam\"])\n",
    "        df[\"FieldPosition\"] = np.where(df[\"FieldPosition\"] == \"BAL\", \"BLT\", df[\"FieldPosition\"])\n",
    "        df[\"PossessionTeam\"] = np.where(df[\"PossessionTeam\"] == \"CLE\", \"CLV\", df[\"PossessionTeam\"])\n",
    "        df[\"FieldPosition\"] = np.where(df[\"FieldPosition\"] == \"CLE\", \"CLV\", df[\"FieldPosition\"])\n",
    "        df[\"PossessionTeam\"] = np.where(df[\"PossessionTeam\"] == \"HOU\", \"HST\", df[\"PossessionTeam\"])\n",
    "        df[\"FieldPosition\"] = np.where(df[\"FieldPosition\"] == \"HOU\", \"HST\", df[\"FieldPosition\"])\n",
    "\n",
    "        for col in ['X', 'Y', 'S', 'A', 'Dis', 'Orientation','Dir','YardLine','Distance', 'DefendersInTheBox']:\n",
    "            df[\"temp\"] = df.groupby([\"PlayId\",\"Team\"])[col].transform(\"mean\")\n",
    "            df[\"Orientation\"] = df[\"Orientation\"].fillna(df[\"temp\"])\n",
    "            \n",
    "        del df[\"temp\"]\n",
    "        \n",
    "        # df[\"DefenderTeam\"] = np.where(df[\"PossessionTeam\"] == df[\"HomeTeamAbbr\"], df[\"VisitorTeamAbbr\"],df[\"HomeTeamAbbr\"])\n",
    "        df[\"FieldPosition\"] = (df[\"FieldPosition\"] == df[\"PossessionTeam\"]).astype(int)\n",
    "\n",
    "        df[\"TeamOnOffense\"] = np.where(df[\"PossessionTeam\"] == df[\"HomeTeamAbbr\"], \"home\", \"away\")\n",
    "        df[\"IsOnOffense\"] = np.where(df[\"Team\"] == df[\"TeamOnOffense\"], 1, 0)\n",
    "\n",
    "        df[\"ToLeft\"] = np.where(df[\"PlayDirection\"] == \"left\", 1, 0)\n",
    "        df[\"YardsFromOwnGoal\"] = np.where(df[\"FieldPosition\"] == 1, df[\"YardLine\"],\n",
    "                                                50 + (50 - df[\"YardLine\"]))\n",
    "        df[\"YardsFromOwnGoal\"] = np.where(df[\"YardLine\"] == 50, 50, df[\"YardsFromOwnGoal\"])\n",
    "\n",
    "        df[\"X\"] = np.where(df[\"ToLeft\"] == 1, 120 - df[\"X\"], df[\"X\"]) - 10  ## Standardizes X\n",
    "        df[\"Y\"] = np.where(df[\"ToLeft\"] == 1, 160 / 3 - df[\"Y\"], df[\"Y\"])  ## Standardized Y\n",
    "        df[\"Dir\"] = np.where(df[\"ToLeft\"] == 1, (df[\"Dir\"] + 180) % 360, df[\"Dir\"])  ## Standardizes Dir\n",
    "        df[\"Orientation\"] = np.where(df[\"ToLeft\"] == 1, (df[\"Orientation\"] + 180) % 360, df[\"Orientation\"])  ## Standardizes Orientation\n",
    "        return df\n",
    "        \n",
    "    def make_emil_feats(self, df):\n",
    "        # df[\"ScoreDifference\"] = df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"]\n",
    "        # df[\"ScoreDifference\"] = np.where(df[\"PossessionTeam\"]==df[\"HomeTeamAbbr\"],df[\"ScoreDifference\"],-df[\"ScoreDifference\"])\n",
    "\n",
    "        df[\"ori_mean\"] = df.groupby([\"PlayId\",\"IsOnOffense\"])[\"Orientation\"].transform(\"mean\")\n",
    "        df[\"Orientation\"] = df[\"Orientation\"].fillna(df[\"ori_mean\"])\n",
    "        df[\"dir_mean\"] = df.groupby([\"PlayId\",\"IsOnOffense\"])[\"Dir\"].transform(\"mean\")\n",
    "        df[\"Dir\"] = df[\"Dir\"].fillna(df[\"dir_mean\"])\n",
    "\n",
    "        df[\"X_end\"] = df[\"S\"]*df[\"Dir\"].apply(lambda x: math.cos((90-x)*np.pi/180)) + df[\"X\"]\n",
    "        df[\"Y_end\"] = df[\"S\"]*df[\"Dir\"].apply(lambda x: math.sin((90-x)*np.pi/180)) + df[\"Y\"]\n",
    "\n",
    "        # df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "\n",
    "        df[\"S_horizontal\"] = df[\"S\"]*df[\"Dir\"].apply(lambda x: math.cos((90-x)*np.pi/180))\n",
    "        df[\"S_vertical\"] = df[\"S\"]*df[\"Dir\"].apply(lambda x: math.sin((90-x)*np.pi/180))\n",
    "        df[\"A_horizontal\"] = df[\"A\"]*df[\"Dir\"].apply(lambda x: math.cos((90-x)*np.pi/180))\n",
    "        # df[\"A_vertical\"] = df[\"A\"]*df[\"Dir\"].apply(lambda x: math.sin((90-x)*np.pi/180))\n",
    "        #\n",
    "\n",
    "        for col in [\"X\",\"Y\",\"X_end\",\"Y_end\",\"S\",\"S_horizontal\",\"S_vertical\",\"A\",\"A_horizontal\"]: # PlayerHeight\n",
    "            temp = np.repeat(df.loc[df[\"NflId\"]==df[\"NflIdRusher\"],col],22)\n",
    "            df[col+\"_rusher\"] = temp.values\n",
    "\n",
    "        df[\"dist_rusher\"] = ((df[\"X_rusher\"]-df[\"X\"])**2+(df[\"Y_rusher\"]-df[\"Y\"])**2)**0.5\n",
    "        dist_rusher = (df[df[\"NflId\"]!=df[\"NflIdRusher\"]].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_rusher\"].agg([\"mean\",\"std\",\"min\",\"max\"])).unstack().reset_index(drop=True)\n",
    "        dist_rusher.columns = [\"dist_rusher_mean_def\",\"dist_rusher_mean_off\",\"dist_rusher_std_def\",\"dist_rusher_std_off\",\"dist_rusher_min_def\",\"dist_rusher_min_off\",\"dist_rusher_max_def\",\"dist_rusher_max_off\"]\n",
    "\n",
    "        df[\"dist_rusher_end\"] = ((df[\"X_end_rusher\"]-df[\"X_end\"])**2+(df[\"Y_end_rusher\"]-df[\"Y_end\"])**2)**0.5\n",
    "        dist_rusher_end = (df[df[\"NflId\"]!=df[\"NflIdRusher\"]].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_rusher_end\"].agg([\"mean\",\"std\",\"min\",\"max\"])).unstack().reset_index(drop=True)\n",
    "        dist_rusher_end.columns = [\"dist_rusher_end_mean_def\",\"dist_rusher_end_mean_off\",\"dist_rusher_end_std_def\",\"dist_rusher_end_std_off\",\"dist_rusher_end_min_def\",\"dist_rusher_end_min_off\",\"dist_rusher_end_max_def\",\"dist_rusher_end_max_off\"]\n",
    "        #\n",
    "\n",
    "        df[\"dist_rusher_travel\"] = ((df[\"X_end_rusher\"]-df[\"X_rusher\"])**2+(df[\"Y_end_rusher\"]-df[\"Y_rusher\"])**2)**0.5\n",
    "        #\n",
    "\n",
    "        df[\"dist_X\"] = (df[\"X\"] - df[\"X_rusher\"])\n",
    "        dist_x = (df[df[\"NflId\"]!=df[\"NflIdRusher\"]].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_X\"].agg([\"mean\",\"min\",\"max\"])).unstack().reset_index(drop=True)\n",
    "        dist_x.columns = [\"dist_X_mean_def\",\"dist_X_mean_off\",\"dist_X_min_def\",\"dist_X_min_off\",\"dist_X_max_def\",\"dist_X_max_off\"]\n",
    "\n",
    "        df[\"dist_Y_end\"] = np.abs(df[\"Y_end\"] - df[\"Y_end_rusher\"])\n",
    "        dist_y_end = (df[df[\"NflId\"]!=df[\"NflIdRusher\"]].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_Y_end\"].agg([\"mean\"])).unstack().reset_index(drop=True)\n",
    "        dist_y_end.columns = [\"dist_Y_end_mean_def\",\"dist_Y_end_mean_off\"]\n",
    "        #\n",
    "\n",
    "        df[\"dist_rusher_rank\"] = df.groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_rusher\"].rank()\n",
    "        df[\"dist_rusher_rank\"] = np.where(df[\"IsOnOffense\"]==1,df[\"dist_rusher_rank\"]-1,df[\"dist_rusher_rank\"])\n",
    "\n",
    "        df[\"dist_rusher_end_rank\"] = df.groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_rusher_end\"].rank()\n",
    "        df[\"dist_rusher_end_rank\"] = np.where(df[\"IsOnOffense\"]==1,df[\"dist_rusher_end_rank\"]-1,df[\"dist_rusher_end_rank\"])\n",
    "        #\n",
    "        for col in [\"X\",\"Y\"]:\n",
    "            temp = np.repeat(df.loc[(df[\"dist_rusher_rank\"] == 1)&(df[\"IsOnOffense\"] == 0),col],22)\n",
    "            df[col+\"_close\"] = temp.values\n",
    "\n",
    "        df[\"dist_close\"] = ((df[\"X_close\"]-df[\"X\"])**2+(df[\"Y_close\"]-df[\"Y\"])**2)**0.5\n",
    "        dist_close = (df[~((df[\"dist_rusher_rank\"] == 1)&(df[\"IsOnOffense\"] == 0))].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_close\"].agg([\"min\"])).unstack().reset_index(drop=True)\n",
    "        dist_close.columns = [\"dist_close_min_def\",\"dist_close_min_off\"]\n",
    "\n",
    "        for col in [\"X_end\",\"Y_end\"]:\n",
    "            temp = np.repeat(df.loc[((df[\"dist_rusher_end_rank\"] == 1)&(df[\"IsOnOffense\"] == 0)),col],22)\n",
    "            df[col+\"_close\"] = temp.values\n",
    "\n",
    "        df[\"dist_close_end\"] = ((df[\"X_end_close\"]-df[\"X\"])**2+(df[\"Y_end_close\"]-df[\"Y\"])**2)**0.5\n",
    "        dist_close_end = (df[~((df[\"dist_rusher_end_rank\"] == 1)&(df[\"IsOnOffense\"] == 0))].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_close_end\"].agg([\"mean\"])).unstack().reset_index(drop=True)\n",
    "        dist_close_end.columns = [\"dist_close_end_mean_def\",\"dist_close_end_mean_off\"]\n",
    "\n",
    "        # for col in [\"X\",\"Y\"]:\n",
    "        #     temp = np.repeat(df.loc[((df[\"dist_rusher_rank\"] == 11)&(df[\"IsOnOffense\"] == 0)),col],22)\n",
    "        #     df[col+\"_far\"] = temp.values\n",
    "\n",
    "        # df[\"dist_far\"] = ((df[\"X_far\"]-df[\"X\"])**2+(df[\"Y_far\"]-df[\"Y\"])**2)**0.5\n",
    "        # dist_far = (df[~((df[\"dist_rusher_rank\"] == 11)&(df[\"IsOnOffense\"] == 0))].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_far\"].agg([\"min\",\"max\"])).unstack().reset_index(drop=True)\n",
    "        # dist_far.columns = [\"dist_far_min_def\",\"dist_far_min_off\",\"dist_far_max_def\",\"dist_far_max_off\"]    \n",
    "\n",
    "        # for col in [\"X_end\",\"Y_end\"]:\n",
    "        #    temp = np.repeat(df.loc[((df[\"dist_rusher_end_rank\"] == 11)&(df[\"IsOnOffense\"] == 0)),col],22)\n",
    "        #    df[col+\"_far\"] = temp.values\n",
    "\n",
    "        # df[\"dist_far_end\"] = ((df[\"X_end_far\"]-df[\"X_end\"])**2+(df[\"Y_end_far\"]-df[\"Y_end\"])**2)**0.5\n",
    "        # dist_far_end = (df[~((df[\"dist_rusher_end_rank\"] == 11)&(df[\"IsOnOffense\"] == 0))].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_far_end\"].agg([\"min\",\"max\"])).unstack().reset_index(drop=True)\n",
    "        # dist_far_end.columns = [\"dist_far_end_min_def\",\"dist_far_end_min_off\",\"dist_far_end_max_def\",\"dist_far_end_max_off\"]\n",
    "\n",
    "        def angle_fun(x_diff,y_diff):\n",
    "            return math.degrees(math.atan2(y_diff,x_diff))\n",
    "        angle_fun = np.vectorize(angle_fun)\n",
    "        y_diff = (df[\"Y\"]-df[\"Y_rusher\"]).values\n",
    "        x_diff = (df[\"X\"]-df[\"X_rusher\"]).values\n",
    "\n",
    "        df[\"angle\"] =  angle_fun(x_diff,y_diff)\n",
    "        df[\"angle\"] = np.where(df[\"NflId\"]==df[\"NflIdRusher\"], (90-df[\"Dir\"]), df[\"angle\"])\n",
    "        df[\"angle\"] = np.where(df[\"NflId\"]==df[\"NflIdRusher\"], (90-df[\"Dir\"]), df[\"angle\"])\n",
    "        df[\"angle\"] = np.where((df[\"NflId\"]==df[\"NflIdRusher\"])&(df[\"Dir\"].between(270,360)), df[\"angle\"]+360, df[\"angle\"])\n",
    "\n",
    "        angle = (df[df[\"NflId\"]!=df[\"NflIdRusher\"]].groupby([\"PlayId\",\"IsOnOffense\"])[\"angle\"].agg([\"std\",\"min\",\"max\"])).unstack().reset_index(drop=True)\n",
    "        angle.columns = [\"angle_std_def\",\"angle_std_off\",\"angle_min_def\",\"angle_min_off\",\"angle_max_def\",\"angle_max_off\"]\n",
    "\n",
    "        y_diff = (df[\"Y_end\"]-df[\"Y_end_rusher\"]).values\n",
    "        x_diff = (df[\"X_end\"]-df[\"X_end_rusher\"]).values\n",
    "\n",
    "        df[\"angle_end\"] = angle_fun(x_diff,y_diff)\n",
    "        df[\"angle_end\"] = np.where(df[\"NflId\"]==df[\"NflIdRusher\"], (90-df[\"Dir\"]),df[\"angle_end\"])\n",
    "        df[\"angle_end\"] = np.where((df[\"NflId\"]==df[\"NflIdRusher\"])&(df[\"Dir\"].between(270,360)), df[\"angle_end\"]+360, df[\"angle_end\"])\n",
    "\n",
    "        angle_end = (df[df[\"NflId\"]!=df[\"NflIdRusher\"]].groupby([\"PlayId\",\"IsOnOffense\"])[\"angle_end\"].agg([\"min\",\"max\"])).unstack().reset_index(drop=True)\n",
    "        angle_end.columns = [\"angle_end_min_def\",\"angle_end_min_off\",\"angle_end_max_def\",\"angle_end_max_off\"]\n",
    "\n",
    "        # def_points, off_points  = df.loc[(df[\"IsOnOffense\"]==0),[\"X\",\"Y\"]].values, df.loc[(df[\"IsOnOffense\"]==1),[\"X\",\"Y\"]].values\n",
    "        # def_areas, off_areas = np.zeros((df.shape[0]//22)), np.zeros((df.shape[0]//22))\n",
    "\n",
    "        # for play in (range(df.shape[0]//22)):\n",
    "        #    def_areas[play], off_areas[play] = ConvexHull(def_points[play*11:play*11+11]).area, ConvexHull(off_points[play*11:play*11+11]).area\n",
    "    \n",
    "        df[\"Old\"] = (df[\"Season\"] == 2017).astype(int)\n",
    "\n",
    "        df[\"dist_yard\"] = ((df[\"YardsFromOwnGoal\"]-df[\"X\"])**2+(df[\"Y_rusher\"]-df[\"Y\"])**2)**0.5\n",
    "        dist_yard = (df[df[\"NflId\"]!=df[\"NflIdRusher\"]].groupby([\"PlayId\",\"IsOnOffense\"])[\"dist_yard\"].agg([\"mean\",\"min\"])).unstack().reset_index(drop=True)\n",
    "        dist_yard.columns = [\"dist_yard_mean_def\",\"dist_yard_mean_off\",\"dist_yard_min_def\",\"dist_yard_min_off\"]\n",
    "\n",
    "\n",
    "        #\n",
    "        raw_feature_configs = [\n",
    "            ('GameId', 2, ['first']),\n",
    "            ('PlayId', 2, ['first']),\n",
    "            # ('Team', 2, ['first']),\n",
    "            # ('PlayerBirthDate', 2, []),\n",
    "            # ('PlayerCollegeName', 2, []),\n",
    "            # ('HomeTeamAbbr', 2, ['first']),\n",
    "            # ('VisitorTeamAbbr', 2, ['first']),\n",
    "            # ('Week', 2, ['first']),\n",
    "            # ('Season', 2, ['first']),\n",
    "            # ('YardLine', 2, ['first']),\n",
    "            # ('Down', 2, ['first']),\n",
    "            # ('HomeScoreBeforePlay', 2, ['first']),\n",
    "            # ('VisitorScoreBeforePlay', 2, ['first']),\n",
    "            # ('NflIdRusher', 2, ['first']),\n",
    "            ('Yards', 2, ['first']),\n",
    "\n",
    "            ('PossessionTeam', 1, ['first']),\n",
    "            ('X', 0, ['team','min','max', 'mean', 'std']),\n",
    "            ('Y', 0, ['team','min','max', 'mean', 'std']),\n",
    "            ('S', 0, ['team','max', 'std']), # 'min','mean', \n",
    "            ('A', 0, ['team', 'std']), # ,'min','max', 'mean'\n",
    "            # ('Dis', 0, ['team','mean']),\n",
    "            # ('Orientation', 0, ['team','mean']),\n",
    "            ('Dir', 0, ['team','mean']),\n",
    "            # ('GameClock', 0, ['first']),\n",
    "            # ('Distance', 0, ['first']),\n",
    "            # ('DefendersInTheBox', 0, ['first']),\n",
    "            ('PlayerWeight', 0, ['team','mean']), # , 'max', 'min', 'std'\n",
    "            # ('Stadium', 1, ['first']),\n",
    "            # ('Location', 1, ['first']),\n",
    "            # ('Turf', 1, ['first']),\n",
    "            # ('GameWeather', 1, ['first']),\n",
    "            # ('Temperature', 0, ['first']),\n",
    "            # ('Humidity', 0, ['first']),\n",
    "            # ('WindSpeed', 0, ['first']),\n",
    "            # ('WindDirection', 1, ['first']),\n",
    "            ################################\n",
    "            # ('Turf1', 0, ['first']),\n",
    "            # ('DefenderTeam', 1, ['first']),\n",
    "            # ('ScoreDifference', 0, ['first']),\n",
    "            ('YardsFromOwnGoal', 0, ['first']),\n",
    "            # ('PlayerHeight_rusher', 0, ['first']),\n",
    "            ('X_end', 0, ['team','min','max', 'mean', 'std']),\n",
    "            ('Y_end', 0, ['team','min','max', 'mean', 'std']),\n",
    "            ('S_horizontal', 0, ['team', 'mean', 'std']),\n",
    "            ('S_vertical', 0, ['team', 'std']), # mean\n",
    "            # ('X_rusher', 2, ['first']),\n",
    "            # ('Y_rusher', 2, ['first']),\n",
    "            ('X_end_rusher', 2, ['first']),\n",
    "            ('Y_end_rusher', 2, ['first']),\n",
    "            ('dist_rusher_travel', 0, ['first']),\n",
    "            ('A_rusher', 0, ['first']),\n",
    "            ('S_rusher', 0, ['first']),\n",
    "            ('S_horizontal_rusher', 0, ['first']),\n",
    "            ('S_vertical_rusher', 0, ['first']),\n",
    "            ('A_horizontal_rusher', 0, ['first']),\n",
    "            # ('A_vertical_rusher', 0, ['first']),\n",
    "            ('Old', 0, ['first']),\n",
    "        ]\n",
    "        \n",
    "        play_df = aggreate_by_play(df, raw_feature_configs)\n",
    "        unuse_features = [f[0] for f in raw_feature_configs if f[1] == 2]\n",
    "        categorical_features = [f for f in play_df.columns if str(play_df[f].dtype) == 'object' and f not in unuse_features]\n",
    "        encoders = generate_categorical_encoders(play_df, categorical_features)\n",
    "        encode_categorical_features(play_df, categorical_features, encoders)\n",
    "        useful_raw_features = [f for f in play_df.columns if f not in unuse_features]\n",
    "\n",
    "        play_df = pd.concat([play_df,dist_rusher],axis=1)\n",
    "        play_df = pd.concat([play_df,dist_rusher_end],axis=1)\n",
    "        play_df = pd.concat([play_df,dist_x],axis=1)\n",
    "        # play_df = pd.concat([play_df,dist_y],axis=1)\n",
    "        play_df = pd.concat([play_df,dist_y_end],axis=1)\n",
    "        play_df = pd.concat([play_df,dist_close],axis=1)\n",
    "        play_df = pd.concat([play_df,dist_close_end],axis=1)\n",
    "        # play_df = pd.concat([play_df,dist_far],axis=1)\n",
    "        # play_df = pd.concat([play_df,dist_far_end],axis=1)\n",
    "        play_df = pd.concat([play_df,angle],axis=1)\n",
    "        play_df = pd.concat([play_df,angle_end],axis=1)\n",
    "        play_df = pd.concat([play_df,dist_yard],axis=1)\n",
    "        for col in dist_rusher+dist_rusher_end+dist_x+dist_y_end+dist_close+dist_close_end+angle+angle_end+dist_yard:\n",
    "            useful_raw_features.append(col)\n",
    "            #\n",
    "\n",
    "        # play_df[\"dist_rusher_def_mean\"] = ((play_df[\"X_mean_def\"]-play_df[\"X_rusher\"])**2+(play_df[\"Y_mean_def\"]-play_df[\"Y_rusher\"])**2)**0.5\n",
    "        # play_df[\"dist_rusher_off_mean\"] = ((play_df[\"X_mean_off\"]-play_df[\"X_rusher\"])**2+(play_df[\"Y_mean_off\"]-play_df[\"Y_rusher\"])**2)**0.5\n",
    "        # useful_raw_features.append(\"dist_rusher_def_mean\")\n",
    "        # useful_raw_features.append(\"dist_rusher_off_mean\")\n",
    "\n",
    "        play_df[\"dist_rusher_end_def_mean\"] = ((play_df[\"X_end_mean_def\"]-play_df[\"X_end_rusher\"])**2+(play_df[\"Y_end_mean_def\"]-play_df[\"Y_end_rusher\"])**2)**0.5\n",
    "        # play_df[\"dist_rusher_end_off_mean\"] = ((play_df[\"X_end_mean_off\"]-play_df[\"X_end_rusher\"])**2+(play_df[\"Y_end_mean_off\"]-play_df[\"Y_end_rusher\"])**2)**0.5\n",
    "        useful_raw_features.append(\"dist_rusher_end_def_mean\")\n",
    "        # useful_raw_features.append(\"dist_rusher_end_off_mean\")\n",
    "\n",
    "        # play_df[\"off_areas\"] = off_areas\n",
    "        # useful_raw_features.append(\"off_areas\")\n",
    "\n",
    "        play_df[\"dist_center\"] = ((play_df[\"X_mean_def\"]-play_df[\"X_mean_off\"])**2+(play_df[\"Y_mean_def\"]-play_df[\"Y_mean_off\"])**2)**0.5\n",
    "\n",
    "        play_df[\"X_span_def\"] = (play_df[\"X_max_def\"]-play_df[\"X_min_def\"])\n",
    "        play_df[\"X_span_off\"] = (play_df[\"X_max_off\"]-play_df[\"X_min_off\"])\n",
    "        # play_df[\"Y_span_def\"] = (play_df[\"Y_max_def\"]-play_df[\"Y_min_def\"])\n",
    "        play_df[\"Y_span_off\"] = (play_df[\"Y_max_off\"]-play_df[\"Y_min_off\"])\n",
    "\n",
    "        # play_df[\"rectangle_def\"] = play_df[\"X_span_def\"]*play_df[\"Y_span_def\"]\n",
    "        play_df[\"rectangle_off\"] = play_df[\"X_span_off\"]*play_df[\"Y_span_off\"]\n",
    "\n",
    "        useful_raw_features = ['PlayId','YardsFromOwnGoal','angle_max_def', 'X_end_min_def', 'dist_close_end_mean_off','X_std_def', \n",
    "                       'S_vertical_std_def','Y_mean_off', 'S_vertical_std_off', 'X_min_off', 'dist_Y_end_mean_off','dist_X_max_off',\n",
    "                       'Dir_mean_def', 'dist_rusher_end_min_off', 'S_max_def', 'dist_X_min_off',\n",
    "                       'S_rusher', 'S_std_def', 'A_std_off', 'dist_rusher_end_std_def',\n",
    "                       'dist_close_min_off', 'PlayerWeight_mean_def', 'dist_rusher_min_def', 'dist_X_max_def', 'angle_min_def',\n",
    "                       'dist_X_mean_off', 'X_end_std_def', 'angle_end_min_def', 'dist_rusher_end_def_mean',\n",
    "                       'angle_std_off', 'S_horizontal_mean_off', 'dist_X_min_def', 'dist_close_end_mean_def',\n",
    "                       'angle_end_max_def', 'dist_rusher_travel', 'dist_rusher_end_mean_def', 'dist_Y_end_mean_def',\n",
    "                       'S_horizontal_mean_def', 'S_horizontal_rusher', 'A_rusher', 'A_horizontal_rusher', 'dist_rusher_end_min_def',\n",
    "                       'dist_center', 'X_span_def','X_span_off','rectangle_off',\n",
    "                       'dist_yard_mean_def', 'dist_yard_min_def', 'dist_yard_min_off', 'Old']\n",
    "        return play_df[useful_raw_features]\n",
    "\n",
    "    def aggreate_by_play(self, df, configs):\n",
    "        df = df.sort_values('PlayId')\n",
    "        agg_df = pd.DataFrame({'PlayId': list(df['PlayId'].unique())}).sort_values('PlayId')\n",
    "        # TODO aggerate with a sliding window\n",
    "        for config in configs:\n",
    "            feature = config[0]\n",
    "            if feature == 'PlayId' or feature not in df.columns:\n",
    "                continue\n",
    "            gy = df.groupby('PlayId')\n",
    "            gy_team = df.groupby(['PlayId','IsOnOffense'])\n",
    "            if 'team' in config[2]:\n",
    "                for agg_func in config[2]:                \n",
    "                    if agg_func == 'team':\n",
    "                        continue\n",
    "                    elif agg_func == 'first':\n",
    "                        agg_df[feature+\"_def\"] = gy_team[feature].agg(agg_func)[::2].values\n",
    "                        agg_df[feature+\"_off\"] = gy_team[feature].agg(agg_func)[1::2].values\n",
    "                    else:\n",
    "                        agg_df[f'{feature}_{agg_func}_def'] = gy_team[feature].agg(agg_func)[::2].values\n",
    "                        agg_df[f'{feature}_{agg_func}_off'] = gy_team[feature].agg(agg_func)[1::2].values\n",
    "            else:\n",
    "                for agg_func in config[2]:\n",
    "                    if agg_func == 'first':\n",
    "                        agg_df[feature] = gy[feature].agg(agg_func).values\n",
    "                    else:\n",
    "                        agg_df[f'{feature}_{agg_func}'] = gy[feature].agg(agg_func).values\n",
    "        return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoldenLgb:\n",
    "    def __init__(self, seed=99, dry_run=False):\n",
    "        self.train_param = self.kernel_train_param()\n",
    "        if dry_run:\n",
    "            self.num_rounds = 100\n",
    "        else:\n",
    "            self.num_rounds = 1500\n",
    "\n",
    "    def do_train_direct(self, x_train, x_test, y_train, y_test):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "        # print('Start training...')\n",
    "        model = lgb.train(self.train_param,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_eval],\n",
    "                          verbose_eval=0,\n",
    "                          num_boost_round=self.num_rounds,\n",
    "                          early_stopping_rounds=100,\n",
    "                          categorical_feature=[])\n",
    "        # print('End training...')\n",
    "        return model\n",
    "\n",
    "    def train_no_holdout(self, x_train, y_train):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "\n",
    "        # print('Start training...')\n",
    "        model = lgb.train(self.train_param,\n",
    "                          lgb_train,\n",
    "                          valid_sets=None,\n",
    "                          num_boost_round=1000,\n",
    "                          categorical_feature=[])\n",
    "        # print('End training...')\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def show_feature_importance(model, filename=None):\n",
    "        fi = pd.DataFrame({\n",
    "            \"name\": model.feature_name(),\n",
    "            \"importance_split\": model.feature_importance(importance_type=\"split\").astype(int),\n",
    "            \"importance_gain\": model.feature_importance(importance_type=\"gain\").astype(int),\n",
    "        })\n",
    "        fi = fi.sort_values(by=\"importance_gain\", ascending=False)\n",
    "        print(fi)\n",
    "\n",
    "    @staticmethod\n",
    "    def kernel_train_param():\n",
    "        return {\n",
    "            'num_leaves': 15,\n",
    "            'min_data_in_leaf': 50,\n",
    "            'objective': 'cross_entropy',\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.02,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"metric\": 'rmse',\n",
    "            \"verbosity\": -1,\n",
    "            \"random_state\": 81,\n",
    "        }\n",
    "    \n",
    "class GoldenTrainer:\n",
    "    def __init__(self, pred_col, dry_run=False):\n",
    "        self.pred_col = pred_col\n",
    "        self.target_col = \"target\"\n",
    "        self.dry_run = dry_run\n",
    "    \n",
    "    def train_models(self, df):\n",
    "        models = dict()\n",
    "        scores = list()\n",
    "        for i in range(-5, 21):\n",
    "            print(f\"model for target_val={i}\")\n",
    "            model_list, score = self.train_model(df, i)\n",
    "            models[i] = model_list\n",
    "            scores.append(score)\n",
    "        print(np.mean(scores))\n",
    "        return models\n",
    "\n",
    "    def train_model(self, df, target_val):\n",
    "        X = df[self.pred_col].copy()\n",
    "        y = (df[\"Yards\"] <= target_val).astype(int)\n",
    "        \n",
    "        models, scores = list(), list()\n",
    "        kf = KFold(n_splits=3, random_state=99, shuffle=True)\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            lgbm = GoldenLgb(seed=99, dry_run=self.dry_run)\n",
    "            model = lgbm.do_train_direct(X_train, X_val, y_train, y_val)\n",
    "            score = model.best_score[\"valid_0\"][\"rmse\"]\n",
    "            # if target_val == 0:\n",
    "            #     lgbm.show_feature_importance(model)\n",
    "            models.append(model)\n",
    "            scores.append(score)\n",
    "        return models, np.mean(scores)\n",
    "    \n",
    "    \n",
    "class GoldenPredictor:\n",
    "    def __init__(self, pred_col, mean_val_dict, models, feature_factory):\n",
    "        self.pred_col = pred_col\n",
    "        self.mean_val_dict = mean_val_dict\n",
    "        self.models = models\n",
    "        self.show = True\n",
    "        self.feature_factory = feature_factory\n",
    "        \n",
    "    def make_oof_pred(self, df):\n",
    "        X = df[self.pred_col].copy()\n",
    "        kf = KFold(n_splits=3, random_state=99, shuffle=True)\n",
    "        ret_df = list()\n",
    "        for f, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "            X_val = X.iloc[val_index]        \n",
    "            pred_data = dict()\n",
    "            prev_pred = np.zeros(X_val.shape[0])\n",
    "            for i in range(-99, 100):\n",
    "                if i in self.models:\n",
    "                    model_list = self.models[i]\n",
    "                    pred = model_list[f].predict(X_val)\n",
    "                elif i in self.mean_val_dict:\n",
    "                    pred = np.full(X_val.shape[0], self.mean_val_dict[i])\n",
    "                else:\n",
    "                    pred = prev_pred\n",
    "                pred_data[f\"Yards{i}\"] = pred\n",
    "                prev_pred = pred\n",
    "            ret_df.append(pd.DataFrame(data=pred_data, index=val_index))\n",
    "        ret_df = pd.concat(ret_df).sort_index()\n",
    "        return ret_df.values\n",
    "        #return self.post_process(ret_df.values)\n",
    "    \n",
    "    def post_process(self, preds):\n",
    "        np.clip(preds, 0, 1)\n",
    "        for i in range(preds.shape[0]):\n",
    "            prev_val = 0\n",
    "            for j in range(199):\n",
    "                if preds[i][j] < prev_val:\n",
    "                    preds[i][j] = prev_val\n",
    "                prev_val = preds[i][j]\n",
    "        return preds\n",
    "    \n",
    "    def no_post_process_pred(self, df):\n",
    "        prepared_df = self.feature_factory.make_feats(df)\n",
    "\n",
    "        pred_data = dict()\n",
    "        prev_pred = 0.0\n",
    "        for i in range(-99, 100):\n",
    "            if i in self.models:\n",
    "                model_list = self.models[i]\n",
    "                pred = 0\n",
    "                for model in model_list:\n",
    "                    pred += model.predict(prepared_df[self.pred_col])\n",
    "                pred /= len(model_list)\n",
    "            elif i in self.mean_val_dict:\n",
    "                pred = self.mean_val_dict[i]\n",
    "            else:\n",
    "                pred = prev_pred\n",
    "            if pred > 1.0:\n",
    "                pred = 1.0\n",
    "            pred_data[f\"Yards{i}\"] = pred\n",
    "            prev_pred = pred\n",
    "        return pd.DataFrame(data=pred_data)\n",
    "\n",
    "    def make_prediction(self, df):\n",
    "        #prepared_df = self.feature_factory.make_feats(df)\n",
    "\n",
    "        pred_data = dict()\n",
    "        prev_pred = 0.0\n",
    "        for i in range(-99, 100):\n",
    "            if i in self.models:\n",
    "                model_list = self.models[i]\n",
    "                pred = 0\n",
    "                for model in model_list:\n",
    "                    pred += model.predict(df[self.pred_col])\n",
    "                pred /= len(model_list)\n",
    "            elif i in self.mean_val_dict:\n",
    "                pred = self.mean_val_dict[i]\n",
    "            else:\n",
    "                pred = prev_pred\n",
    "            # if prev_pred > pred:\n",
    "            #    pred = prev_pred\n",
    "            if pred > 1.0:\n",
    "                pred = 1.0\n",
    "            if self.show:\n",
    "                # print(f\"loop{i}\")\n",
    "                # print(pred)\n",
    "                self.show = False\n",
    "            pred_data[f\"Yards{i}\"] = pred\n",
    "            prev_pred = pred\n",
    "        return pd.DataFrame(data=pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_enhancement(df):\n",
    "    df['Y'] = (160 / 3) - df['Y']\n",
    "    df['Dir'] = df['Dir'].apply(lambda x:(-(x-90)%360 + 90)%360)\n",
    "    df['Orientation'] = df['Orientation'].apply(lambda x:(-(x-90)%360 + 90)%360)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done emil feats 17.277008533477783\n",
      "done dist 21.739611387252808\n",
      "done rush feats  19.66550922393799\n",
      "done play 59.15218377113342\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n",
    "\n",
    "timer = GoldenTimer()\n",
    "categorical_features = [\"OffenseFormation\",\"Location\"]\n",
    "encoders = generate_categorical_encoders(train_df, categorical_features)\n",
    "feature_factory = FeatureFactory(encoders)\n",
    "play_df = feature_factory.make_feats(train_df, show=True)\n",
    "play_df = play_df.drop_duplicates([\"GameId\",\"PlayId\"])\n",
    "play_df = play_df.reset_index(drop=True)\n",
    "\n",
    "timer.time(\"done play\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_emin = play_df.copy()\n",
    "# fake_emin = fake_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_raw_features = ['angle_max_def', 'X_end_min_def', 'dist_close_end_mean_off','X_std_def', 'S_vertical_std_def',\n",
    "                       'Y_mean_off', 'S_vertical_std_off', 'X_min_off', 'dist_Y_end_mean_off','dist_X_max_off',\n",
    "                       'Dir_mean_def', 'dist_rusher_end_min_off', 'S_max_def', 'dist_X_min_off',\n",
    "                       'S_rusher', 'DefendersInTheBox', 'S_std_def', 'A_std_off', 'dist_rusher_end_std_def',\n",
    "                       'dist_close_min_off', 'PlayerWeight_mean_def', 'dist_rusher_min_def', 'dist_X_max_def', 'angle_min_def',\n",
    "                       'dist_X_mean_off', 'X_end_std_def', 'angle_end_min_def', 'dist_rusher_end_def_mean',\n",
    "                       'angle_std_off', 'Distance', 'S_horizontal_mean_off', 'dist_X_min_def', 'dist_close_end_mean_def',\n",
    "                       'angle_end_max_def', 'YardsFromOwnGoal', 'dist_rusher_travel', 'dist_rusher_end_mean_def', 'dist_Y_end_mean_def',\n",
    "                       'S_horizontal_mean_def', 'S_horizontal_rusher', 'A_rusher', 'A_horizontal_rusher', 'dist_rusher_end_min_def','is_old',\n",
    "                       'dist_center', 'X_span_def','X_span_off','rectangle_off',\n",
    "                       'dist_yard_mean_def', 'dist_yard_min_def', 'dist_yard_min_off',\n",
    "                       'closest_A','closest3_A','min_unblocked_dist3','max_df_cnt3','min_df_cnt3','free_width3',\n",
    "                       \"closest_next_dist\", \"closest3_prev_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_emin[\"DefendersInTheBox\"] = play_emin[\"DefendersInTheBox\"].fillna(play_emin[\"DefendersInTheBox\"].mean())\n",
    "play_emin[\"min_unblocked_dist3\"] = play_emin[\"min_unblocked_dist3\"].fillna(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23171, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle_max_def</th>\n",
       "      <th>X_end_min_def</th>\n",
       "      <th>dist_close_end_mean_off</th>\n",
       "      <th>X_std_def</th>\n",
       "      <th>S_vertical_std_def</th>\n",
       "      <th>Y_mean_off</th>\n",
       "      <th>S_vertical_std_off</th>\n",
       "      <th>X_min_off</th>\n",
       "      <th>dist_Y_end_mean_off</th>\n",
       "      <th>dist_X_max_off</th>\n",
       "      <th>Dir_mean_def</th>\n",
       "      <th>dist_rusher_end_min_off</th>\n",
       "      <th>S_max_def</th>\n",
       "      <th>dist_X_min_off</th>\n",
       "      <th>S_rusher</th>\n",
       "      <th>DefendersInTheBox</th>\n",
       "      <th>S_std_def</th>\n",
       "      <th>A_std_off</th>\n",
       "      <th>dist_rusher_end_std_def</th>\n",
       "      <th>dist_close_min_off</th>\n",
       "      <th>PlayerWeight_mean_def</th>\n",
       "      <th>dist_rusher_min_def</th>\n",
       "      <th>dist_X_max_def</th>\n",
       "      <th>angle_min_def</th>\n",
       "      <th>dist_X_mean_off</th>\n",
       "      <th>X_end_std_def</th>\n",
       "      <th>angle_end_min_def</th>\n",
       "      <th>dist_rusher_end_def_mean</th>\n",
       "      <th>angle_std_off</th>\n",
       "      <th>Distance</th>\n",
       "      <th>S_horizontal_mean_off</th>\n",
       "      <th>dist_X_min_def</th>\n",
       "      <th>dist_close_end_mean_def</th>\n",
       "      <th>angle_end_max_def</th>\n",
       "      <th>YardsFromOwnGoal</th>\n",
       "      <th>dist_rusher_travel</th>\n",
       "      <th>dist_rusher_end_mean_def</th>\n",
       "      <th>dist_Y_end_mean_def</th>\n",
       "      <th>S_horizontal_mean_def</th>\n",
       "      <th>S_horizontal_rusher</th>\n",
       "      <th>A_rusher</th>\n",
       "      <th>A_horizontal_rusher</th>\n",
       "      <th>dist_rusher_end_min_def</th>\n",
       "      <th>is_old</th>\n",
       "      <th>dist_center</th>\n",
       "      <th>X_span_def</th>\n",
       "      <th>X_span_off</th>\n",
       "      <th>rectangle_off</th>\n",
       "      <th>dist_yard_mean_def</th>\n",
       "      <th>dist_yard_min_def</th>\n",
       "      <th>dist_yard_min_off</th>\n",
       "      <th>closest_A</th>\n",
       "      <th>closest3_A</th>\n",
       "      <th>min_unblocked_dist3</th>\n",
       "      <th>max_df_cnt3</th>\n",
       "      <th>min_df_cnt3</th>\n",
       "      <th>free_width3</th>\n",
       "      <th>closest_next_dist</th>\n",
       "      <th>closest3_prev_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>71.527935</td>\n",
       "      <td>33.933859</td>\n",
       "      <td>5.497838</td>\n",
       "      <td>5.294079</td>\n",
       "      <td>1.465928</td>\n",
       "      <td>24.797879</td>\n",
       "      <td>1.495569</td>\n",
       "      <td>30.24</td>\n",
       "      <td>3.791940</td>\n",
       "      <td>4.17</td>\n",
       "      <td>170.590000</td>\n",
       "      <td>1.786392</td>\n",
       "      <td>4.55</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.186578</td>\n",
       "      <td>0.738631</td>\n",
       "      <td>4.946979</td>\n",
       "      <td>0.580517</td>\n",
       "      <td>233.545455</td>\n",
       "      <td>4.593310</td>\n",
       "      <td>22.12</td>\n",
       "      <td>-56.951875</td>\n",
       "      <td>3.088</td>\n",
       "      <td>5.165283</td>\n",
       "      <td>-74.221902</td>\n",
       "      <td>3.903068</td>\n",
       "      <td>62.814056</td>\n",
       "      <td>2</td>\n",
       "      <td>1.365528</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.865433</td>\n",
       "      <td>96.957010</td>\n",
       "      <td>35</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.991214</td>\n",
       "      <td>4.616856</td>\n",
       "      <td>0.172228</td>\n",
       "      <td>3.309436</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.054163</td>\n",
       "      <td>2.010548</td>\n",
       "      <td>True</td>\n",
       "      <td>4.137117</td>\n",
       "      <td>18.43</td>\n",
       "      <td>5.18</td>\n",
       "      <td>100.233</td>\n",
       "      <td>7.531487</td>\n",
       "      <td>1.838314</td>\n",
       "      <td>1.408013</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.329092</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.329092</td>\n",
       "      <td>4.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>71.448793</td>\n",
       "      <td>42.687928</td>\n",
       "      <td>5.601030</td>\n",
       "      <td>5.406292</td>\n",
       "      <td>1.491380</td>\n",
       "      <td>28.570606</td>\n",
       "      <td>1.644804</td>\n",
       "      <td>38.21</td>\n",
       "      <td>6.035394</td>\n",
       "      <td>4.88</td>\n",
       "      <td>169.080909</td>\n",
       "      <td>1.548273</td>\n",
       "      <td>2.79</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>3.06</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.630436</td>\n",
       "      <td>0.602741</td>\n",
       "      <td>6.989089</td>\n",
       "      <td>0.603738</td>\n",
       "      <td>233.545455</td>\n",
       "      <td>4.287773</td>\n",
       "      <td>23.02</td>\n",
       "      <td>-51.527841</td>\n",
       "      <td>3.231</td>\n",
       "      <td>5.191388</td>\n",
       "      <td>-49.734085</td>\n",
       "      <td>6.985689</td>\n",
       "      <td>72.521277</td>\n",
       "      <td>10</td>\n",
       "      <td>1.165587</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.713621</td>\n",
       "      <td>75.289672</td>\n",
       "      <td>43</td>\n",
       "      <td>3.06</td>\n",
       "      <td>9.112459</td>\n",
       "      <td>5.196817</td>\n",
       "      <td>0.221386</td>\n",
       "      <td>2.266862</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.785339</td>\n",
       "      <td>1.599975</td>\n",
       "      <td>True</td>\n",
       "      <td>4.696345</td>\n",
       "      <td>18.75</td>\n",
       "      <td>5.60</td>\n",
       "      <td>123.760</td>\n",
       "      <td>7.625625</td>\n",
       "      <td>0.438292</td>\n",
       "      <td>0.742428</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.970149</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.599975</td>\n",
       "      <td>4.287773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>58.943926</td>\n",
       "      <td>64.476474</td>\n",
       "      <td>9.003005</td>\n",
       "      <td>4.720893</td>\n",
       "      <td>1.244774</td>\n",
       "      <td>31.882424</td>\n",
       "      <td>1.225667</td>\n",
       "      <td>60.49</td>\n",
       "      <td>5.568518</td>\n",
       "      <td>5.50</td>\n",
       "      <td>146.707273</td>\n",
       "      <td>1.538625</td>\n",
       "      <td>4.35</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>5.77</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.855726</td>\n",
       "      <td>1.013888</td>\n",
       "      <td>5.285258</td>\n",
       "      <td>0.903383</td>\n",
       "      <td>233.545455</td>\n",
       "      <td>4.221670</td>\n",
       "      <td>20.42</td>\n",
       "      <td>-65.122113</td>\n",
       "      <td>3.859</td>\n",
       "      <td>4.575924</td>\n",
       "      <td>-95.139498</td>\n",
       "      <td>6.065421</td>\n",
       "      <td>54.064127</td>\n",
       "      <td>10</td>\n",
       "      <td>1.533994</td>\n",
       "      <td>3.91</td>\n",
       "      <td>11.734751</td>\n",
       "      <td>67.621387</td>\n",
       "      <td>65</td>\n",
       "      <td>5.77</td>\n",
       "      <td>7.875559</td>\n",
       "      <td>6.057012</td>\n",
       "      <td>0.455077</td>\n",
       "      <td>3.857889</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.618040</td>\n",
       "      <td>1.379718</td>\n",
       "      <td>True</td>\n",
       "      <td>3.723536</td>\n",
       "      <td>16.51</td>\n",
       "      <td>6.35</td>\n",
       "      <td>142.240</td>\n",
       "      <td>7.709866</td>\n",
       "      <td>1.365613</td>\n",
       "      <td>1.028591</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.15</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.180789</td>\n",
       "      <td>4.982550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>49.577496</td>\n",
       "      <td>96.688536</td>\n",
       "      <td>3.306709</td>\n",
       "      <td>0.962418</td>\n",
       "      <td>0.995038</td>\n",
       "      <td>27.533333</td>\n",
       "      <td>1.051438</td>\n",
       "      <td>93.70</td>\n",
       "      <td>3.024926</td>\n",
       "      <td>5.24</td>\n",
       "      <td>197.353636</td>\n",
       "      <td>1.683070</td>\n",
       "      <td>3.28</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>4.45</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.736700</td>\n",
       "      <td>0.869787</td>\n",
       "      <td>2.358279</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>257.454545</td>\n",
       "      <td>4.528002</td>\n",
       "      <td>6.33</td>\n",
       "      <td>-57.851951</td>\n",
       "      <td>3.574</td>\n",
       "      <td>1.296919</td>\n",
       "      <td>-89.998517</td>\n",
       "      <td>1.189177</td>\n",
       "      <td>59.482461</td>\n",
       "      <td>2</td>\n",
       "      <td>1.147356</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.981284</td>\n",
       "      <td>137.832325</td>\n",
       "      <td>98</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.889928</td>\n",
       "      <td>3.637683</td>\n",
       "      <td>-0.148942</td>\n",
       "      <td>4.429957</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.185587</td>\n",
       "      <td>0.994415</td>\n",
       "      <td>True</td>\n",
       "      <td>1.593201</td>\n",
       "      <td>3.01</td>\n",
       "      <td>6.01</td>\n",
       "      <td>70.918</td>\n",
       "      <td>4.088511</td>\n",
       "      <td>1.589277</td>\n",
       "      <td>1.194362</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.473951</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.962270</td>\n",
       "      <td>5.704849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57.258252</td>\n",
       "      <td>22.872706</td>\n",
       "      <td>6.037462</td>\n",
       "      <td>5.391251</td>\n",
       "      <td>1.332185</td>\n",
       "      <td>27.061818</td>\n",
       "      <td>2.517887</td>\n",
       "      <td>19.51</td>\n",
       "      <td>7.122583</td>\n",
       "      <td>6.20</td>\n",
       "      <td>198.156364</td>\n",
       "      <td>2.253578</td>\n",
       "      <td>3.33</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>3.90</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.673500</td>\n",
       "      <td>0.565544</td>\n",
       "      <td>6.481055</td>\n",
       "      <td>0.913510</td>\n",
       "      <td>242.454545</td>\n",
       "      <td>4.288088</td>\n",
       "      <td>19.42</td>\n",
       "      <td>-62.631067</td>\n",
       "      <td>3.460</td>\n",
       "      <td>5.993600</td>\n",
       "      <td>-70.218190</td>\n",
       "      <td>6.692979</td>\n",
       "      <td>74.517985</td>\n",
       "      <td>10</td>\n",
       "      <td>0.615832</td>\n",
       "      <td>3.96</td>\n",
       "      <td>9.339500</td>\n",
       "      <td>69.280260</td>\n",
       "      <td>25</td>\n",
       "      <td>3.90</td>\n",
       "      <td>9.595146</td>\n",
       "      <td>6.089184</td>\n",
       "      <td>-0.380134</td>\n",
       "      <td>1.466013</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.951029</td>\n",
       "      <td>2.669379</td>\n",
       "      <td>True</td>\n",
       "      <td>5.299553</td>\n",
       "      <td>15.46</td>\n",
       "      <td>6.68</td>\n",
       "      <td>177.020</td>\n",
       "      <td>8.080746</td>\n",
       "      <td>0.895879</td>\n",
       "      <td>0.723395</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.04</td>\n",
       "      <td>10.731683</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.669379</td>\n",
       "      <td>4.288088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   angle_max_def  X_end_min_def  dist_close_end_mean_off  X_std_def  \\\n",
       "0      71.527935      33.933859                 5.497838   5.294079   \n",
       "1      71.448793      42.687928                 5.601030   5.406292   \n",
       "2      58.943926      64.476474                 9.003005   4.720893   \n",
       "3      49.577496      96.688536                 3.306709   0.962418   \n",
       "4      57.258252      22.872706                 6.037462   5.391251   \n",
       "\n",
       "   S_vertical_std_def  Y_mean_off  S_vertical_std_off  X_min_off  \\\n",
       "0            1.465928   24.797879            1.495569      30.24   \n",
       "1            1.491380   28.570606            1.644804      38.21   \n",
       "2            1.244774   31.882424            1.225667      60.49   \n",
       "3            0.995038   27.533333            1.051438      93.70   \n",
       "4            1.332185   27.061818            2.517887      19.51   \n",
       "\n",
       "   dist_Y_end_mean_off  dist_X_max_off  Dir_mean_def  dist_rusher_end_min_off  \\\n",
       "0             3.791940            4.17    170.590000                 1.786392   \n",
       "1             6.035394            4.88    169.080909                 1.548273   \n",
       "2             5.568518            5.50    146.707273                 1.538625   \n",
       "3             3.024926            5.24    197.353636                 1.683070   \n",
       "4             7.122583            6.20    198.156364                 2.253578   \n",
       "\n",
       "   S_max_def  dist_X_min_off  S_rusher  DefendersInTheBox  S_std_def  \\\n",
       "0       4.55           -1.01      3.63                6.0   1.186578   \n",
       "1       2.79           -0.72      3.06                6.0   0.630436   \n",
       "2       4.35           -0.85      5.77                7.0   0.855726   \n",
       "3       3.28           -0.77      4.45                9.0   0.736700   \n",
       "4       3.33           -0.48      3.90                7.0   0.673500   \n",
       "\n",
       "   A_std_off  dist_rusher_end_std_def  dist_close_min_off  \\\n",
       "0   0.738631                 4.946979            0.580517   \n",
       "1   0.602741                 6.989089            0.603738   \n",
       "2   1.013888                 5.285258            0.903383   \n",
       "3   0.869787                 2.358279            0.440000   \n",
       "4   0.565544                 6.481055            0.913510   \n",
       "\n",
       "   PlayerWeight_mean_def  dist_rusher_min_def  dist_X_max_def  angle_min_def  \\\n",
       "0             233.545455             4.593310           22.12     -56.951875   \n",
       "1             233.545455             4.287773           23.02     -51.527841   \n",
       "2             233.545455             4.221670           20.42     -65.122113   \n",
       "3             257.454545             4.528002            6.33     -57.851951   \n",
       "4             242.454545             4.288088           19.42     -62.631067   \n",
       "\n",
       "   dist_X_mean_off  X_end_std_def  angle_end_min_def  \\\n",
       "0            3.088       5.165283         -74.221902   \n",
       "1            3.231       5.191388         -49.734085   \n",
       "2            3.859       4.575924         -95.139498   \n",
       "3            3.574       1.296919         -89.998517   \n",
       "4            3.460       5.993600         -70.218190   \n",
       "\n",
       "   dist_rusher_end_def_mean  angle_std_off  Distance  S_horizontal_mean_off  \\\n",
       "0                  3.903068      62.814056         2               1.365528   \n",
       "1                  6.985689      72.521277        10               1.165587   \n",
       "2                  6.065421      54.064127        10               1.533994   \n",
       "3                  1.189177      59.482461         2               1.147356   \n",
       "4                  6.692979      74.517985        10               0.615832   \n",
       "\n",
       "   dist_X_min_def  dist_close_end_mean_def  angle_end_max_def  \\\n",
       "0            3.69                 7.865433          96.957010   \n",
       "1            4.27                 8.713621          75.289672   \n",
       "2            3.91                11.734751          67.621387   \n",
       "3            3.32                 3.981284         137.832325   \n",
       "4            3.96                 9.339500          69.280260   \n",
       "\n",
       "   YardsFromOwnGoal  dist_rusher_travel  dist_rusher_end_mean_def  \\\n",
       "0                35                3.63                  6.991214   \n",
       "1                43                3.06                  9.112459   \n",
       "2                65                5.77                  7.875559   \n",
       "3                98                4.45                  3.889928   \n",
       "4                25                3.90                  9.595146   \n",
       "\n",
       "   dist_Y_end_mean_def  S_horizontal_mean_def  S_horizontal_rusher  A_rusher  \\\n",
       "0             4.616856               0.172228             3.309436      3.35   \n",
       "1             5.196817               0.221386             2.266862      2.41   \n",
       "2             6.057012               0.455077             3.857889      2.42   \n",
       "3             3.637683              -0.148942             4.429957      3.20   \n",
       "4             6.089184              -0.380134             1.466013      2.53   \n",
       "\n",
       "   A_horizontal_rusher  dist_rusher_end_min_def  is_old  dist_center  \\\n",
       "0             3.054163                 2.010548    True     4.137117   \n",
       "1             1.785339                 1.599975    True     4.696345   \n",
       "2             1.618040                 1.379718    True     3.723536   \n",
       "3             3.185587                 0.994415    True     1.593201   \n",
       "4             0.951029                 2.669379    True     5.299553   \n",
       "\n",
       "   X_span_def  X_span_off  rectangle_off  dist_yard_mean_def  \\\n",
       "0       18.43        5.18        100.233            7.531487   \n",
       "1       18.75        5.60        123.760            7.625625   \n",
       "2       16.51        6.35        142.240            7.709866   \n",
       "3        3.01        6.01         70.918            4.088511   \n",
       "4       15.46        6.68        177.020            8.080746   \n",
       "\n",
       "   dist_yard_min_def  dist_yard_min_off  closest_A  closest3_A  \\\n",
       "0           1.838314           1.408013       1.35        0.73   \n",
       "1           0.438292           0.742428       0.55        0.55   \n",
       "2           1.365613           1.028591       1.13        2.15   \n",
       "3           1.589277           1.194362       0.83        2.16   \n",
       "4           0.895879           0.723395       2.04        2.04   \n",
       "\n",
       "   min_unblocked_dist3  max_df_cnt3  min_df_cnt3  free_width3  \\\n",
       "0             3.329092          2.0          1.0          0.0   \n",
       "1            11.970149          3.0          2.0          0.0   \n",
       "2            99.000000          2.0          2.0          0.0   \n",
       "3             2.473951          2.0          1.0          0.0   \n",
       "4            10.731683          2.0          1.0          0.0   \n",
       "\n",
       "   closest_next_dist  closest3_prev_dist  \n",
       "0           3.329092            4.880256  \n",
       "1           1.599975            4.287773  \n",
       "2           3.180789            4.982550  \n",
       "3           3.962270            5.704849  \n",
       "4           2.669379            4.288088  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(play_emin[useful_raw_features].shape)\n",
    "play_emin[useful_raw_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "### Fold 1 ###\n",
      "tr CRPS 0.035677414160645134 val CRPS 0.03578712977421026\n",
      "tr CRPS 0.014946564241350581 val CRPS 0.01527062114621938\n",
      "tr CRPS 0.013588620292564305 val CRPS 0.013933326109728588\n",
      "tr CRPS 0.013088807216407655 val CRPS 0.013441066991002011\n",
      "tr CRPS 0.012715007304695753 val CRPS 0.013080967417305486\n",
      "tr CRPS 0.012599785922938667 val CRPS 0.012962742191351868\n",
      "tr CRPS 0.012481544626478524 val CRPS 0.012856269854558604\n",
      "tr CRPS 0.012370820509891472 val CRPS 0.012752331042166557\n",
      "tr CRPS 0.012316438529445875 val CRPS 0.012719254937551886\n",
      "tr CRPS 0.012255420039181706 val CRPS 0.012683919557079561\n",
      "tr CRPS 0.012215636003771952 val CRPS 0.012649023410986726\n",
      "tr CRPS 0.012154077995823468 val CRPS 0.012586953603946831\n",
      "tr CRPS 0.012143328319244761 val CRPS 0.012575669782736696\n",
      "tr CRPS 0.012085829547613279 val CRPS 0.012537272627676588\n",
      "tr CRPS 0.012046457811438495 val CRPS 0.012530946757482413\n",
      "tr CRPS 0.012043205478576078 val CRPS 0.01253169897641123\n",
      "tr CRPS 0.01198873102470229 val CRPS 0.012475663326087195\n",
      "tr CRPS 0.011983473335913335 val CRPS 0.012486786842881603\n",
      "tr CRPS 0.01198819871403361 val CRPS 0.01251558666910068\n",
      "tr CRPS 0.011972493621259949 val CRPS 0.012466501172767932\n",
      "tr CRPS 0.011985200401524353 val CRPS 0.01252562734395615\n",
      "tr CRPS 0.011929162300732724 val CRPS 0.012444840140780926\n",
      "tr CRPS 0.011910954289957774 val CRPS 0.012449520705228392\n",
      "tr CRPS 0.011941884626710053 val CRPS 0.012497984492210281\n",
      "tr CRPS 0.011850406430333376 val CRPS 0.012417645613641181\n",
      "tr CRPS 0.011859705553880153 val CRPS 0.0124372351383049\n",
      "tr CRPS 0.011834111014616993 val CRPS 0.012405667103252421\n",
      "tr CRPS 0.011842379257561198 val CRPS 0.01241529793050845\n",
      "tr CRPS 0.01179177196677145 val CRPS 0.01239384944516416\n",
      "tr CRPS 0.011792930528396977 val CRPS 0.01239830069688102\n",
      "tr CRPS 0.011762105101285877 val CRPS 0.012391052683590769\n",
      "tr CRPS 0.011756279621690775 val CRPS 0.012379022777102625\n",
      "tr CRPS 0.011791316950213244 val CRPS 0.012404741045885438\n",
      "tr CRPS 0.011758330032703077 val CRPS 0.012400389195972\n",
      "tr CRPS 0.01171591775917576 val CRPS 0.012365776345169785\n",
      "tr CRPS 0.011724939402995137 val CRPS 0.012374998808964114\n",
      "tr CRPS 0.011739910978929463 val CRPS 0.012377373123685339\n",
      "tr CRPS 0.011696091391029161 val CRPS 0.012373947967641841\n",
      "tr CRPS 0.011735349342680947 val CRPS 0.012389782391274981\n",
      "tr CRPS 0.011707566468026216 val CRPS 0.012391742647179125\n",
      "tr CRPS 0.01170666328864223 val CRPS 0.012371903555378204\n",
      "tr CRPS 0.011641797857494392 val CRPS 0.012354908449915849\n",
      "tr CRPS 0.01161686180246652 val CRPS 0.012364602778550168\n",
      "tr CRPS 0.011734883946889397 val CRPS 0.012447633958128458\n",
      "tr CRPS 0.011570706667311286 val CRPS 0.012347757963966097\n",
      "tr CRPS 0.01162882494444406 val CRPS 0.01232971362053217\n",
      "tr CRPS 0.011601549724771603 val CRPS 0.012344920696296167\n",
      "tr CRPS 0.011628190332416966 val CRPS 0.012354635338882914\n",
      "tr CRPS 0.011598618844336874 val CRPS 0.012341633173669582\n",
      "tr CRPS 0.011591044788747807 val CRPS 0.012380256829668288\n",
      "tr CRPS 0.011538228746862583 val CRPS 0.01231329841719272\n",
      "tr CRPS 0.011594924030968694 val CRPS 0.012352934873145559\n",
      "tr CRPS 0.011536090895942793 val CRPS 0.012330187861242315\n",
      "tr CRPS 0.011560520412584673 val CRPS 0.012337693546628198\n",
      "tr CRPS 0.011600473257589727 val CRPS 0.012356281753224962\n",
      "tr CRPS 0.011568284400183855 val CRPS 0.012327861503410113\n",
      "tr CRPS 0.011495686356443895 val CRPS 0.012314401993179323\n",
      "tr CRPS 0.011545832430960419 val CRPS 0.012341276529486562\n",
      "tr CRPS 0.011519543986720806 val CRPS 0.012318282092707133\n",
      "tr CRPS 0.01153350119350721 val CRPS 0.01231307920244238\n",
      "tr CRPS 0.011565146249062373 val CRPS 0.012355586010048441\n",
      "tr CRPS 0.011500914702951344 val CRPS 0.012343776760495745\n",
      "tr CRPS 0.011516310051218647 val CRPS 0.012346538994802193\n",
      "tr CRPS 0.011534307235842612 val CRPS 0.012356696744728344\n",
      "tr CRPS 0.01150721676057033 val CRPS 0.012352555544999515\n",
      "tr CRPS 0.011410477413255501 val CRPS 0.012323308390333668\n",
      "tr CRPS 0.011477274079212153 val CRPS 0.012343411805923963\n",
      "tr CRPS 0.011449221848808804 val CRPS 0.012320545638366173\n",
      "tr CRPS 0.011436988664738898 val CRPS 0.012321590559259082\n",
      "tr CRPS 0.011481252968533131 val CRPS 0.012362568488039976\n",
      "tr CRPS 0.011443685572101193 val CRPS 0.012350648957826971\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00071: early stopping\n",
      "Fold 1 score 0.01231307920244238\n",
      "### Fold 2 ###\n",
      "tr CRPS 0.036342820871178586 val CRPS 0.036108473723228236\n",
      "tr CRPS 0.015119603371298638 val CRPS 0.014974892175902352\n",
      "tr CRPS 0.013682840867324152 val CRPS 0.013539378900273659\n",
      "tr CRPS 0.013224370527012296 val CRPS 0.01307603202739575\n",
      "tr CRPS 0.012870066214416005 val CRPS 0.012728667036818948\n",
      "tr CRPS 0.01271206609094735 val CRPS 0.012580794912415452\n",
      "tr CRPS 0.01261916964385663 val CRPS 0.012506951921176806\n",
      "tr CRPS 0.012482525221514024 val CRPS 0.012382532512629883\n",
      "tr CRPS 0.012412026502279338 val CRPS 0.01232264193578116\n",
      "tr CRPS 0.012345393926413787 val CRPS 0.012274253723802997\n",
      "tr CRPS 0.012312055208337455 val CRPS 0.012264425633320928\n",
      "tr CRPS 0.012291273830264005 val CRPS 0.012247618524893405\n",
      "tr CRPS 0.012245868817657189 val CRPS 0.012211384302868979\n",
      "tr CRPS 0.01223755353701531 val CRPS 0.012215694184897463\n",
      "tr CRPS 0.012185997181377013 val CRPS 0.01216035978241691\n",
      "tr CRPS 0.012152145966610134 val CRPS 0.012151665105941028\n",
      "tr CRPS 0.012127583411925522 val CRPS 0.01215342601008319\n",
      "tr CRPS 0.012118359093716776 val CRPS 0.012124904763032952\n",
      "tr CRPS 0.01212392558191563 val CRPS 0.012173339556306015\n",
      "tr CRPS 0.01208547164723875 val CRPS 0.012104182297967619\n",
      "tr CRPS 0.012034709393632412 val CRPS 0.012089438527223094\n",
      "tr CRPS 0.01201604354783692 val CRPS 0.012074423917966435\n",
      "tr CRPS 0.01204622963476646 val CRPS 0.012094798867183267\n",
      "tr CRPS 0.012000761836797434 val CRPS 0.01204771129291187\n",
      "tr CRPS 0.012059779040850746 val CRPS 0.012125170398870413\n",
      "tr CRPS 0.011982032686657368 val CRPS 0.01206267293526765\n",
      "tr CRPS 0.01196910476472898 val CRPS 0.012043254447644761\n",
      "tr CRPS 0.011957838280014644 val CRPS 0.012021884659110199\n",
      "tr CRPS 0.011911189862592129 val CRPS 0.012024867058748704\n",
      "tr CRPS 0.011928235189148489 val CRPS 0.012019580527665255\n",
      "tr CRPS 0.011924452824631119 val CRPS 0.01202753418416106\n",
      "tr CRPS 0.011884189728556512 val CRPS 0.01201350835835627\n",
      "tr CRPS 0.011909348378958183 val CRPS 0.012044685459741153\n",
      "tr CRPS 0.011882799048737637 val CRPS 0.012021127901457063\n",
      "tr CRPS 0.011835137155496878 val CRPS 0.01199587903401804\n",
      "tr CRPS 0.011841169200095206 val CRPS 0.011995026642948561\n",
      "tr CRPS 0.011855369481978956 val CRPS 0.012012159358591089\n",
      "tr CRPS 0.011840502070861847 val CRPS 0.012011645087204589\n",
      "tr CRPS 0.011845905870597086 val CRPS 0.012036676434023957\n",
      "tr CRPS 0.011843230791315596 val CRPS 0.01203930055872348\n",
      "tr CRPS 0.011810157208384029 val CRPS 0.012003660320771613\n",
      "tr CRPS 0.011771620117318301 val CRPS 0.011954280940938625\n",
      "tr CRPS 0.011768916793484236 val CRPS 0.011970842880758177\n",
      "tr CRPS 0.011784517567500697 val CRPS 0.011974728470860533\n",
      "tr CRPS 0.011778155623895082 val CRPS 0.011974629099171295\n",
      "tr CRPS 0.0117176023490074 val CRPS 0.011926876859421356\n",
      "tr CRPS 0.011761000475157718 val CRPS 0.011963436934406668\n",
      "tr CRPS 0.011745061140112369 val CRPS 0.011948939553280323\n",
      "tr CRPS 0.011770562649909765 val CRPS 0.01198254727635412\n",
      "tr CRPS 0.011746590082081126 val CRPS 0.011974026740589193\n",
      "tr CRPS 0.011772439256529632 val CRPS 0.011997778349094353\n",
      "tr CRPS 0.011684875188252614 val CRPS 0.0119537758908702\n",
      "tr CRPS 0.011740472534393203 val CRPS 0.011984422594721258\n",
      "tr CRPS 0.011691516418425496 val CRPS 0.011955429219681043\n",
      "tr CRPS 0.011681807863002013 val CRPS 0.011951705363672793\n",
      "tr CRPS 0.011663380257558836 val CRPS 0.011959945918947973\n",
      "tr CRPS 0.011692659644050162 val CRPS 0.011957715264048808\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00057: early stopping\n",
      "Fold 2 score 0.011926876859421356\n",
      "### Fold 3 ###\n",
      "tr CRPS 0.03574915538087632 val CRPS 0.03583002863913641\n",
      "tr CRPS 0.014701400608383597 val CRPS 0.014716044913173378\n",
      "tr CRPS 0.013638726451202484 val CRPS 0.013637550487797617\n",
      "tr CRPS 0.013195756910221356 val CRPS 0.013229021868723257\n",
      "tr CRPS 0.012807788472180736 val CRPS 0.012874053195216353\n",
      "tr CRPS 0.012629266754134574 val CRPS 0.012739178163505237\n",
      "tr CRPS 0.012550466147520586 val CRPS 0.01269118844810578\n",
      "tr CRPS 0.012490620573189993 val CRPS 0.012643092298914933\n",
      "tr CRPS 0.012341026309219948 val CRPS 0.012538961392528422\n",
      "tr CRPS 0.012304862837702008 val CRPS 0.012495541845132598\n",
      "tr CRPS 0.012234057158563537 val CRPS 0.012458063993692552\n",
      "tr CRPS 0.012203819231219798 val CRPS 0.012428696210917675\n",
      "tr CRPS 0.012190931488574482 val CRPS 0.012418447441631477\n",
      "tr CRPS 0.012152182329470131 val CRPS 0.012411356468456888\n",
      "tr CRPS 0.012123814495369869 val CRPS 0.012415410964893351\n",
      "tr CRPS 0.012111360464431052 val CRPS 0.0123989501290875\n",
      "tr CRPS 0.012093886636705154 val CRPS 0.012385564568840669\n",
      "tr CRPS 0.012078266448572222 val CRPS 0.012355512270411635\n",
      "tr CRPS 0.012090464736548647 val CRPS 0.012388145620501358\n",
      "tr CRPS 0.01208173524852086 val CRPS 0.0123763141334551\n",
      "tr CRPS 0.011981589502173524 val CRPS 0.012310934722885011\n",
      "tr CRPS 0.0119799132943039 val CRPS 0.012292649838090511\n",
      "tr CRPS 0.011943660024797804 val CRPS 0.012273727463189636\n",
      "tr CRPS 0.011963114844607063 val CRPS 0.012296251693482115\n",
      "tr CRPS 0.0119098605909766 val CRPS 0.012258425268274867\n",
      "tr CRPS 0.011890990586107385 val CRPS 0.012263084696912677\n",
      "tr CRPS 0.011935419816984425 val CRPS 0.012243729692731648\n",
      "tr CRPS 0.011903077695466257 val CRPS 0.01221586011845528\n",
      "tr CRPS 0.011879424000577135 val CRPS 0.012231786122344986\n",
      "tr CRPS 0.011846485945848374 val CRPS 0.012224570539391657\n",
      "tr CRPS 0.011826135152011915 val CRPS 0.012220759295027419\n",
      "tr CRPS 0.011846478848975153 val CRPS 0.012217179388400185\n",
      "tr CRPS 0.011826351834490425 val CRPS 0.012215829783482015\n",
      "tr CRPS 0.011845920991426085 val CRPS 0.012220840698943292\n",
      "tr CRPS 0.011791590714259285 val CRPS 0.012183422497215126\n",
      "tr CRPS 0.011784157685022445 val CRPS 0.012200258537398421\n",
      "tr CRPS 0.01178957092701375 val CRPS 0.012177929388218765\n",
      "tr CRPS 0.011798938370885966 val CRPS 0.012175014242805059\n",
      "tr CRPS 0.011769532125816476 val CRPS 0.012215736302903643\n",
      "tr CRPS 0.011784784603980785 val CRPS 0.01222392128173057\n",
      "tr CRPS 0.011720359208051001 val CRPS 0.012160442472885509\n",
      "tr CRPS 0.011711445537647452 val CRPS 0.012162828045192644\n",
      "tr CRPS 0.011774465022471755 val CRPS 0.012203724316797619\n",
      "tr CRPS 0.011694938825175617 val CRPS 0.012159758159172898\n",
      "tr CRPS 0.01171472899412141 val CRPS 0.012183332116897512\n",
      "tr CRPS 0.011721091180503273 val CRPS 0.01218638915143029\n",
      "tr CRPS 0.01168546090103814 val CRPS 0.012176237404366992\n",
      "tr CRPS 0.011658438713420479 val CRPS 0.012139345200679788\n",
      "tr CRPS 0.011660952466237988 val CRPS 0.012143387895473394\n",
      "tr CRPS 0.01167252539712031 val CRPS 0.012192013538264393\n",
      "tr CRPS 0.011639284747758685 val CRPS 0.012172223610641356\n",
      "tr CRPS 0.01163594962369017 val CRPS 0.012175100397158675\n",
      "tr CRPS 0.011631171311652998 val CRPS 0.012155313811215535\n",
      "tr CRPS 0.011608456504307736 val CRPS 0.012118066965489808\n",
      "tr CRPS 0.011643992666026252 val CRPS 0.012158374109947407\n",
      "tr CRPS 0.01160886783140685 val CRPS 0.012161617321621928\n",
      "tr CRPS 0.01161509763194894 val CRPS 0.0121697261985107\n",
      "tr CRPS 0.011600255620328492 val CRPS 0.012150011554236551\n",
      "tr CRPS 0.011579320768185308 val CRPS 0.012130874956083209\n",
      "tr CRPS 0.011580771517512127 val CRPS 0.012146639925724768\n",
      "tr CRPS 0.011556176091210298 val CRPS 0.012128951185372458\n",
      "tr CRPS 0.011606368735931719 val CRPS 0.012176432208188055\n",
      "tr CRPS 0.011584017315250812 val CRPS 0.012129452679050213\n",
      "tr CRPS 0.011578251960675162 val CRPS 0.012137642896852693\n",
      "tr CRPS 0.011529936211086889 val CRPS 0.0121391586030534\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00065: early stopping\n",
      "Fold 3 score 0.012118066965489808\n",
      "### Fold 4 ###\n",
      "tr CRPS 0.036029519846974424 val CRPS 0.036083167507344235\n",
      "tr CRPS 0.014980000620457231 val CRPS 0.014920805681898514\n",
      "tr CRPS 0.013817416941636513 val CRPS 0.01378748223020356\n",
      "tr CRPS 0.013124290440493066 val CRPS 0.013096616361621917\n",
      "tr CRPS 0.01290105698743723 val CRPS 0.012905632607817925\n",
      "tr CRPS 0.01263561444539039 val CRPS 0.012651107906819435\n",
      "tr CRPS 0.012546949901731204 val CRPS 0.012624194058901974\n",
      "tr CRPS 0.01247354539666513 val CRPS 0.012602889024838795\n",
      "tr CRPS 0.01239958586089538 val CRPS 0.012502575909324052\n",
      "tr CRPS 0.012315204014573105 val CRPS 0.012429727552500222\n",
      "tr CRPS 0.012309966493831904 val CRPS 0.012452686222460273\n",
      "tr CRPS 0.012242720864843874 val CRPS 0.012392736389880081\n",
      "tr CRPS 0.012195013437945235 val CRPS 0.012386191439939118\n",
      "tr CRPS 0.01216506292428521 val CRPS 0.01232632488285893\n",
      "tr CRPS 0.012129794306353126 val CRPS 0.012314194270082625\n",
      "tr CRPS 0.012122999700305337 val CRPS 0.012295081732685769\n",
      "tr CRPS 0.012092169265666206 val CRPS 0.012285903830477911\n",
      "tr CRPS 0.012062038390354241 val CRPS 0.01228565094097821\n",
      "tr CRPS 0.012019444242248833 val CRPS 0.012234571042281548\n",
      "tr CRPS 0.012024630844990782 val CRPS 0.012274827203220855\n",
      "tr CRPS 0.011996164690394585 val CRPS 0.012255656226315225\n",
      "tr CRPS 0.011982943440585772 val CRPS 0.012220209453361724\n",
      "tr CRPS 0.011992691239074335 val CRPS 0.012211476669923517\n",
      "tr CRPS 0.011945568815879722 val CRPS 0.012195905381028676\n",
      "tr CRPS 0.011917964148498323 val CRPS 0.012197907103085031\n",
      "tr CRPS 0.011941484192114967 val CRPS 0.012222358509349789\n",
      "tr CRPS 0.0119377588561884 val CRPS 0.012221347707340464\n",
      "tr CRPS 0.011913226896462658 val CRPS 0.012232616979221919\n",
      "tr CRPS 0.011887144421150743 val CRPS 0.012162825260839687\n",
      "tr CRPS 0.011864837308893615 val CRPS 0.012201882857118176\n",
      "tr CRPS 0.011848582562171372 val CRPS 0.012216763712277241\n",
      "tr CRPS 0.011851080108285549 val CRPS 0.012152705606794248\n",
      "tr CRPS 0.01183564255005944 val CRPS 0.012132540167295014\n",
      "tr CRPS 0.011851835551268147 val CRPS 0.012169427857525705\n",
      "tr CRPS 0.01179849791142859 val CRPS 0.012164259987204856\n",
      "tr CRPS 0.011809913216612311 val CRPS 0.012160849189239207\n",
      "tr CRPS 0.01176503920114197 val CRPS 0.012134804608331065\n",
      "tr CRPS 0.011775808688754613 val CRPS 0.012147022034600087\n",
      "tr CRPS 0.011792812953324884 val CRPS 0.01215111814261884\n",
      "tr CRPS 0.01171343440421939 val CRPS 0.012106481387102188\n",
      "tr CRPS 0.01175982099138732 val CRPS 0.012159534976908212\n",
      "tr CRPS 0.011727170438921838 val CRPS 0.012113779921939377\n",
      "tr CRPS 0.011707646582561189 val CRPS 0.012136927596690569\n",
      "tr CRPS 0.011719047535111576 val CRPS 0.012110113659435668\n",
      "tr CRPS 0.011734578115753104 val CRPS 0.012136494031500578\n",
      "tr CRPS 0.011697213276050809 val CRPS 0.012161130250014994\n",
      "tr CRPS 0.011709073083936185 val CRPS 0.012166767222173396\n",
      "tr CRPS 0.011655872098426664 val CRPS 0.012096366433348403\n",
      "tr CRPS 0.011661798145966582 val CRPS 0.012138209300200712\n",
      "tr CRPS 0.011642986086152274 val CRPS 0.012080516071240159\n",
      "tr CRPS 0.011623318356780932 val CRPS 0.012085976588179701\n",
      "tr CRPS 0.011662370868554216 val CRPS 0.01215961115140959\n",
      "tr CRPS 0.011644984164659136 val CRPS 0.012115200329027631\n",
      "tr CRPS 0.01160920876183047 val CRPS 0.01210832619218804\n",
      "tr CRPS 0.01158552606353835 val CRPS 0.012134445045432339\n",
      "tr CRPS 0.011617647667012494 val CRPS 0.01213769172474487\n",
      "tr CRPS 0.0115876468260736 val CRPS 0.012093093557469483\n",
      "tr CRPS 0.011589751135969023 val CRPS 0.012095668802211815\n",
      "tr CRPS 0.011683880594073067 val CRPS 0.012171410478895694\n",
      "tr CRPS 0.011566918059713584 val CRPS 0.012133621238787376\n",
      "tr CRPS 0.01156034426666467 val CRPS 0.012114856531444753\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00061: early stopping\n",
      "Fold 4 score 0.012080516071240159\n",
      "OOF Score 0.012109636031335814\n",
      "1 Iteration score 0.012075011534854277\n",
      "NN Score 0.012075011534854277\n",
      "done nn training 467.79014134407043\n"
     ]
    }
   ],
   "source": [
    "final_score = 0\n",
    "gamblers = []\n",
    "scores = []\n",
    "folds = 4\n",
    "\n",
    "iterations = 5\n",
    "cv = \"cv\"\n",
    "if cv == \"cv\":\n",
    "    iterations = 1\n",
    "\n",
    "for it in range(iterations):\n",
    "    print(f'Iteration {it+1}')    \n",
    "    gambler = Gambler(len(useful_raw_features))\n",
    "    nn_ids, nn_predictions, nn_targets = train_loop(gambler, play_emin, folds, useful_raw_features, cv=cv)\n",
    "    nn_raw = nn_predictions.copy()\n",
    "    \n",
    "    for i in range(len(nn_predictions)):\n",
    "        temp_yard = play_df.loc[play_df[\"PlayId\"]==nn_ids[i],\"YardsFromOwnGoal\"].iloc[0]\n",
    "        nn_predictions[i][-temp_yard:] = 1\n",
    "        nn_predictions[i][:99-temp_yard] = 0\n",
    "\n",
    "    nn_score = ((nn_predictions - nn_targets) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets.shape[0])\n",
    "    scores.append(nn_score)\n",
    "    print(f'{it+1} Iteration score', nn_score)    \n",
    "    \n",
    "    gamblers.append(gambler)\n",
    "    final_score+= nn_score/iterations\n",
    "\n",
    "print(f'NN Score', final_score)\n",
    "\n",
    "timer.time(\"done nn training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_pocket = play_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "pred_col = [\n",
    "    \"YardsFromOwnGoal\", \"Down\", \"Distance\", \n",
    "    \"DefendersInTheBox\", \"S\", \"A\", \"Dis\",\n",
    "    \"rounded_dir\", #\"rounded_orient\",  #\"Orientation\", \n",
    "    \"OffenseFormation\", # \"GameWeather\",\n",
    "    \"rush_yardline_dist\",\n",
    "    \"is_old\", \"std_Y\",\n",
    "    \"min_df_dist\", \"mean_df_dist\", \"std_df_dist\",\n",
    "    \"min_df_dist2\", \"mean_df_dist2\", \"std_df_dist2\",\n",
    "    \"min_df_dist3\", \"mean_df_dist3\", \"std_df_dist3\",\n",
    "    \"std_df_dist4\",\n",
    "    \"min_tt_dist\", \n",
    "    \"mean_tt_dist\",\n",
    "    \"min_tt_dist3\", \n",
    "    \"min_tt_dist4\",\n",
    "    \"closest_A\", \"closest_mark_dist\",\n",
    "    \"closest3_S\", \"closest3_A\",\n",
    "    \"dist_to_centroid\",\n",
    "    \"min_unblocked_dist3\", \"min_blocked_dist3\",\n",
    "    \"mean_dist3_diffmin1\",\n",
    "    \"mean_dist3_diffmax3\", \"mean_dist3_diffmin3\",\n",
    "    \"max_df_cnt3\",\n",
    "    \"free_width3\",\n",
    "    \"closest_next_dist\", \"closest3_prev_dist\"\n",
    "]\n",
    "emin_col = [\n",
    "    # Really good features that I didn't have\n",
    "    'S_horizontal_mean_def', 'S_horizontal_rusher', 'A_horizontal_rusher', #+5\n",
    "    'dist_rusher_end_mean_def', 'dist_rusher_end_min_def', # +5?\n",
    "    'dist_yard_mean_def', 'dist_yard_min_def', 'dist_yard_min_off', # +2?\n",
    "    'dist_rusher_end_def_mean', #+2?\n",
    "    'X_span_def', 'X_span_off', 'rectangle_off', # +1?\n",
    "    'X_end_std_def', # +1?\n",
    "    'angle_max_def', 'angle_std_off', 'angle_end_max_def', 'angle_end_min_def', 'angle_min_def',\n",
    "    'X_std_def', 'X_min_off', 'dist_Y_end_mean_off', 'A_std_off',\n",
    "    'dist_rusher_end_std_def', 'dist_X_max_def', 'dist_X_mean_off', 'dist_center'# +1?\n",
    "]\n",
    "pred_col += emin_col\n",
    "print(len(pred_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for target_val=-5\n",
      "model for target_val=-4\n",
      "model for target_val=-3\n",
      "model for target_val=-2\n",
      "model for target_val=-1\n",
      "model for target_val=0\n",
      "model for target_val=1\n",
      "model for target_val=2\n",
      "model for target_val=3\n",
      "model for target_val=4\n",
      "model for target_val=5\n",
      "model for target_val=6\n",
      "model for target_val=7\n",
      "model for target_val=8\n",
      "model for target_val=9\n",
      "model for target_val=10\n",
      "model for target_val=11\n",
      "model for target_val=12\n",
      "model for target_val=13\n",
      "model for target_val=14\n",
      "model for target_val=15\n",
      "model for target_val=16\n",
      "model for target_val=17\n",
      "model for target_val=18\n",
      "model for target_val=19\n",
      "model for target_val=20\n",
      "0.2677199914763317\n",
      "done lgbm training 240.1024100780487\n"
     ]
    }
   ],
   "source": [
    "dry_run = False\n",
    "trainer = GoldenTrainer(pred_col, dry_run=dry_run)\n",
    "models = trainer.train_models(play_pocket)\n",
    "timer.time(\"done lgbm training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19536864519563482\n",
      "0.3141691065566498\n",
      "0.4429065743944637\n"
     ]
    }
   ],
   "source": [
    "temp = train_df[train_df[\"Season\"] == 2018]\n",
    "mean_df = temp.groupby(\"Yards\")[\"GameId\"].count().reset_index()\n",
    "mean_df[\"cumsum\"] = mean_df[\"GameId\"].cumsum()\n",
    "mean_df[\"cumsum\"] /= mean_df[\"cumsum\"].max()\n",
    "mean_val_dict = dict(zip(mean_df[\"Yards\"], mean_df[\"cumsum\"]))\n",
    "for i in range(3):\n",
    "    print(mean_val_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(preds):\n",
    "    np.clip(preds, 0, 1)\n",
    "    for i in range(preds.shape[0]):\n",
    "        preds[i] = sorted(preds[i])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LGB Score 0.012128549778693067\n"
     ]
    }
   ],
   "source": [
    "predictor = GoldenPredictor(pred_col, mean_val_dict, models, feature_factory)\n",
    "lgb_predictions = predictor.make_oof_pred(play_pocket)\n",
    "lgb_raw = lgb_predictions.copy()\n",
    "lgb_predictions = np.clip(lgb_predictions, 0, 1)\n",
    "lgb_predictions = post_process(lgb_predictions)\n",
    "\n",
    "for i in range(len(lgb_predictions)):\n",
    "    temp_yard = play_df.loc[play_df[\"PlayId\"]==nn_ids[i],\"YardsFromOwnGoal\"].iloc[0]\n",
    "    lgb_predictions[i][-temp_yard:] = 1\n",
    "    lgb_predictions[i][:99-temp_yard] = 0\n",
    "        \n",
    "targets = play_pocket['Yards']\n",
    "lgb_targets = np.zeros((targets.shape[0], 199))\n",
    "for idx, target in enumerate(list(targets)):\n",
    "    lgb_targets[idx][99 + target] = 1\n",
    "    \n",
    "lgb_targets = np.clip(np.cumsum(lgb_targets, axis=1), 0, 1)            \n",
    "lgb_score = ((lgb_predictions - lgb_targets) ** 2).sum(axis=1).sum(axis=0) / (199 * lgb_targets.shape[0])\n",
    "print(f'Final LGB Score', lgb_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triple Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23171, 317)\n",
      "done fe 73.52923655509949\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2020/train.csv\")\n",
    "\n",
    "exclude_global_feature = ['Week','Humidity', 'Stadium', 'Location', 'Turf', 'GameWeather',\n",
    "                          'Temperature',  'WindSpeed', 'WindDirection', 'Season',\n",
    "                           'HomeScoreBeforePlay', 'VisitorScoreBeforePlay', 'YardLine_std','YardLine']#\n",
    "exclude_personal_feature = [ 'NflId',\"player's name\",'NflIdRusher', 'Orientation', 'Dir', 'PlayerWeight', 'PlayerHeight']\n",
    "exclude_feature = ['Quarter','Yards', 'PlayId', 'GameId'] + exclude_global_feature + exclude_personal_feature\n",
    "\n",
    "category_features = ['DefendersInTheBox', 'Position', 'OffenseFormation', 'DefensePersonnel']# 'Quarter', 'Down',,\n",
    "#player_continuous_feature = ['speed_sin_Dir', 'speed_cos_Dir', 'acc_sin_Dir', 'acc_cos_Dir', 'X', 'Y', 'dx', 'dy']\n",
    "player_continuous_feature = ['speed_sin_Dir', 'speed_cos_Dir', 'acc_sin_Dir', 'acc_cos_Dir', 'X', 'Y', \"x1\", \"y1\", \"x2\", \"y2\"]\n",
    "absolute_player_continuous_feature = []\n",
    "\n",
    "# TODO: age\n",
    "player_category_feature = ['Position','JerseyNumber']\n",
    "# TODO: JerseyNumber\n",
    "\n",
    "# team features \n",
    "friend_continuous_features = ['friend' + str(i) + '_cont_' + cont_feature for cont_feature in player_continuous_feature for i in range(10)]\n",
    "friend_category_features = ['friend' + str(i) + '_cat#' + cont_feature for cont_feature in player_category_feature for i in range(10)]\n",
    "ravel_continuous_features = ['ravel' + str(i) + '_cont_' + cont_feature for cont_feature in player_continuous_feature for i in range(11)]\n",
    "ravel_category_features = ['ravel' + str(i) + '_cat#' + cont_feature for cont_feature in player_category_feature for i in range(11)]\n",
    "friends_position = [\"friend\" + str(i) + \"_position\" for i in range(10)]\n",
    "ravel_position = [\"ravel\" + str(i) + \"_position\" for i in range(11)]\n",
    "\n",
    "team_player_feature = friend_continuous_features + friend_category_features + ravel_continuous_features + ravel_category_features\n",
    "\n",
    "\n",
    "class GroupDataWrap(object):\n",
    "    def __init__(self, np_arr, columns, column_map=None):\n",
    "        self.np_arr = np_arr\n",
    "        self.columns = columns\n",
    "        self.column_map = column_map if column_map is not None else dict([(pair[1], pair[0]) for pair in enumerate(columns)])\n",
    "        \n",
    "    def __getitem__(self, col):\n",
    "        if isinstance(col, str):\n",
    "            return self.np_arr[:,self.column_map[col]]\n",
    "        else:\n",
    "            return GroupDataWrap(self.np_arr[col,:], self.columns)\n",
    "\n",
    "def fe(df):\n",
    "    mean_old, mean_new, std_old, std_new = 2.435519556913685, 2.7570316419451517, 1.2929623410155855, 1.4551321358655551\n",
    "    df[\"S\"] = np.where(df[\"Season\"] >= 2018, (df[\"S\"]-mean_new) / std_new * std_old + mean_old, df[\"S\"])\n",
    "    mean_old, mean_new, std_old, std_new = 1.5895792207792045, 1.7819953460610594, 0.8795106467756848, 1.060305722313926\n",
    "    df[\"A\"] = np.where(df[\"Season\"] >= 2018, (df[\"A\"]-mean_new) / std_new * std_old + mean_old, df[\"A\"])\n",
    "    \n",
    "    df[\"VisitorTeamAbbr\"] = np.where(df[\"VisitorTeamAbbr\"] == \"ARI\", \"ARZ\", df[\"VisitorTeamAbbr\"])\n",
    "    df[\"HomeTeamAbbr\"] = np.where(df[\"HomeTeamAbbr\"] == \"ARI\", \"ARZ\", df[\"HomeTeamAbbr\"])\n",
    "    df[\"VisitorTeamAbbr\"] = np.where(df[\"VisitorTeamAbbr\"] == \"BAL\", \"BLT\", df[\"VisitorTeamAbbr\"])\n",
    "    df[\"HomeTeamAbbr\"] = np.where(df[\"HomeTeamAbbr\"] == \"BAL\", \"BLT\", df[\"HomeTeamAbbr\"])\n",
    "    df[\"VisitorTeamAbbr\"] = np.where(df[\"VisitorTeamAbbr\"] == \"CLE\", \"CLV\", df[\"VisitorTeamAbbr\"])\n",
    "    df[\"HomeTeamAbbr\"] = np.where(df[\"HomeTeamAbbr\"] == \"CLE\", \"CLV\", df[\"HomeTeamAbbr\"])\n",
    "    df[\"VisitorTeamAbbr\"] = np.where(df[\"VisitorTeamAbbr\"] == \"HOU\", \"HST\", df[\"VisitorTeamAbbr\"])\n",
    "    df[\"HomeTeamAbbr\"] = np.where(df[\"HomeTeamAbbr\"] == \"HOU\", \"HST\", df[\"HomeTeamAbbr\"])\n",
    "\n",
    "    df[\"PossessionTeam\"] = np.where(df[\"PossessionTeam\"] == \"ARI\", \"ARZ\", df[\"PossessionTeam\"])\n",
    "    df[\"FieldPosition\"] = np.where(df[\"FieldPosition\"] == \"ARI\", \"ARZ\", df[\"FieldPosition\"])\n",
    "    df[\"PossessionTeam\"] = np.where(df[\"PossessionTeam\"] == \"BAL\", \"BLT\", df[\"PossessionTeam\"])\n",
    "    df[\"FieldPosition\"] = np.where(df[\"FieldPosition\"] == \"BAL\", \"BLT\", df[\"FieldPosition\"])\n",
    "    df[\"PossessionTeam\"] = np.where(df[\"PossessionTeam\"] == \"CLE\", \"CLV\", df[\"PossessionTeam\"])\n",
    "    df[\"FieldPosition\"] = np.where(df[\"FieldPosition\"] == \"CLE\", \"CLV\", df[\"FieldPosition\"])\n",
    "    df[\"PossessionTeam\"] = np.where(df[\"PossessionTeam\"] == \"HOU\", \"HST\", df[\"PossessionTeam\"])\n",
    "    df[\"FieldPosition\"] = np.where(df[\"FieldPosition\"] == \"HOU\", \"HST\", df[\"FieldPosition\"])\n",
    "    \n",
    "    for col in ['X', 'Y', 'S', 'A', 'Dis', 'Orientation','Dir','YardLine','Distance', 'DefendersInTheBox']:\n",
    "        df[\"temp\"] = df.groupby([\"PlayId\",\"Team\"])[col].transform(\"mean\")\n",
    "        df[\"Orientation\"] = df[\"Orientation\"].fillna(df[\"temp\"])\n",
    "\n",
    "    del df[\"temp\"]\n",
    "    \n",
    "    df.fillna(0, inplace=True)    \n",
    "    \n",
    "    df[\"team_abbr\"] = np.where(df[\"Team\"] == \"home\", df[\"HomeTeamAbbr\"], df[\"VisitorTeamAbbr\"])\n",
    "    df[\"reval_abbr\"] = np.where(df[\"Team\"] == \"away\", df[\"HomeTeamAbbr\"], df[\"VisitorTeamAbbr\"])\n",
    "\n",
    "    df.loc[df['PlayDirection'] == 'left', 'X'] = 120 - df.loc[df['PlayDirection'] == 'left', 'X']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Y'] = (160 / 3) - df.loc[df['PlayDirection'] == 'left', 'Y']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Orientation'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Orientation'], 360)\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Dir'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Dir'], 360)    \n",
    "        \n",
    "    df['FieldPosition'].fillna('', inplace=True)\n",
    "    \n",
    "  \n",
    "    df['speed_sin_Dir'] = df['S'] * np.sin(df['Dir'] / 180 * np.pi)\n",
    "    df['speed_cos_Dir'] = df['S'] * np.cos(df['Dir'] / 180 * np.pi)\n",
    "    \n",
    "    df['acc_sin_Dir'] = df['A'] * np.sin(df['Dir'] / 180 * np.pi)\n",
    "    df['acc_cos_Dir'] = df['A'] * np.cos(df['Dir'] / 180 * np.pi)\n",
    "    \n",
    "    df[\"dxdy_dir\"] = (540 - (df[\"Dir\"] + 90)) % 360\n",
    "    df[\"dy\"] = np.sin(np.deg2rad(df[\"dxdy_dir\"]))\n",
    "    df[\"dx\"] = np.cos(np.deg2rad(df[\"dxdy_dir\"]))\n",
    "    df[\"x1\"] = df[\"X\"] + (df[\"dx\"] * (df[\"S\"]))\n",
    "    df[\"y1\"] = df[\"Y\"] + (df[\"dy\"] * (df[\"S\"]))\n",
    "    df[\"x2\"] = df[\"X\"] + (df[\"dx\"] * (df[\"S\"]*2))\n",
    "    df[\"y2\"] = df[\"Y\"] + (df[\"dy\"] * (df[\"S\"]*2))\n",
    "    df.drop(['dxdy_dir'], inplace=True, axis=1)\n",
    "    \n",
    "    df[\"is_old\"] = np.where(df[\"Season\"]<2018, 1, 0)\n",
    "    \n",
    "    df[\"YardLine_std\"] = np.where(df[\"PossessionTeam\"] == df[\"FieldPosition\"], df[\"YardLine\"]+10, 110-df[\"YardLine\"])\n",
    "    df['YardLine_std_diff'] = df['X'] - df['YardLine_std']\n",
    "    \n",
    "    grass_labels = tuple(['grass', 'natural grass', 'natural', 'naturall grass'])\n",
    "    df['Grass'] = np.where(df.Turf.str.lower().isin([grass_labels]), 1, 0)\n",
    "\n",
    "\n",
    "    rusher_df = df[df['NflId'] == df['NflIdRusher']]   \n",
    "    \n",
    "    # team features\n",
    "    # fields: [rusher nfl id, PlayId] [friends fields] [reval fields]\n",
    "    val_rows = []\n",
    "    val_schema = ['NflId', 'PlayId'] + team_player_feature\n",
    "    \n",
    "    for groupname, group_df in (df.groupby(['PlayId'])):\n",
    "        row_fields = []\n",
    "        \n",
    "        group_df = GroupDataWrap(group_df.to_numpy(), group_df.columns)\n",
    "        \n",
    "        runner = group_df[group_df['NflId'] == group_df['NflIdRusher']]   \n",
    "        friends = group_df[(group_df['PossessionTeam'] == group_df['team_abbr']) & (group_df['NflId'] != group_df['NflIdRusher'])]\n",
    "        ravel = group_df[group_df['PossessionTeam'] == group_df['reval_abbr']]\n",
    "        \n",
    "        row_fields.append(runner['NflId'][0])\n",
    "        row_fields.append(runner['PlayId'][0])\n",
    "        for cont_feature in player_continuous_feature:\n",
    "            if cont_feature in absolute_player_continuous_feature:\n",
    "                row_fields += friends[cont_feature].tolist()\n",
    "            else:\n",
    "                row_fields += (friends[cont_feature] - runner[cont_feature][0]).tolist()\n",
    "        for cat_feature in player_category_feature:\n",
    "            row_fields += friends[cat_feature].tolist()\n",
    "        for cont_feature in player_continuous_feature:\n",
    "            if cont_feature in absolute_player_continuous_feature:\n",
    "                row_fields += ravel[cont_feature].tolist()\n",
    "            else:\n",
    "                row_fields += (ravel[cont_feature] - runner[cont_feature][0]).tolist()\n",
    "        for cat_feature in player_category_feature:\n",
    "            row_fields += ravel[cat_feature].tolist()\n",
    "            \n",
    "        val_rows.append(row_fields)\n",
    "            \n",
    "    team_feature_df = pd.DataFrame(val_rows, columns=val_schema)\n",
    "    \n",
    "    df = rusher_df.merge(team_feature_df, on=['NflId', 'PlayId'])\n",
    "\n",
    "    return df\n",
    "\n",
    "timer = GoldenTimer()\n",
    "train_df = fe(train_df)\n",
    "train_df.fillna(0, inplace=True)\n",
    "print(train_df.shape)\n",
    "timer.time(\"done fe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MAX = 54\n",
    "X_MAX = 120\n",
    "X_FORWARD = 20\n",
    "\n",
    "RESOLUTION = 2\n",
    "\n",
    "def DropoutDense(units, activation=\"linear\", name=None, dropout_ratio=None):\n",
    "    if dropout_ratio is None:\n",
    "        return Dense(units, name=name, activation=activation)\n",
    "    else:\n",
    "        dense = Dense(units, activation=activation)\n",
    "        dropout = Dropout(dropout_ratio, name=name)\n",
    "        return lambda x: dropout(dense(x))\n",
    "\n",
    "\n",
    "class NLF_NN(object):\n",
    "    def __init__(self, continuous_features, category_features, label, epoch, batch_size=2000, \n",
    "                 common_embedding_size=8, specified_embedding_map=None, learning_rate=0.005, \n",
    "                 player_continuous_feature=None, player_category_feature=None):\n",
    "        self.continuous_features = [f for f in continuous_features if f != label]\n",
    "        self.category_features = category_features\n",
    "        self.common_embedding_size = common_embedding_size\n",
    "        self.specified_embedding_map = specified_embedding_map if specified_embedding_map is not None else dict()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.label = label\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.player_continuous_feature = player_continuous_feature\n",
    "        self.player_category_feature = player_category_feature\n",
    "        \n",
    "        \n",
    "    def crps_loss_by_label_tensor(self, y_true, y_pred):\n",
    "        y_true = K.clip(K.cumsum(y_true, axis=-1), 0, 1)\n",
    "        y_pred = K.clip(K.cumsum(y_pred, axis=-1), 0, 1)\n",
    "        return K.mean(K.square(y_true - y_pred))\n",
    "    \n",
    "    def crps_loss_by_label_np(self, y_true, y_pred):\n",
    "        return np.mean(np.square(y_true - y_pred))\n",
    "    \n",
    "    def make_category_embedding(self, cat_input, category_list, cat_size_map, name=None, embedding_size=None):\n",
    "        def _inner_make_category_embedding(cat_input):\n",
    "            cat_emb_res = []\n",
    "            for i in range(len(category_list)):\n",
    "                cat_field_name = category_list[i]\n",
    "                emb_size = embedding_size if embedding_size is not None else self.specified_embedding_map.get(cat_field_name, self.common_embedding_size)\n",
    "                cat_size = cat_size_map[cat_field_name]\n",
    "                emb_tensor = Embedding(cat_size, emb_size)(cat_input[:,i])\n",
    "                cat_emb_res.append(emb_tensor)\n",
    "                \n",
    "            return K.concatenate(cat_emb_res, axis=-1)\n",
    "        \n",
    "        return Lambda(_inner_make_category_embedding, name=name)(cat_input)\n",
    "    \n",
    "    def make_team_embedding(self, cont_features, cat_features, cat_size_map):\n",
    "        # l1:256 cont dense\n",
    "        # l2:combined cont and cat emb\n",
    "        # l3:128 dense\n",
    "        \n",
    "        cont_dense = Dense(256, activation='relu')\n",
    "        comb_dense_ = Dense(128, activation='relu')\n",
    "        comb_bn = BatchNormalization()\n",
    "        comb_dense = lambda x: comb_bn(comb_dense_(x))\n",
    "        out_dense = DropoutDense(64, activation='relu')\n",
    "        \n",
    "        team_embeddings = []\n",
    "        for i in range(len(cont_features)):\n",
    "            hidden1 = cont_dense(cont_features[i])\n",
    "#            cat_emb = self.make_category_embedding(cat_features[i], self.player_category_feature, cat_size_map, embedding_size=8)\n",
    "#            combined_feature = Lambda(lambda xs: K.concatenate(xs, axis=-1))([hidden1, cat_emb])\n",
    "#            hidden2 = comb_dense(combined_feature)\n",
    "            hidden2 = comb_dense(hidden1)\n",
    "            hidden3 = out_dense(hidden2)\n",
    "            team_embeddings.append(Lambda(lambda x: K.expand_dims(x, 1))(hidden3))\n",
    "                \n",
    "        return team_embeddings\n",
    "    \n",
    "    def make_mix_team_embedding(self, cont_friend, cat_friend, cont_ravel, cat_ravel, cat_size_map):        \n",
    "        friend_embeddings = self.make_team_embedding(cont_friend, cat_friend, cat_size_map)\n",
    "        ravel_embeddings = self.make_team_embedding(cont_ravel, cat_ravel, cat_size_map)\n",
    "        \n",
    "        friend_weight_dense = Dense(1, activation='sigmoid')\n",
    "        ravel_weight_dense = Dense(1, activation='sigmoid')\n",
    "        \n",
    "        \n",
    "        friends_weights = []\n",
    "        ravels_weights = []\n",
    "        \n",
    "        friend_mean_embedding = Lambda(lambda xs: K.mean(xs, axis=1))(Concatenate(axis=1)(friend_embeddings))\n",
    "        ravel_mean_embedding = Lambda(lambda xs: K.mean(xs, axis=1))(Concatenate(axis=1)(ravel_embeddings))\n",
    "        mean_embedding = Add()([friend_mean_embedding, ravel_mean_embedding])\n",
    "                \n",
    "        for palyer_emb in friend_embeddings:\n",
    "            ca = Lambda(lambda xs: K.concatenate([xs[0], K.squeeze(xs[1], axis=1)]))([mean_embedding, palyer_emb])\n",
    "            friends_weights.append(friend_weight_dense(ca))\n",
    "            \n",
    "        for palyer_emb in ravel_embeddings:\n",
    "            ca = Lambda(lambda xs: K.concatenate([xs[0], K.squeeze(xs[1], axis=1)]))([mean_embedding, palyer_emb])\n",
    "            ravels_weights.append(ravel_weight_dense(ca))\n",
    "            \n",
    "        friend_concated_weights = Lambda(lambda x: K.exp(x))(Concatenate(axis=-1)(friends_weights))\n",
    "        friend_concated_weights = Lambda(lambda x: x / K.sum(x, axis=-1, keepdims=True))(friend_concated_weights)\n",
    "        \n",
    "        ravel_concated_weights = Lambda(lambda x: K.exp(x))(Concatenate(axis=-1)(ravels_weights))\n",
    "        ravel_concated_weights = Lambda(lambda x: x / K.sum(x, axis=-1, keepdims=True))(ravel_concated_weights)\n",
    "        \n",
    "        friend_concated_team_embeddings = Concatenate(axis=1)(friend_embeddings)\n",
    "        ravel_concated_team_embeddings = Concatenate(axis=1)(ravel_embeddings)\n",
    "        \n",
    "        friend_res = Lambda(lambda ps: K.mean(tf.matmul(K.expand_dims(ps[0], axis=1), ps[1]), axis=1))([friend_concated_weights, friend_concated_team_embeddings])\n",
    "        ravel_res = Lambda(lambda ps: K.mean(tf.matmul(K.expand_dims(ps[0], axis=1), ps[1]), axis=1))([ravel_concated_weights, ravel_concated_team_embeddings])\n",
    "        \n",
    "        return friend_res, ravel_res\n",
    "        \n",
    "        \n",
    "    def build_muti_class_model(self, cat_size_map):\n",
    "        # build nn structure of discrete feature\n",
    "        cat_embedding = self.make_category_embedding(self.category_input, self.category_features, cat_size_map, name=\"multiclass_cat_embedding\")\n",
    "        \n",
    "        friend_team_embedding, ravel_team_embedding = self.make_mix_team_embedding(self.continuous_friend_input, self.category_friend_input, self.continuous_ravel_input, self.category_ravel_input, cat_size_map)\n",
    "        \n",
    "        hidden_layer1 = Dense(256, name=\"sigmoid_hidden1\", activation='relu')(self.continuous_input)\n",
    "        combined_feature = Lambda(lambda xs: K.concatenate(xs, axis=-1), name=\"combine_cont_dis\")([hidden_layer1, friend_team_embedding, ravel_team_embedding, cat_embedding])\n",
    "        hidden_layer2 = DropoutDense(256, name=\"sigmoid_hidden2\", activation='relu')(combined_feature)\n",
    "\n",
    "        # final output\n",
    "        hidden_layer4 = DropoutDense(128, name=\"sigmoid_hidden4\", dropout_ratio=0.5, activation='relu')(hidden_layer2)\n",
    "        final_output = Dense(199, name=\"output_dense1\", activation='softmax')(hidden_layer4)     \n",
    "        final_output = Lambda(lambda x: K.clip(x, 1e-8, 1), name=\"output_dense1_clip\")(final_output)\n",
    "\n",
    "        return final_output\n",
    "    \n",
    "    \n",
    "    def build_model(self, cat_size_map):\n",
    "        self.continuous_input = Input((len(self.continuous_features), ), dtype=tf.float32, name=\"continuous_input\")\n",
    "        self.category_input = Input((len(self.category_features), ), dtype=tf.int32, name=\"category_input\")\n",
    "        \n",
    "        # team friend features\n",
    "        self.continuous_friend_input = [Input((len(self.player_continuous_feature), ),  dtype=tf.float32, name=\"friend_continuous_input\" + str(i)) for i in range(10)]\n",
    "        self.category_friend_input = [Input((len(self.player_category_feature), ),  dtype=tf.int32, name=\"friend_category_input\" + str(i)) for i in range(10)]\n",
    "\n",
    "        # team ravel features\n",
    "        self.continuous_ravel_input = [Input((len(self.player_continuous_feature), ),  dtype=tf.float32, name=\"ravel_continuous_input\" + str(i)) for i in range(11)]\n",
    "        self.category_ravel_input = [Input((len(self.player_category_feature), ),  dtype=tf.int32, name=\"ravel_category_input\" + str(i)) for i in range(11)]\n",
    "  \n",
    "        # clip value avoid overflow\n",
    "        self.output = self.build_muti_class_model(cat_size_map)\n",
    "                \n",
    "        self.model = Model(inputs=[self.continuous_input, self.category_input] + \n",
    "                           self.continuous_friend_input + self.category_friend_input +\n",
    "                           self.continuous_ravel_input + self.category_ravel_input,\n",
    "                           outputs=self.output)\n",
    "    \n",
    "        optimizer = adam(lr=self.learning_rate, clipvalue=0.005)\n",
    "        \n",
    "        # compile model\n",
    "        self.model.compile(optimizer, loss=\"categorical_crossentropy\", metrics=[self.crps_loss_by_label_tensor])\n",
    "        \n",
    "    def make_y_vec(self, y_list):\n",
    "        y_list =np.round(y_list).astype('int32') + 99\n",
    "        target = np.zeros((len(y_list), 199))\n",
    "        target[range(len(y_list)),y_list] = 1\n",
    "        \n",
    "        return target\n",
    "        \n",
    "    def train_model(self, train_df, validate_df=None):\n",
    "        # print(self.continuous_features)\n",
    "        x_continuous = train_df[self.continuous_features]\n",
    "        x_category = train_df[self.category_features]\n",
    "        x_friend_continuours = [train_df[[f for f in friend_continuous_features if f.startswith(\"friend\"+str(i)+\"_\")]]  for i in range(10)]\n",
    "        x_friend_category = [train_df[[f for f in friend_category_features if f.startswith(\"friend\"+str(i)+\"_\")]]  for i in range(10)]\n",
    "        x_ravel_continuours = [train_df[[f for f in ravel_continuous_features if f.startswith(\"ravel\"+str(i)+\"_\")]]  for i in range(11)]\n",
    "        x_ravel_category = [train_df[[f for f in ravel_category_features if f.startswith(\"ravel\"+str(i)+\"_\")]]  for i in range(11)]\n",
    "        # print(x_friend_continuours[0].columns)\n",
    "        # print(x_ravel_continuours[0].shape)\n",
    "        \n",
    "        validate_x_continuous = validate_df[self.continuous_features]\n",
    "        validate_x_category = validate_df[self.category_features]\n",
    "        validate_x_friend_continuours = [validate_df[[f for f in friend_continuous_features if f.startswith(\"friend\"+str(i)+\"_\")]]  for i in range(10)]\n",
    "        validate_x_friend_category = [validate_df[[f for f in friend_category_features if f.startswith(\"friend\"+str(i)+\"_\")]]  for i in range(10)]\n",
    "        validate_x_ravel_continuours =  [validate_df[[f for f in ravel_continuous_features if f.startswith(\"ravel\"+str(i)+\"_\")]]  for i in range(11)]\n",
    "        validate_x_ravel_category = [validate_df[[f for f in ravel_category_features if f.startswith(\"ravel\"+str(i)+\"_\")]]  for i in range(11)]\n",
    "        \n",
    "        y_vector = self.make_y_vec(train_df[self.label])\n",
    "        validate_y_vector = self.make_y_vec(validate_df[self.label])\n",
    "        \n",
    "        xs = [x_continuous, x_category] + x_friend_continuours + x_friend_category + \\\n",
    "            x_ravel_continuours + x_ravel_category\n",
    "        \n",
    "        validate_xs = [validate_x_continuous, validate_x_category] + validate_x_friend_continuours + \\\n",
    "                        validate_x_friend_category  + \\\n",
    "                        validate_x_ravel_continuours + validate_x_ravel_category\n",
    "                \n",
    "        es = EarlyStopping(monitor='val_crps_loss_by_label_tensor', \n",
    "                       mode='min',\n",
    "                       verbose=2, \n",
    "                       restore_best_weights=True,\n",
    "                       patience=10)\n",
    "\n",
    "        self.model.fit(xs, y_vector, epochs=self.epoch, batch_size=self.batch_size, \n",
    "                       callbacks=[es], validation_data=(validate_xs, validate_y_vector))\n",
    "        \n",
    "        \n",
    "    def score(self, validate_df):\n",
    "        y = self.predict(validate_df)\n",
    "        y_vector = np.cumsum(self.make_y_vec(validate_df[self.label]), axis=-1)\n",
    "        \n",
    "        return y, y_vector, self.crps_loss_by_label_np(y, y_vector)\n",
    "       \n",
    "        \n",
    "    def predict(self, test_df):\n",
    "        x_continuous = test_df[self.continuous_features]\n",
    "        x_category = test_df[self.category_features]\n",
    "        x_friend_continuours = [test_df[[f for f in friend_continuous_features if f.startswith(\"friend\"+str(i)+\"_\")]]  for i in range(10)]\n",
    "        x_friend_category = [test_df[[f for f in friend_category_features if f.startswith(\"friend\"+str(i)+\"_\")]]  for i in range(10)]\n",
    "        x_ravel_continuours = [test_df[[f for f in ravel_continuous_features if f.startswith(\"ravel\"+str(i)+\"_\")]]  for i in range(11)]\n",
    "        x_ravel_category = [test_df[[f for f in ravel_category_features if f.startswith(\"ravel\"+str(i)+\"_\")]]  for i in range(11)]\n",
    "        \n",
    "        xs = [x_continuous, x_category] + x_friend_continuours + x_friend_category + \\\n",
    "              x_ravel_continuours + x_ravel_category\n",
    "        \n",
    "        y = self.model.predict(xs)\n",
    "        y = np.clip(np.cumsum(y, axis=-1), 0, 1)\n",
    "        \n",
    "        # modify by YardLine_std\n",
    "        max_to_go = np.array(110 - test_df['YardLine_std'] + 0.5).astype(np.int32)\n",
    "        target_index = np.array([np.arange(199)] * len(max_to_go))\n",
    "        # print(max_to_go)\n",
    "        y[target_index-99 >= np.array([max_to_go]).T] = 1\n",
    "        y[target_index-99 <= np.array([max_to_go]).T - 110] = 0\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "class KFoldByKey(object):\n",
    "    def __init__(self, nfold, shuffle=False):\n",
    "        self.nfold = nfold\n",
    "        self.shuffle= shuffle\n",
    "        \n",
    "    def __flatten(self, list2d):\n",
    "        ret = []\n",
    "        for i in list2d:\n",
    "            ret += i\n",
    "        return ret\n",
    "        \n",
    "    def split(self, df_col):        \n",
    "        key_values = list(set(df_col))\n",
    "        split_step = float(len(key_values)) / self.nfold\n",
    "        range_point = [int(i * split_step) for i in range(self.nfold)] + [len(key_values)]\n",
    "        key_splits = [key_values[range_point[i]:range_point[i+1]] for i in range(self.nfold)]\n",
    "        \n",
    "        for i in range(self.nfold):\n",
    "            test_keys = key_splits[i]\n",
    "            train_keys = self.__flatten([key_splits[j] for j in range(self.nfold) if j != i])\n",
    "            \n",
    "            yield (np.where(df_col.isin(train_keys)), np.where(df_col.isin(test_keys)))\n",
    "\n",
    "\n",
    "class CategoryFeatureEncoder(object):\n",
    "    def __init__(self, category_features):\n",
    "        self.label_encoders = dict()\n",
    "        self.category_features = category_features\n",
    "        self.cat_size = dict()\n",
    "\n",
    "    def fit(self, df):\n",
    "        for column in self.category_features:\n",
    "            suffix = column.split('#')[-1]\n",
    "            if suffix not in self.label_encoders:\n",
    "                related_cols = [col for col in self.category_features if col.split(\"#\")[-1] == suffix]\n",
    "                related_category = []\n",
    "                for col in related_cols:\n",
    "                    related_category += list(set(df[col]))\n",
    "                related_category = list(set(related_category))\n",
    "                _, indexer = pd.DataFrame({\"x\": related_category})['x'].factorize()\n",
    "                self.cat_size[suffix] = indexer.size + 2\n",
    "                self.label_encoders[suffix] = indexer\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        for col in self.category_features:\n",
    "            suffix = col.split('#')[-1]\n",
    "            indexer = self.label_encoders[suffix]\n",
    "            df[col] = indexer.get_indexer(df[col]) + 2\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)\n",
    "\n",
    "    def get_cat_size_map(self):\n",
    "        return self.cat_size\n",
    "\n",
    "\n",
    "\n",
    "class DataNegEnhancement(object):\n",
    "    def __init__(self, f_convert=None):\n",
    "        self.f_convert = f_convert if f_convert is not None else self.neg_enhancement\n",
    "        \n",
    "    def transform(self, df):\n",
    "        neg_df = df.copy()\n",
    "        neg_df = self.f_convert(neg_df)\n",
    "        return pd.concat([df, neg_df])\n",
    "    \n",
    "    @staticmethod\n",
    "    def neg_enhancement(df):\n",
    "        df['Y'] = (160 / 3) - df['Y']\n",
    "        df['y1'] = (160 / 3) - df['y1']\n",
    "        df['y2'] = (160 / 3) - df['y2']\n",
    "        for f in df.columns:\n",
    "            if f.endswith('_cont_Y') or f.endswith('_cont_y1') or f.endswith('_cont_y2'):\n",
    "                df[f] = -df[f]\n",
    "        df['Dir'] = df['Dir'].apply(lambda x:(-(x-90)%360 + 90)%360)\n",
    "        df['Orientation'] = df['Orientation'].apply(lambda x:(-(x-90)%360 + 90)%360)\n",
    "        for col in ['speed_cos_Dir','acc_cos_Dir','speed_cos_Ori','acc_cos_Ori']:\n",
    "            for f in df.columns:\n",
    "                if col in f:\n",
    "                    df[f] = -df[f]\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_model(train_df, continuous_features, category_features, label, cat_size_map, epoch=100, batch_size=1024,\n",
    "                     common_embedding_size=8, specified_embedding_map=None, learning_rate=0.001, nfold=4, last_only=False):\n",
    "    errs = []\n",
    "    clfs = []\n",
    "\n",
    "    oof_predictions = np.zeros((train_df.shape[0], 199))\n",
    "    oof_targets = np.zeros((train_df.shape[0], 199))\n",
    "\n",
    "    category_features = [f for f in category_features if f in cat_size_map]\n",
    "    \n",
    "    # fold data\n",
    "    kf = KFoldByKey(nfold, shuffle=False)\n",
    "    cnt = 0\n",
    "    for train_index, test_index in kf.split(train_df[\"GameId\"]):\n",
    "        cnt += 1\n",
    "        print(f\"Training for FOLD {cnt}\")\n",
    "        gc.collect()\n",
    "        timer = GoldenTimer()\n",
    "        if (not last_only) or cnt == nfold:\n",
    "            X_train, X_test = train_df.iloc[train_index].copy(), train_df.iloc[test_index].copy()\n",
    "            \n",
    "            data_enhancement = DataNegEnhancement()\n",
    "            X_train = data_enhancement.transform(X_train)\n",
    "            \n",
    "            X_train[continuous_features] = sc.transform(X_train[continuous_features])\n",
    "            X_test[continuous_features] = sc.transform(X_test[continuous_features])\n",
    "    \n",
    "            model = NLF_NN(continuous_features, category_features, label, epoch, batch_size, \n",
    "                           common_embedding_size=common_embedding_size, specified_embedding_map=specified_embedding_map,\n",
    "                           learning_rate=learning_rate, \n",
    "                           player_continuous_feature=player_continuous_feature, player_category_feature=player_category_feature)\n",
    "             \n",
    "            model.build_model(cat_size_map)\n",
    "            model.train_model(X_train, validate_df=X_test)\n",
    "            \n",
    "            y_pred, y_target, score = model.score(X_test)\n",
    "            \n",
    "            oof_predictions[test_index] = y_pred\n",
    "            oof_targets[test_index] = y_target\n",
    "\n",
    "            print(f\"FOLD {cnt} score:\", score)\n",
    "            \n",
    "            if score < 0.015 and not math.isnan(score):\n",
    "                errs.append(score)\n",
    "                clfs.append(model)\n",
    "\n",
    "    oof_score = ((oof_predictions - oof_targets) ** 2).sum(axis=1).sum(axis=0) / (199 * oof_targets.shape[0])                        \n",
    "    print(f\"OOF Score {oof_score}, Mean Score {np.mean(errs)}, Std Score {np.std(errs)}\")\n",
    "    return clfs, oof_predictions, oof_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DefendersInTheBox', 'Position', 'OffenseFormation', 'DefensePersonnel']\n",
      "['X', 'Y', 'S', 'A', 'Dis', 'Distance', 'Dir', 'speed_sin_Dir', 'speed_cos_Dir', 'acc_sin_Dir', 'acc_cos_Dir', 'x1', 'y1', 'x2', 'y2', 'YardLine_std_diff', 'is_old']\n",
      "Training for FOLD 1\n",
      "Train on 34568 samples, validate on 5887 samples\n",
      "Epoch 1/100\n",
      "34568/34568 [==============================] - 12s 353us/step - loss: 3.7733 - crps_loss_by_label_tensor: 0.0324 - val_loss: 2.9165 - val_crps_loss_by_label_tensor: 0.0148\n",
      "Epoch 2/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 3.0203 - crps_loss_by_label_tensor: 0.0146 - val_loss: 2.7712 - val_crps_loss_by_label_tensor: 0.0129\n",
      "Epoch 3/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.8887 - crps_loss_by_label_tensor: 0.0136 - val_loss: 2.7040 - val_crps_loss_by_label_tensor: 0.0123\n",
      "Epoch 4/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.8116 - crps_loss_by_label_tensor: 0.0132 - val_loss: 2.6561 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 5/100\n",
      "34568/34568 [==============================] - 6s 164us/step - loss: 2.7599 - crps_loss_by_label_tensor: 0.0129 - val_loss: 2.6237 - val_crps_loss_by_label_tensor: 0.0119\n",
      "Epoch 6/100\n",
      "34568/34568 [==============================] - 6s 163us/step - loss: 2.7250 - crps_loss_by_label_tensor: 0.0127 - val_loss: 2.6063 - val_crps_loss_by_label_tensor: 0.0118\n",
      "Epoch 7/100\n",
      "34568/34568 [==============================] - 6s 170us/step - loss: 2.6971 - crps_loss_by_label_tensor: 0.0126 - val_loss: 2.5852 - val_crps_loss_by_label_tensor: 0.0116\n",
      "Epoch 8/100\n",
      "34568/34568 [==============================] - 6s 171us/step - loss: 2.6768 - crps_loss_by_label_tensor: 0.0125 - val_loss: 2.5736 - val_crps_loss_by_label_tensor: 0.0116\n",
      "Epoch 9/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.6637 - crps_loss_by_label_tensor: 0.0124 - val_loss: 2.5685 - val_crps_loss_by_label_tensor: 0.0115\n",
      "Epoch 10/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.6489 - crps_loss_by_label_tensor: 0.0124 - val_loss: 2.5721 - val_crps_loss_by_label_tensor: 0.0115\n",
      "Epoch 11/100\n",
      "34568/34568 [==============================] - 6s 168us/step - loss: 2.6369 - crps_loss_by_label_tensor: 0.0123 - val_loss: 2.5575 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 12/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.6304 - crps_loss_by_label_tensor: 0.0123 - val_loss: 2.5539 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 13/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.6188 - crps_loss_by_label_tensor: 0.0122 - val_loss: 2.5595 - val_crps_loss_by_label_tensor: 0.0115\n",
      "Epoch 14/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.6141 - crps_loss_by_label_tensor: 0.0122 - val_loss: 2.5599 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 15/100\n",
      "34568/34568 [==============================] - 6s 167us/step - loss: 2.6082 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.5624 - val_crps_loss_by_label_tensor: 0.0115\n",
      "Epoch 16/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.5982 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.5460 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 17/100\n",
      "34568/34568 [==============================] - 7s 201us/step - loss: 2.5936 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.5532 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 18/100\n",
      "34568/34568 [==============================] - 6s 170us/step - loss: 2.5826 - crps_loss_by_label_tensor: 0.0120 - val_loss: 2.5530 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 19/100\n",
      "34568/34568 [==============================] - 6s 167us/step - loss: 2.5762 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.5544 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 20/100\n",
      "34568/34568 [==============================] - 6s 169us/step - loss: 2.5697 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.5463 - val_crps_loss_by_label_tensor: 0.0113\n",
      "Epoch 21/100\n",
      "34568/34568 [==============================] - 6s 168us/step - loss: 2.5667 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.5620 - val_crps_loss_by_label_tensor: 0.0115\n",
      "Epoch 22/100\n",
      "34568/34568 [==============================] - 6s 167us/step - loss: 2.5611 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.5511 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 23/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.5582 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.5494 - val_crps_loss_by_label_tensor: 0.0113\n",
      "Epoch 24/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.5496 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.5579 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 25/100\n",
      "34568/34568 [==============================] - 6s 168us/step - loss: 2.5399 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.5512 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 26/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.5315 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.5610 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 27/100\n",
      "34568/34568 [==============================] - 6s 182us/step - loss: 2.5314 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.5535 - val_crps_loss_by_label_tensor: 0.0113\n",
      "Epoch 28/100\n",
      "34568/34568 [==============================] - 6s 168us/step - loss: 2.5244 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.5518 - val_crps_loss_by_label_tensor: 0.0113\n",
      "Epoch 29/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.5186 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.5540 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 30/100\n",
      "34568/34568 [==============================] - 6s 163us/step - loss: 2.5206 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.5684 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 31/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.5075 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.5614 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 32/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.4988 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.5667 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 33/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.4894 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.5600 - val_crps_loss_by_label_tensor: 0.0113\n",
      "Epoch 34/100\n",
      "34568/34568 [==============================] - 6s 165us/step - loss: 2.4882 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.5661 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 35/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.4825 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.5732 - val_crps_loss_by_label_tensor: 0.0115\n",
      "Epoch 36/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.4756 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.5785 - val_crps_loss_by_label_tensor: 0.0115\n",
      "Epoch 37/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.4719 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.5681 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Epoch 38/100\n",
      "34568/34568 [==============================] - 6s 166us/step - loss: 2.4598 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.5766 - val_crps_loss_by_label_tensor: 0.0114\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00038: early stopping\n",
      "FOLD 1 score: 0.01125016275525398\n",
      "Training for FOLD 2\n",
      "Train on 35080 samples, validate on 5631 samples\n",
      "Epoch 1/100\n",
      "35080/35080 [==============================] - 12s 353us/step - loss: 3.7377 - crps_loss_by_label_tensor: 0.0306 - val_loss: 2.9219 - val_crps_loss_by_label_tensor: 0.0148\n",
      "Epoch 2/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 3.0018 - crps_loss_by_label_tensor: 0.0143 - val_loss: 2.7991 - val_crps_loss_by_label_tensor: 0.0134\n",
      "Epoch 3/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 2.8663 - crps_loss_by_label_tensor: 0.0134 - val_loss: 2.7402 - val_crps_loss_by_label_tensor: 0.0130\n",
      "Epoch 4/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 2.7911 - crps_loss_by_label_tensor: 0.0129 - val_loss: 2.6869 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 5/100\n",
      "35080/35080 [==============================] - 6s 163us/step - loss: 2.7341 - crps_loss_by_label_tensor: 0.0127 - val_loss: 2.6717 - val_crps_loss_by_label_tensor: 0.0125\n",
      "Epoch 6/100\n",
      "35080/35080 [==============================] - 6s 162us/step - loss: 2.7050 - crps_loss_by_label_tensor: 0.0125 - val_loss: 2.6424 - val_crps_loss_by_label_tensor: 0.0123\n",
      "Epoch 7/100\n",
      "35080/35080 [==============================] - 6s 166us/step - loss: 2.6750 - crps_loss_by_label_tensor: 0.0123 - val_loss: 2.6434 - val_crps_loss_by_label_tensor: 0.0123\n",
      "Epoch 8/100\n",
      "35080/35080 [==============================] - 6s 165us/step - loss: 2.6603 - crps_loss_by_label_tensor: 0.0122 - val_loss: 2.6332 - val_crps_loss_by_label_tensor: 0.0122\n",
      "Epoch 9/100\n",
      "35080/35080 [==============================] - 6s 166us/step - loss: 2.6435 - crps_loss_by_label_tensor: 0.0122 - val_loss: 2.6270 - val_crps_loss_by_label_tensor: 0.0122\n",
      "Epoch 10/100\n",
      "35080/35080 [==============================] - 6s 166us/step - loss: 2.6305 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.6232 - val_crps_loss_by_label_tensor: 0.0122\n",
      "Epoch 11/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 2.6214 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.6277 - val_crps_loss_by_label_tensor: 0.0122\n",
      "Epoch 12/100\n",
      "35080/35080 [==============================] - 6s 165us/step - loss: 2.6108 - crps_loss_by_label_tensor: 0.0120 - val_loss: 2.6099 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 13/100\n",
      "35080/35080 [==============================] - 6s 168us/step - loss: 2.6012 - crps_loss_by_label_tensor: 0.0120 - val_loss: 2.6104 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 14/100\n",
      "35080/35080 [==============================] - 6s 169us/step - loss: 2.5952 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.6033 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 15/100\n",
      "35080/35080 [==============================] - 6s 168us/step - loss: 2.5852 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6135 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 16/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 2.5812 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.6090 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 17/100\n",
      "35080/35080 [==============================] - 6s 166us/step - loss: 2.5754 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.6012 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 18/100\n",
      "35080/35080 [==============================] - 6s 169us/step - loss: 2.5657 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6026 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 19/100\n",
      "35080/35080 [==============================] - 6s 172us/step - loss: 2.5579 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.6095 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 20/100\n",
      "35080/35080 [==============================] - 6s 171us/step - loss: 2.5609 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6114 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 21/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 2.5489 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.5979 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 22/100\n",
      "35080/35080 [==============================] - 6s 168us/step - loss: 2.5417 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6116 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 23/100\n",
      "35080/35080 [==============================] - 6s 165us/step - loss: 2.5360 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6015 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 24/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 2.5359 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6457 - val_crps_loss_by_label_tensor: 0.0122\n",
      "Epoch 25/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 2.5379 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6117 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 26/100\n",
      "35080/35080 [==============================] - 6s 165us/step - loss: 2.5229 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6095 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 27/100\n",
      "35080/35080 [==============================] - 6s 166us/step - loss: 2.5253 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.6104 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 28/100\n",
      "35080/35080 [==============================] - 6s 166us/step - loss: 2.5151 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.6176 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 29/100\n",
      "35080/35080 [==============================] - 6s 167us/step - loss: 2.5065 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6183 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 30/100\n",
      "35080/35080 [==============================] - 6s 166us/step - loss: 2.4989 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6158 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 31/100\n",
      "35080/35080 [==============================] - 6s 166us/step - loss: 2.4968 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6131 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00031: early stopping\n",
      "FOLD 2 score: 0.011832806028491169\n",
      "Training for FOLD 3\n",
      "Train on 34630 samples, validate on 5856 samples\n",
      "Epoch 1/100\n",
      "34630/34630 [==============================] - 12s 354us/step - loss: 3.7565 - crps_loss_by_label_tensor: 0.0315 - val_loss: 2.9361 - val_crps_loss_by_label_tensor: 0.0149\n",
      "Epoch 2/100\n",
      "34630/34630 [==============================] - 6s 179us/step - loss: 3.0029 - crps_loss_by_label_tensor: 0.0143 - val_loss: 2.8050 - val_crps_loss_by_label_tensor: 0.0133\n",
      "Epoch 3/100\n",
      "34630/34630 [==============================] - 6s 164us/step - loss: 2.8707 - crps_loss_by_label_tensor: 0.0134 - val_loss: 2.7532 - val_crps_loss_by_label_tensor: 0.0129\n",
      "Epoch 4/100\n",
      "34630/34630 [==============================] - 6s 162us/step - loss: 2.7904 - crps_loss_by_label_tensor: 0.0130 - val_loss: 2.6995 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 5/100\n",
      "34630/34630 [==============================] - 6s 163us/step - loss: 2.7419 - crps_loss_by_label_tensor: 0.0127 - val_loss: 2.6770 - val_crps_loss_by_label_tensor: 0.0125\n",
      "Epoch 6/100\n",
      "34630/34630 [==============================] - 6s 166us/step - loss: 2.7073 - crps_loss_by_label_tensor: 0.0125 - val_loss: 2.6597 - val_crps_loss_by_label_tensor: 0.0123\n",
      "Epoch 7/100\n",
      "34630/34630 [==============================] - 6s 162us/step - loss: 2.6770 - crps_loss_by_label_tensor: 0.0124 - val_loss: 2.6385 - val_crps_loss_by_label_tensor: 0.0122\n",
      "Epoch 8/100\n",
      "34630/34630 [==============================] - 6s 162us/step - loss: 2.6596 - crps_loss_by_label_tensor: 0.0123 - val_loss: 2.6377 - val_crps_loss_by_label_tensor: 0.0122\n",
      "Epoch 9/100\n",
      "34630/34630 [==============================] - 6s 171us/step - loss: 2.6433 - crps_loss_by_label_tensor: 0.0122 - val_loss: 2.6230 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 10/100\n",
      "34630/34630 [==============================] - 6s 164us/step - loss: 2.6336 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.6219 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 11/100\n",
      "34630/34630 [==============================] - 6s 164us/step - loss: 2.6197 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.6229 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 12/100\n",
      "34630/34630 [==============================] - 6s 164us/step - loss: 2.6143 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.6153 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 13/100\n",
      "34630/34630 [==============================] - 6s 167us/step - loss: 2.5988 - crps_loss_by_label_tensor: 0.0120 - val_loss: 2.6136 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 14/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.5913 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.6225 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 15/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.5900 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.6062 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 16/100\n",
      "34630/34630 [==============================] - 6s 167us/step - loss: 2.5764 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6092 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 17/100\n",
      "34630/34630 [==============================] - 6s 166us/step - loss: 2.5723 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6049 - val_crps_loss_by_label_tensor: 0.0119\n",
      "Epoch 18/100\n",
      "34630/34630 [==============================] - 6s 164us/step - loss: 2.5650 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6109 - val_crps_loss_by_label_tensor: 0.0119\n",
      "Epoch 19/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.5579 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.6220 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 20/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.5558 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.6160 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 21/100\n",
      "34630/34630 [==============================] - 6s 166us/step - loss: 2.5460 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.6162 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 22/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.5423 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.6171 - val_crps_loss_by_label_tensor: 0.0121\n",
      "Epoch 23/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.5332 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6138 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 24/100\n",
      "34630/34630 [==============================] - 6s 166us/step - loss: 2.5247 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6152 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 25/100\n",
      "34630/34630 [==============================] - 6s 166us/step - loss: 2.5198 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.6207 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 26/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.5189 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.6187 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 27/100\n",
      "34630/34630 [==============================] - 6s 166us/step - loss: 2.5139 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.6205 - val_crps_loss_by_label_tensor: 0.0119\n",
      "Epoch 28/100\n",
      "34630/34630 [==============================] - 6s 164us/step - loss: 2.5050 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6175 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 29/100\n",
      "34630/34630 [==============================] - 6s 164us/step - loss: 2.4979 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6240 - val_crps_loss_by_label_tensor: 0.0119\n",
      "Epoch 30/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.4946 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6272 - val_crps_loss_by_label_tensor: 0.0119\n",
      "Epoch 31/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.4842 - crps_loss_by_label_tensor: 0.0113 - val_loss: 2.6322 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 32/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.4835 - crps_loss_by_label_tensor: 0.0113 - val_loss: 2.6310 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 33/100\n",
      "34630/34630 [==============================] - 6s 167us/step - loss: 2.4686 - crps_loss_by_label_tensor: 0.0113 - val_loss: 2.6304 - val_crps_loss_by_label_tensor: 0.0119\n",
      "Epoch 34/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.4636 - crps_loss_by_label_tensor: 0.0112 - val_loss: 2.6364 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 35/100\n",
      "34630/34630 [==============================] - 6s 166us/step - loss: 2.4652 - crps_loss_by_label_tensor: 0.0112 - val_loss: 2.6438 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 36/100\n",
      "34630/34630 [==============================] - 6s 165us/step - loss: 2.4599 - crps_loss_by_label_tensor: 0.0112 - val_loss: 2.6468 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Epoch 37/100\n",
      "34630/34630 [==============================] - 6s 169us/step - loss: 2.4494 - crps_loss_by_label_tensor: 0.0112 - val_loss: 2.6383 - val_crps_loss_by_label_tensor: 0.0120\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00037: early stopping\n",
      "FOLD 3 score: 0.011874915856235832\n",
      "Training for FOLD 4\n",
      "Train on 34748 samples, validate on 5797 samples\n",
      "Epoch 1/100\n",
      "34748/34748 [==============================] - 13s 377us/step - loss: 3.7384 - crps_loss_by_label_tensor: 0.0315 - val_loss: 2.9511 - val_crps_loss_by_label_tensor: 0.0154\n",
      "Epoch 2/100\n",
      "34748/34748 [==============================] - 6s 167us/step - loss: 2.9903 - crps_loss_by_label_tensor: 0.0141 - val_loss: 2.8224 - val_crps_loss_by_label_tensor: 0.0137\n",
      "Epoch 3/100\n",
      "34748/34748 [==============================] - 6s 165us/step - loss: 2.8484 - crps_loss_by_label_tensor: 0.0131 - val_loss: 2.7710 - val_crps_loss_by_label_tensor: 0.0133\n",
      "Epoch 4/100\n",
      "34748/34748 [==============================] - 6s 165us/step - loss: 2.7600 - crps_loss_by_label_tensor: 0.0127 - val_loss: 2.7302 - val_crps_loss_by_label_tensor: 0.0130\n",
      "Epoch 5/100\n",
      "34748/34748 [==============================] - 6s 168us/step - loss: 2.7122 - crps_loss_by_label_tensor: 0.0125 - val_loss: 2.7091 - val_crps_loss_by_label_tensor: 0.0128\n",
      "Epoch 6/100\n",
      "34748/34748 [==============================] - 6s 164us/step - loss: 2.6767 - crps_loss_by_label_tensor: 0.0123 - val_loss: 2.7053 - val_crps_loss_by_label_tensor: 0.0128\n",
      "Epoch 7/100\n",
      "34748/34748 [==============================] - 6s 165us/step - loss: 2.6559 - crps_loss_by_label_tensor: 0.0122 - val_loss: 2.6971 - val_crps_loss_by_label_tensor: 0.0128\n",
      "Epoch 8/100\n",
      "34748/34748 [==============================] - 6s 163us/step - loss: 2.6363 - crps_loss_by_label_tensor: 0.0121 - val_loss: 2.6885 - val_crps_loss_by_label_tensor: 0.0127\n",
      "Epoch 9/100\n",
      "34748/34748 [==============================] - 6s 167us/step - loss: 2.6195 - crps_loss_by_label_tensor: 0.0120 - val_loss: 2.6851 - val_crps_loss_by_label_tensor: 0.0127\n",
      "Epoch 10/100\n",
      "34748/34748 [==============================] - 6s 165us/step - loss: 2.6089 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.6952 - val_crps_loss_by_label_tensor: 0.0127\n",
      "Epoch 11/100\n",
      "34748/34748 [==============================] - 6s 162us/step - loss: 2.5993 - crps_loss_by_label_tensor: 0.0119 - val_loss: 2.6896 - val_crps_loss_by_label_tensor: 0.0128\n",
      "Epoch 12/100\n",
      "34748/34748 [==============================] - 6s 165us/step - loss: 2.5878 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6714 - val_crps_loss_by_label_tensor: 0.0125\n",
      "Epoch 13/100\n",
      "34748/34748 [==============================] - 6s 183us/step - loss: 2.5762 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6716 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 14/100\n",
      "34748/34748 [==============================] - 6s 168us/step - loss: 2.5714 - crps_loss_by_label_tensor: 0.0118 - val_loss: 2.6809 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 15/100\n",
      "34748/34748 [==============================] - 6s 167us/step - loss: 2.5635 - crps_loss_by_label_tensor: 0.0117 - val_loss: 2.6734 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 16/100\n",
      "34748/34748 [==============================] - 6s 170us/step - loss: 2.5556 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6734 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 17/100\n",
      "34748/34748 [==============================] - 6s 167us/step - loss: 2.5506 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6785 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 18/100\n",
      "34748/34748 [==============================] - 6s 169us/step - loss: 2.5442 - crps_loss_by_label_tensor: 0.0116 - val_loss: 2.6654 - val_crps_loss_by_label_tensor: 0.0125\n",
      "Epoch 19/100\n",
      "34748/34748 [==============================] - 6s 171us/step - loss: 2.5361 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.6738 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 20/100\n",
      "34748/34748 [==============================] - 6s 168us/step - loss: 2.5305 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.6739 - val_crps_loss_by_label_tensor: 0.0125\n",
      "Epoch 21/100\n",
      "34748/34748 [==============================] - 6s 166us/step - loss: 2.5239 - crps_loss_by_label_tensor: 0.0115 - val_loss: 2.6720 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 22/100\n",
      "34748/34748 [==============================] - 6s 168us/step - loss: 2.5159 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6865 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 23/100\n",
      "34748/34748 [==============================] - 6s 171us/step - loss: 2.5079 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6736 - val_crps_loss_by_label_tensor: 0.0125\n",
      "Epoch 24/100\n",
      "34748/34748 [==============================] - 6s 173us/step - loss: 2.5056 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.6773 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 25/100\n",
      "34748/34748 [==============================] - 6s 167us/step - loss: 2.5036 - crps_loss_by_label_tensor: 0.0114 - val_loss: 2.7110 - val_crps_loss_by_label_tensor: 0.0127\n",
      "Epoch 26/100\n",
      "34748/34748 [==============================] - 6s 169us/step - loss: 2.4937 - crps_loss_by_label_tensor: 0.0113 - val_loss: 2.7021 - val_crps_loss_by_label_tensor: 0.0128\n",
      "Epoch 27/100\n",
      "34748/34748 [==============================] - 6s 167us/step - loss: 2.4887 - crps_loss_by_label_tensor: 0.0113 - val_loss: 2.6938 - val_crps_loss_by_label_tensor: 0.0127\n",
      "Epoch 28/100\n",
      "34748/34748 [==============================] - 6s 165us/step - loss: 2.4863 - crps_loss_by_label_tensor: 0.0113 - val_loss: 2.7015 - val_crps_loss_by_label_tensor: 0.0127\n",
      "Epoch 29/100\n",
      "34748/34748 [==============================] - 6s 171us/step - loss: 2.4799 - crps_loss_by_label_tensor: 0.0112 - val_loss: 2.6887 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 30/100\n",
      "34748/34748 [==============================] - 6s 169us/step - loss: 2.4772 - crps_loss_by_label_tensor: 0.0112 - val_loss: 2.6946 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 31/100\n",
      "34748/34748 [==============================] - 6s 169us/step - loss: 2.4626 - crps_loss_by_label_tensor: 0.0112 - val_loss: 2.6879 - val_crps_loss_by_label_tensor: 0.0125\n",
      "Epoch 32/100\n",
      "34748/34748 [==============================] - 6s 166us/step - loss: 2.4594 - crps_loss_by_label_tensor: 0.0111 - val_loss: 2.7021 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Epoch 33/100\n",
      "34748/34748 [==============================] - 6s 166us/step - loss: 2.4587 - crps_loss_by_label_tensor: 0.0111 - val_loss: 2.7011 - val_crps_loss_by_label_tensor: 0.0126\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00033: early stopping\n",
      "FOLD 4 score: 0.01243442224554228\n",
      "OOF Score 0.01184593206586421, Mean Score 0.011848076721380815, Std Score 0.0004190034957535558\n",
      "done training 909.0277547836304\n"
     ]
    }
   ],
   "source": [
    "def is_team_feature(f):\n",
    "    team_prefix = ['friend', 'ravel']\n",
    "    for prefix in team_prefix:\n",
    "        if f.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "continuous_features = [f for f in train_df.columns if f not in exclude_feature + category_features and \n",
    "                       train_df[f].dtype != 'object' and not is_team_feature(f)]\n",
    "\n",
    "\n",
    "continuous_features = [\n",
    "    'X', 'Y', 'S', 'A', 'Dis', 'Distance', #'PlayerWeight',\n",
    "    'Dir',\n",
    "    'speed_sin_Dir', 'speed_cos_Dir', 'acc_sin_Dir', 'acc_cos_Dir',\n",
    "    \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "    'YardLine_std_diff', #'Grass'\n",
    "    \"is_old\", #'YardLine_std',\n",
    "]\n",
    "\n",
    "print(category_features)\n",
    "print(continuous_features)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_df[continuous_features])\n",
    "\n",
    "cfe = CategoryFeatureEncoder(category_features+friend_category_features+ravel_category_features)\n",
    "train_encode_df = cfe.fit_transform(train_df)\n",
    "\n",
    "timer = GoldenTimer()\n",
    "clfs, triple_predictions, triple_targets = train_base_model(train_encode_df, continuous_features, category_features, \n",
    "                        'Yards', cfe.get_cat_size_map(), \n",
    "                        common_embedding_size = 10, specified_embedding_map={\"NflId\": 256}, last_only=False)\n",
    "timer.time(\"done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn score 0.012075011534854277\n",
      "lgb score 0.012128549778693067\n",
      "triple score 0.01184593206586421\n",
      "avg score 0.011756674620531347\n"
     ]
    }
   ],
   "source": [
    "avg_pred = np.zeros(lgb_predictions.shape)\n",
    "for i in range(199):\n",
    "    avg_pred[:, i] = (lgb_predictions[:, i]*15 + nn_predictions[:, i]*20 + triple_predictions[:, i]*65) / 100\n",
    "\n",
    "oof_score = ((nn_predictions - nn_targets) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets.shape[0])\n",
    "print('nn score', oof_score)\n",
    "oof_score = ((lgb_predictions - nn_targets) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets.shape[0])\n",
    "print('lgb score', oof_score)\n",
    "oof_score = ((triple_predictions - triple_targets) ** 2).sum(axis=1).sum(axis=0) / (199 * triple_targets.shape[0])\n",
    "print('triple score', oof_score)\n",
    "oof_score = ((avg_pred - nn_targets) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets.shape[0])\n",
    "print('avg score', oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_predictions1 = nn_predictions[:,:100].copy()\n",
    "# lgb_predictions1 = lgb_predictions[:,:100].copy()\n",
    "# triple_predictions1 = triple_predictions[:,:100].copy()\n",
    "\n",
    "# nn_targets1 = nn_targets[:,:100].copy()\n",
    "# lgb_targets1 = lgb_targets[:,:100].copy()\n",
    "# triple_targets1 = triple_targets[:,:100].copy()\n",
    "\n",
    "# avg_pred = np.zeros(lgb_predictions1.shape)\n",
    "# for i in range(100):\n",
    "#     avg_pred[:, i] = (lgb_predictions1[:, i]*15 + nn_predictions1[:, i]*25 + triple_predictions1[:, i]*60) / 100\n",
    "\n",
    "# oof_score = ((nn_predictions1 - nn_targets1) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets1.shape[0])\n",
    "# print('nn score', oof_score)\n",
    "# oof_score = ((lgb_predictions1 - nn_targets1) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets1.shape[0])\n",
    "# print('lgb score', oof_score)\n",
    "# oof_score = ((triple_predictions1 - triple_targets1) ** 2).sum(axis=1).sum(axis=0) / (199 * triple_targets1.shape[0])\n",
    "# print('triple score', oof_score)\n",
    "# oof_score = ((avg_pred - nn_targets1) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets1.shape[0])\n",
    "# print('avg score', oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 120\n",
    "# nn_predictions1 = nn_predictions[:,k:].copy()\n",
    "# lgb_predictions1 = lgb_predictions[:,k:].copy()\n",
    "# triple_predictions1 = triple_predictions[:,k:].copy()\n",
    "\n",
    "# nn_targets1 = nn_targets[:,k:].copy()\n",
    "# lgb_targets1 = lgb_targets[:,k:].copy()\n",
    "# triple_targets1 = triple_targets[:,k:].copy()\n",
    "\n",
    "# avg_pred = np.zeros(lgb_predictions1.shape)\n",
    "# for i in range(199-k):\n",
    "#     avg_pred[:, i] = (lgb_predictions1[:, i]*0 + nn_predictions1[:, i]*35 + triple_predictions1[:, i]*65) / 100\n",
    "\n",
    "# oof_score = ((nn_predictions1 - nn_targets1) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets1.shape[0])\n",
    "# print('nn score', oof_score)\n",
    "# oof_score = ((lgb_predictions1 - nn_targets1) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets1.shape[0])\n",
    "# print('lgb score', oof_score)\n",
    "# oof_score = ((triple_predictions1 - triple_targets1) ** 2).sum(axis=1).sum(axis=0) / (199 * triple_targets1.shape[0])\n",
    "# print('triple score', oof_score)\n",
    "# oof_score = ((avg_pred - nn_targets1) ** 2).sum(axis=1).sum(axis=0) / (199 * nn_targets1.shape[0])\n",
    "# print('avg score', oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg score 0.011765824671969094 13-27-60\n",
    "# avg score 0.01177357946296064 0-35-65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict(test_df, models, exclude_feature=[]):\n",
    "    test_df = test_df.copy()\n",
    "    test_df = fe(test_df)\n",
    "    test_df.fillna(0, inplace=True)\n",
    "    test_df[continuous_features] = sc.transform(test_df[continuous_features])\n",
    "    test_df = cfe.transform(test_df)\n",
    "    \n",
    "    preds_labels = np.mean([model.predict(test_df) for model in models], axis=0)\n",
    "    \n",
    "    preds_labels[0][0] = 0\n",
    "    preds_labels[0][-1] = 1\n",
    "    \n",
    "    return preds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be6b903b2ec44129ce84917bb922cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env = nflrush.make_env()\n",
    "for (test_df, sample_prediction_df) in tqdm_notebook(env.iter_test()):\n",
    "    test_triple = test_df.copy()\n",
    "    test_play_df = feature_factory.make_feats(test_df, False)\n",
    "    test_play_emin = test_play_df.copy()\n",
    "    test_play_pocket = test_play_df.copy()\n",
    "    temp_yard = test_play_df[\"YardsFromOwnGoal\"].iloc[0]\n",
    "\n",
    "    lgb_pred = predictor.make_prediction(test_play_pocket).values[0]\n",
    "    lgb_pred = np.array(sorted(lgb_pred))\n",
    "    test_play_emin = test_play_emin[useful_raw_features].fillna(-10)\n",
    "    nn_pred = gambler.predict_final(test_play_emin)\n",
    "    nn_pred = np.clip(np.cumsum(nn_pred, axis=1), 0, 1)\n",
    "    nn_pred = nn_pred.ravel() \n",
    "    \n",
    "    y_triple = make_predict(test_triple, clfs).ravel() \n",
    "\n",
    "    y_pred = (15*lgb_pred+20*nn_pred+65*y_triple)/100\n",
    "    # y_pred = (50*nn_pred+50*y_triple)/100\n",
    "    y_pred = np.clip(y_pred, 0, 1)\n",
    "\n",
    "    y_pred[-temp_yard:] = 1\n",
    "    y_pred[:99-temp_yard] = 0\n",
    "    \n",
    "    sample_prediction_df.iloc[0, :] = y_pred\n",
    "\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3b630fd5c418494f98296e5197929142": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ae2002554c54876a3dd857042e5fd1f",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5e6ed81432c44de9bd0754b9c400ef23",
       "value": 1
      }
     },
     "4ae2002554c54876a3dd857042e5fd1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5be6b903b2ec44129ce84917bb922cc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3b630fd5c418494f98296e5197929142",
        "IPY_MODEL_92dfed357c75442ca59d04536e1cdc87"
       ],
       "layout": "IPY_MODEL_70103d9ba8b84ed287dde2b385d4155b"
      }
     },
     "5e6ed81432c44de9bd0754b9c400ef23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "70103d9ba8b84ed287dde2b385d4155b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92dfed357c75442ca59d04536e1cdc87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f328a7e87ba748d5aa2736f533cfb8a2",
       "placeholder": "​",
       "style": "IPY_MODEL_ad05a9a9fcb448a59fd68d006ed97754",
       "value": " 3438/? [2:55:27&lt;00:00,  3.06s/it]"
      }
     },
     "ad05a9a9fcb448a59fd68d006ed97754": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f328a7e87ba748d5aa2736f533cfb8a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
